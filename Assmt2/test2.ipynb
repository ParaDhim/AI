{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate for AI Assignment â€” Knowledge Representation, Reasoning and Planning\n",
    "# CSE 643\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import networkx as nx\n",
    "from pyDatalog import pyDatalog\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "## ****IMPORTANT****\n",
    "## Don't import or use any other libraries other than defined above\n",
    "## Otherwise your code file will be rejected in the automated testing\n",
    "\n",
    "# ------------------ Global Variables ------------------\n",
    "route_to_stops = defaultdict(list)  # Mapping of route IDs to lists of stops\n",
    "trip_to_route = {}                   # Mapping of trip IDs to route IDs\n",
    "stop_trip_count = defaultdict(int)    # Count of trips for each stop\n",
    "fare_rules = {}                      # Mapping of route IDs to fare information\n",
    "merged_fare_df = None                # To be initialized in create_kb()\n",
    "\n",
    "# Load static data from GTFS (General Transit Feed Specification) files\n",
    "df_stops = pd.read_csv('GTFS/stops.txt')\n",
    "df_routes = pd.read_csv('GTFS/routes.txt')\n",
    "df_stop_times = pd.read_csv('GTFS/stop_times.txt')\n",
    "df_fare_attributes = pd.read_csv('GTFS/fare_attributes.txt')\n",
    "df_trips = pd.read_csv('GTFS/trips.txt')\n",
    "df_fare_rules = pd.read_csv('GTFS/fare_rules.txt')\n",
    "\n",
    "# ------------------ Function Definitions ------------------\n",
    "\n",
    "# Function to create knowledge base from the loaded data\n",
    "def create_kb():\n",
    "    \"\"\"\n",
    "    Create knowledge base by populating global variables with information from loaded datasets.\n",
    "    It establishes the relationships between routes, trips, stops, and fare rules.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    global route_to_stops, trip_to_route, stop_trip_count, fare_rules, merged_fare_df\n",
    "\n",
    "    # Create trip_id to route_id mapping\"\"\"\n",
    "    trip_to_route = defaultdict(list)\n",
    "    for _, row in df_trips.iterrows():\n",
    "        trip_to_route[row['trip_id']].append(row['route_id'])\n",
    "        \n",
    "    # Map route_id to a list of stops in order of their sequence\"\"\"\n",
    "    route_to_stops = defaultdict(list)\n",
    "    sorted_stop_times = df_stop_times.sort_values(['trip_id', 'stop_sequence'])\n",
    "    sorted_stop_times.head\n",
    "    for trip_id, stop_grp in sorted_stop_times.groupby('trip_id'):\n",
    "        if trip_id in trip_to_route:\n",
    "            route_id = trip_to_route[trip_id][0]\n",
    "            stops = stop_grp['stop_id'].to_list()\n",
    "            route_to_stops[route_id].extend(stops)\n",
    "            \n",
    "    # Ensure each route only has unique stops\"\"\"\n",
    "    route_to_stops = {\n",
    "        route: [x for i, x in enumerate(stops) if x not in stops[:i]]\n",
    "        for route, stops in route_to_stops.items()\n",
    "    }\n",
    "    \n",
    "    # Count trips per stop\"\"\"\n",
    "    stop_trip_count = dict(df_stop_times['stop_id'].value_counts())\n",
    "\n",
    "    # Create fare rules for routes\n",
    "    fare_rules = {}\n",
    "    for i in range(len(df_fare_rules['route_id'])):\n",
    "        route_id = df_fare_rules['route_id'][i]\n",
    "        fare_id = df_fare_rules['fare_id'][i]\n",
    "\n",
    "        if route_id not in fare_rules:\n",
    "            fare_rules[route_id] = []\n",
    "\n",
    "        fare_rules[route_id].append(fare_id)\n",
    "\n",
    "    # Merge fare rules and attributes into a single DataFrame\n",
    "    merged_fare_df = pd.merge(\n",
    "        df_fare_rules,\n",
    "        df_fare_attributes,\n",
    "        on='fare_id',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "# Function to find the top 5 busiest routes based on the number of trips\n",
    "def get_busiest_routes():\n",
    "    \"\"\"\n",
    "    Identify the top 5 busiest routes based on trip counts.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains:\n",
    "              - route_id (int): The ID of the route.\n",
    "              - trip_count (int): The number of trips for that route.\n",
    "    \"\"\"\n",
    "    route_trip_counts = defaultdict(int)\n",
    "    for trip_id, routes in trip_to_route.items():\n",
    "        # Since we stored routes as a list in trip_to_route, take the first route\n",
    "        route_id = routes[0]\n",
    "        route_trip_counts[route_id] += 1\n",
    "    \n",
    "    res = sorted(route_trip_counts.items(), key = lambda ele: ele[1], reverse = True)\n",
    "    \n",
    "    # Return top 5 routes\n",
    "    return res[:5]\n",
    "    pass  # Implementation here\n",
    "\n",
    "# Function to find the top 5 stops with the most frequent trips\n",
    "def get_most_frequent_stops():\n",
    "    \"\"\"\n",
    "    Identify the top 5 stops with the highest number of trips.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains:\n",
    "              - stop_id (int): The ID of the stop.\n",
    "              - trip_count (int): The number of trips for that stop.\n",
    "    \"\"\"\n",
    "    res = sorted(stop_trip_count.items(), key = lambda ele: ele[1], reverse = True)\n",
    "    \n",
    "    # Return top 5 routes\n",
    "    return res[:5]\n",
    "    pass  # Implementation here\n",
    "\n",
    "# Function to find the top 5 busiest stops based on the number of routes passing through them\n",
    "def get_top_5_busiest_stops():\n",
    "    \"\"\"\n",
    "    Identify the top 5 stops with the highest number of different routes.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains:\n",
    "              - stop_id (int): The ID of the stop.\n",
    "              - route_count (int): The number of routes passing through that stop.\n",
    "    \"\"\"\n",
    "    stop_routes = defaultdict(set)\n",
    "    for route_id, stops in route_to_stops.items():\n",
    "        for stop_id in stops:\n",
    "            stop_routes[stop_id].add(route_id)\n",
    "            \n",
    "    stop_counts = []\n",
    "    for stop_id, routes in stop_routes.items():\n",
    "        route_count = len(routes)\n",
    "        stop_counts.append((stop_id, route_count))\n",
    "\n",
    "    res = sorted(stop_counts, key = lambda ele: ele[1], reverse = True)\n",
    "    \n",
    "    return res[:5]\n",
    "    pass  # Implementation here\n",
    "\n",
    "# Function to identify the top 5 pairs of stops with only one direct route between them\n",
    "def get_stops_with_one_direct_route():\n",
    "    \"\"\"\n",
    "    Identify the top 5 pairs of consecutive stops (start and end) connected by exactly one direct route. \n",
    "    The pairs are sorted by the combined frequency of trips passing through both stops.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains:\n",
    "              - pair (tuple): A tuple with two stop IDs (stop_1, stop_2).\n",
    "              - route_id (int): The ID of the route connecting the two stops.\n",
    "    \"\"\"\n",
    "    connections = {}\n",
    "    \n",
    "    for route_id, stops in route_to_stops.items():\n",
    "        for i in range(len(stops) - 1):\n",
    "            current_stop = stops[i]\n",
    "            next_stop = stops[i + 1]\n",
    "            \n",
    "            # same order for consistency\n",
    "            stop_pair = (current_stop, next_stop) if current_stop < next_stop else (next_stop, current_stop)\n",
    "\n",
    "            \n",
    "            # Add the route to this pair's list of routes\n",
    "            if stop_pair not in connections:\n",
    "                connections[stop_pair] = []\n",
    "            connections[stop_pair].append(route_id)\n",
    "    \n",
    "    result = []\n",
    "    for stop_pair, routes in connections.items():\n",
    "        if len(routes) == 1:\n",
    "            result.append((stop_pair, routes[0]))\n",
    "    \n",
    "    return result\n",
    "    pass  # Implementation here\n",
    "\n",
    "# Function to get merged fare DataFrame\n",
    "# No need to change this function\n",
    "def get_merged_fare_df():\n",
    "    \"\"\"\n",
    "    Retrieve the merged fare DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The merged fare DataFrame containing fare rules and attributes.\n",
    "    \"\"\"\n",
    "    global merged_fare_df\n",
    "    return merged_fare_df\n",
    "\n",
    "# Visualize the stop-route graph interactively\n",
    "def visualize_stop_route_graph_interactive(route_to_stops):\n",
    "    \"\"\"\n",
    "    Visualize the stop-route graph using Plotly for interactive exploration.\n",
    "\n",
    "    Args:\n",
    "        route_to_stops (dict): A dictionary mapping route IDs to lists of stops.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Step 1: Create a network graph\n",
    "    grph = nx.Graph()\n",
    "    \n",
    "    # Step 2: Add edges (connections between stops) from each route\n",
    "    edge_colors = []\n",
    "    edge_labels = []\n",
    "    \n",
    "    unique_routes = list(route_to_stops.keys())\n",
    "    color_palette = plt.cm.get_cmap('hsv')(np.linspace(0, 1, len(unique_routes)))\n",
    "    \n",
    "    rt_color_map = {}\n",
    "    for i in range (len(unique_routes)):\n",
    "        route_id = unique_routes[i]\n",
    "        r, g, b, _ = color_palette[i]\n",
    "        \n",
    "        color_string = f'rgb({int(r*255)},{int(g*255)},{int(b*255)})'\n",
    "        rt_color_map[route_id] = color_string\n",
    "    \n",
    "    for route_id, stops_on_route in route_to_stops.items():\n",
    "        route_name = df_routes[df_routes['route_id'] == route_id]['route_long_name'].iloc[0]\n",
    "        for i in range(len(stops_on_route) - 1):\n",
    "            current_stop = stops_on_route[i]\n",
    "            next_stop = stops_on_route[i + 1]\n",
    "            \n",
    "            grph.add_edge(current_stop, next_stop)\n",
    "            \n",
    "            edge_colors.append(rt_color_map[route_id])\n",
    "            edge_labels.append(f\"Route: {route_name}\")\n",
    "        \n",
    "    # Step 3: Calculate state_positions for the graph\n",
    "    stop_positions = nx.shell_layout(grph)\n",
    "    \n",
    "    # Step 4: Create edge trace\n",
    "    edge_trace = []\n",
    "    for i in range (len(grph.edges())):\n",
    "        edge = list(grph.edges())[i]\n",
    "        color = edge_colors[i]\n",
    "        label = edge_labels[i]\n",
    "        \n",
    "        x0, y0 = stop_positions[edge[0]]\n",
    "        x1, y1 = stop_positions[edge[1]]\n",
    "        \n",
    "        \n",
    "        edge_trace.append(\n",
    "            go.Scatter(\n",
    "                x=[x0, x1, None],\n",
    "                y=[y0, y1, None],\n",
    "                line=dict(width=2, color=color),\n",
    "                hoverinfo='text',\n",
    "                text=label,\n",
    "                mode='lines'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    # Step 5: Create node trace\n",
    "    node_x = []\n",
    "    node_y = []\n",
    "    node_text = []\n",
    "    \n",
    "    for node in grph.nodes():\n",
    "        x, y = stop_positions[node]\n",
    "        node_x.append(x)\n",
    "        node_y.append(y)\n",
    "        # Get stop name for hover text\n",
    "        stop_name = df_stops[df_stops['stop_id'] == node]['stop_name'].iloc[0]\n",
    "        node_text.append(f\"Stop: {stop_name}<br>ID: {node}\")\n",
    "    \n",
    "    node_trace = go.Scatter(\n",
    "        x=node_x,\n",
    "        y=node_y,\n",
    "        mode='markers+text',\n",
    "        hoverinfo='text',\n",
    "        text=node_text,\n",
    "        marker=dict(\n",
    "            size=10,\n",
    "            color='lightblue',\n",
    "            line=dict(width=2, color='darkblue')\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Step 6: Create the figure\n",
    "    fig = go.Figure(data=edge_trace + [node_trace],\n",
    "                   layout=go.Layout(\n",
    "                       title='Transit Network Map',\n",
    "                       showlegend=False,\n",
    "                       hovermode='closest',\n",
    "                       margin=dict(b=0, l=0, r=0, t=40),\n",
    "                       xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                       yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                       plot_bgcolor='white'\n",
    "                   ))\n",
    "    \n",
    "    # Add a legend showing route colors\n",
    "    for route_id in unique_routes:\n",
    "        route_name = df_routes[df_routes['route_id'] == route_id]['route_long_name'].iloc[0]\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[None],\n",
    "            y=[None],\n",
    "            mode='lines',\n",
    "            name=route_name,\n",
    "            line=dict(color=rt_color_map[route_id], width=2),\n",
    "            showlegend=True\n",
    "        ))\n",
    "    \n",
    "    # Step 7: Show the plot\n",
    "    fig.show()\n",
    "    pass  # Implementation here\n",
    "\n",
    "# Brute-Force Approach for finding direct routes\n",
    "def direct_route_brute_force(start_stop, end_stop):\n",
    "    \"\"\"\n",
    "    Find all valid routes between two stops using a brute-force method.\n",
    "\n",
    "    Args:\n",
    "        start_stop (int): The ID of the starting stop.\n",
    "        end_stop (int): The ID of the ending stop.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of route IDs (int) that connect the two stops directly.\n",
    "    \"\"\"\n",
    "    \n",
    "    dir_routes = []\n",
    "    for route_id, stops in route_to_stops.items():\n",
    "        if start_stop in stops and end_stop in stops:\n",
    "            # Check if start_stop comes before end_stop in the sequence\n",
    "            if stops.index(start_stop) < stops.index(end_stop):\n",
    "                dir_routes.append(route_id)\n",
    "    return dir_routes\n",
    "    \n",
    "    \n",
    "    \n",
    "    # dir_routes = []\n",
    "    # for route_id, stops in route_to_stops.items():\n",
    "    #     start_indexes = [i for i, stop in enumerate(stops) if stop == start_stop]\n",
    "    #     end_indexes = [i for i, stop in enumerate(stops) if stop == end_stop]\n",
    "    #     for start_idx in start_indexes:\n",
    "    #         for end_idx in end_indexes:\n",
    "    #             if end_idx > start_idx:\n",
    "    #                 dir_routes.append(route_id)\n",
    "    #                 break\n",
    "    #         if route_id in dir_routes:\n",
    "    #             break\n",
    "            \n",
    "    # return sorted(dir_routes)\n",
    "    \n",
    "    pass  # Implementation here\n",
    "\n",
    "# Initialize Datalog predicates for reasoning\n",
    "pyDatalog.create_terms('RouteHasStop, DirectRoute, OptimalRoute, X, Y, Z, R, R1, R2')  \n",
    "def initialize_datalog():\n",
    "    \"\"\"\n",
    "    Initialize Datalog terms and predicates for reasoning about routes and stops.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    pyDatalog.clear()  # Clear previous terms\n",
    "    print(\"Terms initialized: DirectRoute, RouteHasStop, OptimalRoute\")  # Confirmation print\n",
    "\n",
    "    # Define Datalog predicates\n",
    "\n",
    "    create_kb()  # Populate the knowledge base\n",
    "    add_route_data(route_to_stops)  # Add route data to Datalog\n",
    "    \n",
    "    \n",
    "# Adding route data to Datalog\n",
    "def add_route_data(route_to_stops):\n",
    "    \"\"\"\n",
    "    Add the route data to Datalog for reasoning.\n",
    "\n",
    "    Args:\n",
    "        route_to_stops (dict): A dictionary mapping route IDs to lists of stops.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    for route_id, stops in route_to_stops.items():\n",
    "        for stop_id in stops:\n",
    "            +RouteHasStop(route_id, stop_id)\n",
    "\n",
    "# Function to query direct routes between two stops\n",
    "def query_direct_routes(start, end):\n",
    "    \"\"\"\n",
    "    Query for direct routes between two stops.\n",
    "\n",
    "    Args:\n",
    "        start (int): The ID of the starting stop.\n",
    "        end (int): The ID of the ending stop.\n",
    "\n",
    "    Returns:\n",
    "        list: A sorted list of route IDs (str) connecting the two stops.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Query for routes that contain both start and end stops\n",
    "    query_result = pyDatalog.ask(f'RouteHasStop(R, {start}) & RouteHasStop(R, {end})')\n",
    "    \n",
    "    # Process the results, assuming each answer contains a single route_id\n",
    "    if query_result:\n",
    "        return sorted(set(route_id[0] for route_id in query_result.answers))\n",
    "    return []\n",
    "    \n",
    "    pass  # Implementation here\n",
    "\n",
    "# Forward chaining for optimal route planning\n",
    "def forward_chaining(start_stop_id, end_stop_id, stop_id_to_include, max_transfers):\n",
    "    \"\"\"\n",
    "    Perform forward chaining to find optimal routes considering transfers.\n",
    "\n",
    "    Args:\n",
    "        start_stop_id (int): The starting stop ID.\n",
    "        end_stop_id (int): The ending stop ID.\n",
    "        stop_id_to_include (int): The stop ID where a transfer occurs.\n",
    "        max_transfers (int): The maximum number of transfers allowed.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of unique paths (list of tuples) that satisfy the criteria, where each tuple contains:\n",
    "              - route_id (int): The ID of the route.\n",
    "              - stop_id (int): The ID of the stop.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    pass  # Implementation here\n",
    "\n",
    "# Backward chaining for optimal route planning\n",
    "def backward_chaining(start_stop_id, end_stop_id, stop_id_to_include, max_transfers):\n",
    "    \"\"\"\n",
    "    Perform backward chaining to find optimal routes considering transfers.\n",
    "\n",
    "    Args:\n",
    "        start_stop_id (int): The starting stop ID.\n",
    "        end_stop_id (int): The ending stop ID.\n",
    "        stop_id_to_include (int): The stop ID where a transfer occurs.\n",
    "        max_transfers (int): The maximum number of transfers allowed.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of unique paths (list of tuples) that satisfy the criteria, where each tuple contains:\n",
    "              - route_id (int): The ID of the route.\n",
    "              - stop_id (int): The ID of the stop.\n",
    "    \"\"\"\n",
    "    pass  # Implementation here\n",
    "\n",
    "# PDDL-style planning for route finding\n",
    "def pddl_planning(start_stop_id, end_stop_id, stop_id_to_include, max_transfers):\n",
    "    \"\"\"\n",
    "    Implement PDDL-style planning to find routes with optional transfers.\n",
    "\n",
    "    Args:\n",
    "        start_stop_id (int): The starting stop ID.\n",
    "        end_stop_id (int): The ending stop ID.\n",
    "        stop_id_to_include (int): The stop ID for a transfer.\n",
    "        max_transfers (int): The maximum number of transfers allowed.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of unique paths (list of tuples) that satisfy the criteria, where each tuple contains:\n",
    "              - route_id (int): The ID of the route.\n",
    "              - stop_id (int): The ID of the stop.\n",
    "    \"\"\"\n",
    "    pass  # Implementation here\n",
    "\n",
    "# Function to filter fare data based on an initial fare limit\n",
    "def prune_data(merged_fare_df, initial_fare):\n",
    "    \"\"\"\n",
    "    Filter fare data based on an initial fare limit.\n",
    "\n",
    "    Args:\n",
    "        merged_fare_df (DataFrame): The merged fare DataFrame.\n",
    "        initial_fare (float): The maximum fare allowed.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A filtered DataFrame containing only routes within the fare limit.\n",
    "    \"\"\"\n",
    "    pass  # Implementation here\n",
    "\n",
    "# Pre-computation of Route Summary\n",
    "def compute_route_summary(pruned_df):\n",
    "    \"\"\"\n",
    "    Generate a summary of routes based on fare information.\n",
    "\n",
    "    Args:\n",
    "        pruned_df (DataFrame): The filtered DataFrame containing fare information.\n",
    "\n",
    "    Returns:\n",
    "        dict: A summary of routes with the following structure:\n",
    "              {\n",
    "                  route_id (int): {\n",
    "                      'min_price': float,          # The minimum fare for the route\n",
    "                      'stops': set                # A set of stop IDs for that route\n",
    "                  }\n",
    "              }\n",
    "    \"\"\"\n",
    "    pass  # Implementation here\n",
    "\n",
    "# BFS for optimized route planning\n",
    "def bfs_route_planner_optimized(start_stop_id, end_stop_id, initial_fare, route_summary, max_transfers=3):\n",
    "    \"\"\"\n",
    "    Use Breadth-First Search (BFS) to find the optimal route while considering fare constraints.\n",
    "\n",
    "    Args:\n",
    "        start_stop_id (int): The starting stop ID.\n",
    "        end_stop_id (int): The ending stop ID.\n",
    "        initial_fare (float): The available fare for the trip.\n",
    "        route_summary (dict): A summary of routes with fare and stop information.\n",
    "        max_transfers (int): The maximum number of transfers allowed (default is 3).\n",
    "\n",
    "    Returns:\n",
    "        list: A list representing the optimal route with stops and routes taken, structured as:\n",
    "              [\n",
    "                  (route_id (int), stop_id (int)),  # Tuple for each stop taken in the route\n",
    "                  ...\n",
    "              ]\n",
    "    \"\"\"\n",
    "    pass  # Implementation here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sample public test inputs with expected outputs explicitly defined\n",
    "test_inputs = {\n",
    "    \"direct_route\": [\n",
    "        ((2573, 1177), [10001, 1117, 1407]),  # Input -> Expected output\n",
    "        ((2001, 2005), [10001, 1151])\n",
    "    ],\n",
    "\n",
    "    \"forward_chaining\": [\n",
    "        ((22540, 2573, 4686, 1), [(10153, 4686, 1407)]),\n",
    "        ((951, 340, 300, 1), [(294, 300, 712), (10453, 300, 712), (1211, 300, 712), (1158, 300, 712), \n",
    "                              (37, 300, 712), (1571, 300, 712), (49, 300, 712), (387, 300, 712), \n",
    "                              (1206, 300, 712), (1038, 300, 712), (10433, 300, 712), (121, 300, 712)])\n",
    "    ],\n",
    "    \"backward_chaining\": [\n",
    "        ((2573, 22540, 4686, 1), [(1407, 4686, 10153)]),\n",
    "        ((340, 951, 300, 1), [(712, 300, 121), (712, 300, 1211), (712, 300, 37), (712, 300, 387),\n",
    "                              (712, 300, 49), (712, 300, 10453), (712, 300, 1038), (712, 300, 10433),\n",
    "                              (712, 300, 1571)])\n",
    "    ],\n",
    "    \"pddl_planning\": [\n",
    "        ((22540, 2573, 4686, 1), [(10153, 4686, 1407)]),\n",
    "        ((951, 340, 300, 1), [(294, 300, 712), (10453, 300, 712), (1211, 300, 712), (1158, 300, 712), \n",
    "                              (37, 300, 712), (1571, 300, 712), (49, 300, 712), (387, 300, 712), \n",
    "                              (1206, 300, 712), (1038, 300, 712), (10433, 300, 712), (121, 300, 712)])\n",
    "    ],\n",
    "    \"bfs_route\": [\n",
    "        ((22540, 2573, 10, 3), [(10153, 4686), (1407, 2573)]),\n",
    "        ((4012, 4013, 10, 3), [(10004, 4013)])\n",
    "    ],\n",
    "\n",
    "    ### NOTE: The below values are just dummy values, the actual values are might differ! \n",
    "    \"busiest_routes\": [\n",
    "        [(123, 456), (789, 234), (567, 235), (3456, 897), (345, 345)]\n",
    "    ],\n",
    "    \"most_frequent_stops\": [\n",
    "        [(456, 456), (234, 765), (234, 765), (234, 657765), (3252, 35634)]\n",
    "    ],\n",
    "    \"busiest_stops\": [\n",
    "        [(432243, 14543), (454235, 2452), (2452, 2454), (78568, 24352), (42352, 24532)]\n",
    "    ],\n",
    "    \"stops_with_one_direct_route\": [\n",
    "        [((24527, 676), 542), ((243535, 8768), 2456), ((43262, 564), 65437),\n",
    "         ((256, 56), 245), ((266, 256), 78)]\n",
    "    ]\n",
    "}\n",
    "\n",
    "def check_output(expected, actual):\n",
    "    \"\"\"Function to compare expected and actual outputs.\"\"\"\n",
    "    return set(expected) == set(actual)\n",
    "\n",
    "def test_direct_route_brute_force():\n",
    "    for (start_stop, end_stop), expected_output in test_inputs[\"direct_route\"]:\n",
    "        actual_output = direct_route_brute_force(start_stop, end_stop)\n",
    "        print(f\"Test direct_route_brute_force ({start_stop}, {end_stop}): \", \n",
    "              \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "def test_query_direct_routes():\n",
    "    for (start_stop, end_stop), expected_output in test_inputs[\"direct_route\"]:\n",
    "        actual_output = query_direct_routes(start_stop, end_stop)\n",
    "        print(f\"Test query_direct_routes ({start_stop}, {end_stop}): \", \n",
    "              \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "def test_forward_chaining():\n",
    "    for (start_stop, end_stop, via_stop, max_transfers), expected_output in test_inputs[\"forward_chaining\"]:\n",
    "        actual_output = forward_chaining(start_stop, end_stop, via_stop, max_transfers)\n",
    "        print(f\"Test forward_chaining ({start_stop}, {end_stop}, {via_stop}, {max_transfers}): \", \n",
    "              \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "def test_backward_chaining():\n",
    "    for (end_stop, start_stop, via_stop, max_transfers), expected_output in test_inputs[\"backward_chaining\"]:\n",
    "        actual_output = backward_chaining(start_stop, end_stop, via_stop, max_transfers)\n",
    "        print(f\"Test backward_chaining ({start_stop}, {end_stop}, {via_stop}, {max_transfers}): \", \n",
    "              \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "def test_pddl_planning():\n",
    "    for (start_stop, end_stop, via_stop, max_transfers), expected_output in test_inputs[\"pddl_planning\"]:\n",
    "        actual_output = pddl_planning(start_stop, end_stop, via_stop, max_transfers)\n",
    "        print(f\"Test pddl_planning ({start_stop}, {end_stop}, {via_stop}, {max_transfers}): \", \n",
    "              \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "def test_bfs_route_planner():\n",
    "    for (start_stop, end_stop, initial_fare, max_transfers), expected_output in test_inputs[\"bfs_route\"]:\n",
    "        pruned_df = prune_data(merged_fare_df, initial_fare)\n",
    "        route_summary = compute_route_summary(pruned_df)\n",
    "        actual_output = bfs_route_planner_optimized(start_stop, end_stop, initial_fare, route_summary, max_transfers)\n",
    "        print(f\"Test bfs_route_planner_optimized ({start_stop}, {end_stop}, {initial_fare}, {max_transfers}): \", \n",
    "              \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "# New test functions for the additional queries\n",
    "\n",
    "def test_get_busiest_routes():\n",
    "    expected_output = test_inputs[\"busiest_routes\"][0]\n",
    "    actual_output = get_busiest_routes()\n",
    "    print(f\"Test get_busiest_routes: \", \n",
    "          \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "def test_get_most_frequent_stops():\n",
    "    expected_output = test_inputs[\"most_frequent_stops\"][0]\n",
    "    actual_output = get_most_frequent_stops()\n",
    "    print(f\"Test get_most_frequent_stops: \", \n",
    "          \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "def test_get_top_5_busiest_stops():\n",
    "    expected_output = test_inputs[\"busiest_stops\"][0]\n",
    "    actual_output = get_top_5_busiest_stops()\n",
    "    print(f\"Test get_top_5_busiest_stops: \", \n",
    "          \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "def test_get_stops_with_one_direct_route():\n",
    "    expected_output = test_inputs[\"stops_with_one_direct_route\"][0]\n",
    "    actual_output = get_stops_with_one_direct_route()\n",
    "    print(f\"Test get_stops_with_one_direct_route: \", \n",
    "          \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     create_kb()  # Ensure the data is loaded before testing\n",
    "#     merged_fare_df = get_merged_fare_df()  # Use the function to retrieve the DataFrame\n",
    "#     initialize_datalog()\n",
    "    \n",
    "#     # Run all tests\n",
    "#     test_direct_route_brute_force()\n",
    "#     test_query_direct_routes()\n",
    "#     test_forward_chaining()\n",
    "#     test_backward_chaining()\n",
    "#     test_pddl_planning()\n",
    "#     test_bfs_route_planner()\n",
    "    \n",
    "#     # Run additional tests for the new queries\n",
    "#     test_get_busiest_routes()\n",
    "#     test_get_most_frequent_stops()\n",
    "#     test_get_top_5_busiest_stops()\n",
    "#     test_get_stops_with_one_direct_route()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary functions from code_changeRollNumber.py\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "route_to_stops = defaultdict(list)  # Maps route_id to an ordered list of stop_ids\n",
    "trip_to_route = {}  # Maps trip_id to route_id\n",
    "stop_trip_count = defaultdict(int)  # Maps stop_id to count of trips stopping there\n",
    "fare_rules = {}  # Maps route_id to fare information\n",
    "\n",
    "# from code_changeRollNumber import (\n",
    "#     direct_route_brute_force,\n",
    "#     query_direct_routes,\n",
    "#     forward_chaining,\n",
    "#     backward_chaining,\n",
    "#     pddl_planning,\n",
    "#     bfs_route_planner_optimized,\n",
    "#     create_kb,  # Ensure the data is loaded for testing\n",
    "#     prune_data,\n",
    "#     initialize_datalog,\n",
    "#     get_merged_fare_df,\n",
    "#     compute_route_summary,\n",
    "#     get_busiest_routes,  # New functions for testing\n",
    "#     get_most_frequent_stops,\n",
    "#     get_top_5_busiest_stops,\n",
    "#     get_stops_with_one_direct_route\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terms initialized: DirectRoute, RouteHasStop, OptimalRoute\n"
     ]
    }
   ],
   "source": [
    "create_kb()  # Ensure the data is loaded before testing\n",
    "merged_fare_df = get_merged_fare_df()  # Use the function to retrieve the DataFrame\n",
    "initialize_datalog()\n",
    "    \n",
    "#     # Run all tests\n",
    "#     test_direct_route_brute_force()\n",
    "#     test_query_direct_routes()\n",
    "#     test_forward_chaining()\n",
    "#     test_backward_chaining()\n",
    "#     test_pddl_planning()\n",
    "#     test_bfs_route_planner()\n",
    "    \n",
    "#     # Run additional tests for the new queries\n",
    "#     test_get_busiest_routes()\n",
    "#     test_get_most_frequent_stops()\n",
    "#     test_get_top_5_busiest_stops()\n",
    "#     test_get_stops_with_one_direct_route()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test direct_route_brute_force (2573, 1177):  Pass\n",
      "Test direct_route_brute_force (2001, 2005):  Pass\n",
      "Test query_direct_routes (2573, 1177):  Pass\n",
      "Test query_direct_routes (2001, 2005):  Pass\n"
     ]
    }
   ],
   "source": [
    "test_direct_route_brute_force()\n",
    "test_query_direct_routes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_chaining(start_stop_id, end_stop_id, stop_id_to_include, max_transfers):\n",
    "    \"\"\"\n",
    "    Find optimal routes using Forward Chaining.\n",
    "\n",
    "    Args:\n",
    "        start_stop_id (int): Starting stop ID.\n",
    "        end_stop_id (int): Ending stop ID.\n",
    "        stop_id_to_include (int): Intermediate stop ID to include.\n",
    "        max_transfers (int): Maximum number of transfers allowed.\n",
    "\n",
    "    Returns:\n",
    "        list: Optimal routes satisfying constraints.\n",
    "    \"\"\"\n",
    "    # Initialize Datalog predicates\n",
    "    initialize_datalog()\n",
    "\n",
    "    # Define rules for optimal route planning\n",
    "    pyDatalog.create_terms('RouteHasStop, DirectRoute, OptimalRoute, X, Y, Z, R, R1, R2')\n",
    "    @pyDatalog.program()\n",
    "    def optimal_route_program():\n",
    "        +OptimalRoute(X, Y, Z) <= RouteHasStop(R, X) & RouteHasStop(R, Y) & RouteHasStop(R, Z)\n",
    "        +OptimalRoute(X, Y, Z) <= RouteHasStop(R1, X) & RouteHasStop(R2, Y) & RouteHasStop(R2, Z) & DirectRoute(R1, R2)\n",
    "\n",
    "    optimal_route_program()\n",
    "\n",
    "    # Query for optimal routes\n",
    "    query = f'OptimalRoute({start_stop_id}, {stop_id_to_include}, {end_stop_id})'\n",
    "    results = pyDatalog.ask(query)\n",
    "\n",
    "    # Process results\n",
    "    optimal_routes = []\n",
    "    for result in results.answers:\n",
    "        route_id = result[0]\n",
    "        optimal_routes.append(route_id)\n",
    "\n",
    "    # Filter results based on max_transfers\n",
    "    filtered_routes = []\n",
    "    for route_id in optimal_routes:\n",
    "        transfers = 0\n",
    "        stops = route_to_stops[route_id]\n",
    "        start_index = stops.index(start_stop_id)\n",
    "        end_index = stops.index(end_stop_id)\n",
    "        via_index = stops.index(stop_id_to_include)\n",
    "        transfers += abs(start_index - via_index)\n",
    "        transfers += abs(via_index - end_index)\n",
    "        if transfers <= max_transfers:\n",
    "            filtered_routes.append(route_id)\n",
    "\n",
    "    return filtered_routes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terms initialized: DirectRoute, RouteHasStop, OptimalRoute\n"
     ]
    },
    {
     "ename": "DatalogError",
     "evalue": "Cannot assert a fact containing Variables\n        +OptimalRoute(X, Y, Z) <= RouteHasStop(R, X) & RouteHasStop(R, Y) & RouteHasStop(R, Z)\nin line 1 of optimal_route_program",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDatalogError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_forward_chaining\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# test_backward_chaining()\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 65\u001b[0m, in \u001b[0;36mtest_forward_chaining\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_forward_chaining\u001b[39m():\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (start_stop, end_stop, via_stop, max_transfers), expected_output \u001b[38;5;129;01min\u001b[39;00m test_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward_chaining\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m---> 65\u001b[0m         actual_output \u001b[38;5;241m=\u001b[39m \u001b[43mforward_chaining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvia_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_transfers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest forward_chaining (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_stop\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_stop\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvia_stop\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_transfers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     67\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_output(expected_output, actual_output) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFail (Expected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_output\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactual_output\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[28], line 19\u001b[0m, in \u001b[0;36mforward_chaining\u001b[0;34m(start_stop_id, end_stop_id, stop_id_to_include, max_transfers)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Define rules for optimal route planning\u001b[39;00m\n\u001b[1;32m     18\u001b[0m pyDatalog\u001b[38;5;241m.\u001b[39mcreate_terms(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRouteHasStop, DirectRoute, OptimalRoute, X, Y, Z, R, R1, R2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;129;43m@pyDatalog\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43moptimal_route_program\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mOptimalRoute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mRouteHasStop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mRouteHasStop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mRouteHasStop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mOptimalRoute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mRouteHasStop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mRouteHasStop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mRouteHasStop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mDirectRoute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyDatalog/pyParser.py:830\u001b[0m, in \u001b[0;36madd_program\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    827\u001b[0m func_name \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m PY3 \u001b[38;5;28;01melse\u001b[39;00m func\u001b[38;5;241m.\u001b[39mfunc_name\n\u001b[1;32m    828\u001b[0m defined \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(code\u001b[38;5;241m.\u001b[39mco_varnames)\u001b[38;5;241m.\u001b[39munion(\u001b[38;5;28mset\u001b[39m(newglobals\u001b[38;5;241m.\u001b[39mkeys())) \u001b[38;5;66;03m# local variables and global variables\u001b[39;00m\n\u001b[0;32m--> 830\u001b[0m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewglobals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefined\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _NoCallFunction()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyDatalog/pyParser.py:806\u001b[0m, in \u001b[0;36mload\u001b[0;34m(code, newglobals, defined, function)\u001b[0m\n\u001b[1;32m    804\u001b[0m e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m    805\u001b[0m e\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (e\u001b[38;5;241m.\u001b[39mvalue, lines[e\u001b[38;5;241m.\u001b[39mlineno\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 806\u001b[0m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyDatalog/util.py:104\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyDatalog/pyParser.py:793\u001b[0m, in \u001b[0;36mload\u001b[0;34m(code, newglobals, defined, function)\u001b[0m\n\u001b[1;32m    791\u001b[0m     add_symbols((name,), newglobals)\n\u001b[1;32m    792\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 793\u001b[0m     util\u001b[38;5;241m.\u001b[39mexec_(code, newglobals)\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m util\u001b[38;5;241m.\u001b[39mDatalogError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    795\u001b[0m     e\u001b[38;5;241m.\u001b[39mfunction \u001b[38;5;241m=\u001b[39m function\n",
      "File \u001b[0;32moptimal_route_program:1\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyDatalog/pyParser.py:584\u001b[0m, in \u001b[0;36mQuery.__pos__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m unary + means insert into database as fact \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variables():\n\u001b[0;32m--> 584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m util\u001b[38;5;241m.\u001b[39mDatalogError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot assert a fact containing Variables\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    585\u001b[0m clause \u001b[38;5;241m=\u001b[39m pyEngine\u001b[38;5;241m.\u001b[39mClause(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlua, [])\n\u001b[1;32m    586\u001b[0m pyEngine\u001b[38;5;241m.\u001b[39massert_(clause)\n",
      "\u001b[0;31mDatalogError\u001b[0m: Cannot assert a fact containing Variables\n        +OptimalRoute(X, Y, Z) <= RouteHasStop(R, X) & RouteHasStop(R, Y) & RouteHasStop(R, Z)\nin line 1 of optimal_route_program"
     ]
    }
   ],
   "source": [
    "test_forward_chaining()\n",
    "# test_backward_chaining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate for AI Assignment â€” Knowledge Representation, Reasoning and Planning\n",
    "# CSE 643\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import networkx as nx\n",
    "from pyDatalog import pyDatalog\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "## ****IMPORTANT****\n",
    "## Don't import or use any other libraries other than defined above\n",
    "## Otherwise your code file will be rejected in the automated testing\n",
    "\n",
    "# ------------------ Global Variables ------------------\n",
    "route_to_stops = defaultdict(list)  # Mapping of route IDs to lists of stops\n",
    "trip_to_route = {}                   # Mapping of trip IDs to route IDs\n",
    "stop_trip_count = defaultdict(int)    # Count of trips for each stop\n",
    "fare_rules = {}                      # Mapping of route IDs to fare information\n",
    "merged_fare_df = None                # To be initialized in create_kb()\n",
    "\n",
    "# Load static data from GTFS (General Transit Feed Specification) files\n",
    "df_stops = pd.read_csv('GTFS/stops.txt')\n",
    "df_routes = pd.read_csv('GTFS/routes.txt')\n",
    "df_stop_times = pd.read_csv('GTFS/stop_times.txt')\n",
    "df_fare_attributes = pd.read_csv('GTFS/fare_attributes.txt')\n",
    "df_trips = pd.read_csv('GTFS/trips.txt')\n",
    "df_fare_rules = pd.read_csv('GTFS/fare_rules.txt')\n",
    "\n",
    "# ------------------ Function Definitions ------------------\n",
    "\n",
    "# Function to create knowledge base from the loaded data\n",
    "def create_kb():\n",
    "    \"\"\"\n",
    "    Create knowledge base by populating global variables with information from loaded datasets.\n",
    "    It establishes the relationships between routes, trips, stops, and fare rules.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    global route_to_stops, trip_to_route, stop_trip_count, fare_rules, merged_fare_df\n",
    "\n",
    "    # Create trip_id to route_id mapping\"\"\"\n",
    "    trip_to_route = defaultdict(list)\n",
    "    for _, row in df_trips.iterrows():\n",
    "        trip_to_route[row['trip_id']].append(row['route_id'])\n",
    "        \n",
    "    # Map route_id to a list of stops in order of their sequence\"\"\"\n",
    "    route_to_stops = defaultdict(list)\n",
    "    sorted_stop_times = df_stop_times.sort_values(['trip_id', 'stop_sequence'])\n",
    "    sorted_stop_times.head\n",
    "    for trip_id, stop_grp in sorted_stop_times.groupby('trip_id'):\n",
    "        if trip_id in trip_to_route:\n",
    "            route_id = trip_to_route[trip_id][0]\n",
    "            stops = stop_grp['stop_id'].to_list()\n",
    "            route_to_stops[route_id].extend(stops)\n",
    "            \n",
    "    # Ensure each route only has unique stops\"\"\"\n",
    "    for route_id in route_to_stops:\n",
    "        # Use dict.fromkeys() to preserve order while removing duplicates\n",
    "        route_to_stops[route_id] = list(dict.fromkeys(route_to_stops[route_id]))\n",
    "    \n",
    "    # Count trips per stop\"\"\"\n",
    "    stop_trip_count = dict(df_stop_times['stop_id'].value_counts())\n",
    "\n",
    "    # Create fare rules for routes\n",
    "    fare_rules = {}\n",
    "    for i in range(len(df_fare_rules['route_id'])):\n",
    "        route_id = df_fare_rules['route_id'][i]\n",
    "        fare_id = df_fare_rules['fare_id'][i]\n",
    "\n",
    "        if route_id not in fare_rules:\n",
    "            fare_rules[route_id] = []\n",
    "\n",
    "        fare_rules[route_id].append(fare_id)\n",
    "\n",
    "    # Merge fare rules and attributes into a single DataFrame\n",
    "    merged_fare_df = pd.merge(\n",
    "        df_fare_rules,\n",
    "        df_fare_attributes,\n",
    "        on='fare_id',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "# Function to find the top 5 busiest routes based on the number of trips\n",
    "def get_busiest_routes():\n",
    "    \"\"\"\n",
    "    Identify the top 5 busiest routes based on trip counts.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains:\n",
    "              - route_id (int): The ID of the route.\n",
    "              - trip_count (int): The number of trips for that route.\n",
    "    \"\"\"\n",
    "    route_trip_counts = defaultdict(int)\n",
    "    for trip_id, routes in trip_to_route.items():\n",
    "        # Since we stored routes as a list in trip_to_route, take the first route\n",
    "        route_id = routes[0]\n",
    "        route_trip_counts[route_id] += 1\n",
    "    \n",
    "    res = sorted(route_trip_counts.items(), key = lambda ele: ele[1], reverse = True)\n",
    "    \n",
    "    # Return top 5 routes\n",
    "    return res[:5]\n",
    "    pass  # Implementation here\n",
    "\n",
    "# Function to find the top 5 stops with the most frequent trips\n",
    "def get_most_frequent_stops():\n",
    "    \"\"\"\n",
    "    Identify the top 5 stops with the highest number of trips.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains:\n",
    "              - stop_id (int): The ID of the stop.\n",
    "              - trip_count (int): The number of trips for that stop.\n",
    "    \"\"\"\n",
    "    res = sorted(stop_trip_count.items(), key = lambda ele: ele[1], reverse = True)\n",
    "    \n",
    "    # Return top 5 routes\n",
    "    return res[:5]\n",
    "    pass  # Implementation here\n",
    "\n",
    "# Function to find the top 5 busiest stops based on the number of routes passing through them\n",
    "def get_top_5_busiest_stops():\n",
    "    \"\"\"\n",
    "    Identify the top 5 stops with the highest number of different routes.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains:\n",
    "              - stop_id (int): The ID of the stop.\n",
    "              - route_count (int): The number of routes passing through that stop.\n",
    "    \"\"\"\n",
    "    stop_routes = defaultdict(set)\n",
    "    for route_id, stops in route_to_stops.items():\n",
    "        for stop_id in stops:\n",
    "            stop_routes[stop_id].add(route_id)\n",
    "            \n",
    "    stop_counts = []\n",
    "    for stop_id, routes in stop_routes.items():\n",
    "        route_count = len(routes)\n",
    "        stop_counts.append((stop_id, route_count))\n",
    "\n",
    "    res = sorted(stop_counts, key = lambda ele: ele[1], reverse = True)\n",
    "    \n",
    "    return res[:5]\n",
    "    pass  # Implementation here\n",
    "\n",
    "# Function to identify the top 5 pairs of stops with only one direct route between them\n",
    "def get_stops_with_one_direct_route():\n",
    "    \"\"\"\n",
    "    Identify the top 5 pairs of consecutive stops (start and end) connected by exactly one direct route. \n",
    "    The pairs are sorted by the combined frequency of trips passing through both stops.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains:\n",
    "              - pair (tuple): A tuple with two stop IDs (stop_1, stop_2).\n",
    "              - route_id (int): The ID of the route connecting the two stops.\n",
    "    \"\"\"\n",
    "    connections = {}\n",
    "    \n",
    "    for route_id, stops in route_to_stops.items():\n",
    "        for i in range(len(stops) - 1):\n",
    "            current_stop = stops[i]\n",
    "            next_stop = stops[i + 1]\n",
    "            \n",
    "            # same order for consistency\n",
    "            stop_pair = (current_stop, next_stop) if current_stop < next_stop else (next_stop, current_stop)\n",
    "\n",
    "            \n",
    "            # Add the route to this pair's list of routes\n",
    "            if stop_pair not in connections:\n",
    "                connections[stop_pair] = []\n",
    "            connections[stop_pair].append(route_id)\n",
    "    \n",
    "    result = []\n",
    "    for stop_pair, routes in connections.items():\n",
    "        if len(routes) == 1:\n",
    "            result.append((stop_pair, routes[0]))\n",
    "    \n",
    "    return result\n",
    "    pass  # Implementation here\n",
    "\n",
    "# Function to get merged fare DataFrame\n",
    "# No need to change this function\n",
    "def get_merged_fare_df():\n",
    "    \"\"\"\n",
    "    Retrieve the merged fare DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The merged fare DataFrame containing fare rules and attributes.\n",
    "    \"\"\"\n",
    "    global merged_fare_df\n",
    "    return merged_fare_df\n",
    "\n",
    "# Visualize the stop-route graph interactively\n",
    "def visualize_stop_route_graph_interactive(route_to_stops):\n",
    "    \"\"\"\n",
    "    Visualize the stop-route graph using Plotly for interactive exploration.\n",
    "\n",
    "    Args:\n",
    "        route_to_stops (dict): A dictionary mapping route IDs to lists of stops.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Step 1: Create a network graph\n",
    "    grph = nx.Graph()\n",
    "    \n",
    "    # Step 2: Add edges (connections between stops) from each route\n",
    "    edge_colors = []\n",
    "    edge_labels = []\n",
    "    \n",
    "    unique_routes = list(route_to_stops.keys())\n",
    "    color_palette = plt.cm.get_cmap('hsv')(np.linspace(0, 1, len(unique_routes)))\n",
    "    \n",
    "    rt_color_map = {}\n",
    "    for i in range (len(unique_routes)):\n",
    "        route_id = unique_routes[i]\n",
    "        r, g, b, _ = color_palette[i]\n",
    "        \n",
    "        color_string = f'rgb({int(r*255)},{int(g*255)},{int(b*255)})'\n",
    "        rt_color_map[route_id] = color_string\n",
    "    \n",
    "    for route_id, stops_on_route in route_to_stops.items():\n",
    "        route_name = df_routes[df_routes['route_id'] == route_id]['route_long_name'].iloc[0]\n",
    "        for i in range(len(stops_on_route) - 1):\n",
    "            current_stop = stops_on_route[i]\n",
    "            next_stop = stops_on_route[i + 1]\n",
    "            \n",
    "            grph.add_edge(current_stop, next_stop)\n",
    "            \n",
    "            edge_colors.append(rt_color_map[route_id])\n",
    "            edge_labels.append(f\"Route: {route_name}\")\n",
    "        \n",
    "    # Step 3: Calculate state_positions for the graph\n",
    "    stop_positions = nx.shell_layout(grph)\n",
    "    \n",
    "    # Step 4: Create edge trace\n",
    "    edge_trace = []\n",
    "    for i in range (len(grph.edges())):\n",
    "        edge = list(grph.edges())[i]\n",
    "        color = edge_colors[i]\n",
    "        label = edge_labels[i]\n",
    "        \n",
    "        x0, y0 = stop_positions[edge[0]]\n",
    "        x1, y1 = stop_positions[edge[1]]\n",
    "        \n",
    "        \n",
    "        edge_trace.append(\n",
    "            go.Scatter(\n",
    "                x=[x0, x1, None],\n",
    "                y=[y0, y1, None],\n",
    "                line=dict(width=2, color=color),\n",
    "                hoverinfo='text',\n",
    "                text=label,\n",
    "                mode='lines'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    # Step 5: Create node trace\n",
    "    node_x = []\n",
    "    node_y = []\n",
    "    node_text = []\n",
    "    \n",
    "    for node in grph.nodes():\n",
    "        x, y = stop_positions[node]\n",
    "        node_x.append(x)\n",
    "        node_y.append(y)\n",
    "        # Get stop name for hover text\n",
    "        stop_name = df_stops[df_stops['stop_id'] == node]['stop_name'].iloc[0]\n",
    "        node_text.append(f\"Stop: {stop_name}<br>ID: {node}\")\n",
    "    \n",
    "    node_trace = go.Scatter(\n",
    "        x=node_x,\n",
    "        y=node_y,\n",
    "        mode='markers+text',\n",
    "        hoverinfo='text',\n",
    "        text=node_text,\n",
    "        marker=dict(\n",
    "            size=10,\n",
    "            color='lightblue',\n",
    "            line=dict(width=2, color='darkblue')\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Step 6: Create the figure\n",
    "    fig = go.Figure(data=edge_trace + [node_trace],\n",
    "                   layout=go.Layout(\n",
    "                       title='Transit Network Map',\n",
    "                       showlegend=False,\n",
    "                       hovermode='closest',\n",
    "                       margin=dict(b=0, l=0, r=0, t=40),\n",
    "                       xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                       yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                       plot_bgcolor='white'\n",
    "                   ))\n",
    "    \n",
    "    # Add a legend showing route colors\n",
    "    for route_id in unique_routes:\n",
    "        route_name = df_routes[df_routes['route_id'] == route_id]['route_long_name'].iloc[0]\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[None],\n",
    "            y=[None],\n",
    "            mode='lines',\n",
    "            name=route_name,\n",
    "            line=dict(color=rt_color_map[route_id], width=2),\n",
    "            showlegend=True\n",
    "        ))\n",
    "    \n",
    "    # Step 7: Show the plot\n",
    "    fig.show()\n",
    "    pass  # Implementation here\n",
    "\n",
    "# Brute-Force Approach for finding direct routes\n",
    "def direct_route_brute_force(start_stop, end_stop):\n",
    "    \"\"\"\n",
    "    Find all valid routes between two stops using a brute-force method.\n",
    "\n",
    "    Args:\n",
    "        start_stop (int): The ID of the starting stop.\n",
    "        end_stop (int): The ID of the ending stop.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of route IDs (int) that connect the two stops directly.\n",
    "    \"\"\"\n",
    "    \n",
    "    dir_routes = []\n",
    "    for route_id, stops in route_to_stops.items():\n",
    "        if start_stop in stops and end_stop in stops:\n",
    "            # Check if start_stop comes before end_stop in the sequence\n",
    "            if stops.index(start_stop) < stops.index(end_stop):\n",
    "                dir_routes.append(route_id)\n",
    "    return dir_routes\n",
    "    \n",
    "    pass  # Implementation here\n",
    "\n",
    "# Initialize Datalog predicates for reasoning\n",
    "pyDatalog.create_terms('RouteHasStop, DirectRoute, OptimalRoute, X, Y, Z, R, R1, R2')  \n",
    "def initialize_datalog():\n",
    "    \"\"\"\n",
    "    Initialize Datalog terms and predicates for reasoning about routes and stops.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    pyDatalog.clear()  # Clear previous terms\n",
    "    print(\"Terms initialized: DirectRoute, RouteHasStop, OptimalRoute\")  # Confirmation print\n",
    "\n",
    "    # Define Datalog predicates\n",
    "\n",
    "    create_kb()  # Populate the knowledge base\n",
    "    add_route_data(route_to_stops)  # Add route data to Datalog\n",
    "    \n",
    "    \n",
    "# Adding route data to Datalog\n",
    "def add_route_data(route_to_stops):\n",
    "    \"\"\"\n",
    "    Add the route data to Datalog for reasoning.\n",
    "\n",
    "    Args:\n",
    "        route_to_stops (dict): A dictionary mapping route IDs to lists of stops.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    for route_id, stops in route_to_stops.items():\n",
    "        for stop_id in stops:\n",
    "            +RouteHasStop(route_id, stop_id)\n",
    "\n",
    "# Function to query direct routes between two stops\n",
    "def query_direct_routes(start, end):\n",
    "    \"\"\"\n",
    "    Query for direct routes between two stops.\n",
    "\n",
    "    Args:\n",
    "        start (int): The ID of the starting stop.\n",
    "        end (int): The ID of the ending stop.\n",
    "\n",
    "    Returns:\n",
    "        list: A sorted list of route IDs (str) connecting the two stops.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Query for routes that contain both start and end stops\n",
    "    query_result = pyDatalog.ask(f'RouteHasStop(R, {start}) & RouteHasStop(R, {end})')\n",
    "    \n",
    "    # Process the results, assuming each answer contains a single route_id\n",
    "    if query_result:\n",
    "        return sorted(set(route_id[0] for route_id in query_result.answers))\n",
    "    return []\n",
    "    \n",
    "    pass  # Implementation here\n",
    "\n",
    "\n",
    "\n",
    "# PDDL-style planning for route finding\n",
    "def pddl_planning(start_stop_id, end_stop_id, stop_id_to_include, max_transfers):\n",
    "    \"\"\"\n",
    "    Implement PDDL-style planning to find routes with optional transfers.\n",
    "\n",
    "    Args:\n",
    "        start_stop_id (int): The starting stop ID.\n",
    "        end_stop_id (int): The ending stop ID.\n",
    "        stop_id_to_include (int): The stop ID for a transfer.\n",
    "        max_transfers (int): The maximum number of transfers allowed.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of unique paths (list of tuples) that satisfy the criteria, where each tuple contains:\n",
    "              - route_id (int): The ID of the route.\n",
    "              - stop_id (int): The ID of the stop.\n",
    "    \"\"\"\n",
    "    pass  # Implementation here\n",
    "\n",
    "# Function to filter fare data based on an initial fare limit\n",
    "def prune_data(merged_fare_df, initial_fare):\n",
    "    \"\"\"\n",
    "    Filter fare data based on an initial fare limit.\n",
    "\n",
    "    Args:\n",
    "        merged_fare_df (DataFrame): The merged fare DataFrame.\n",
    "        initial_fare (float): The maximum fare allowed.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A filtered DataFrame containing only routes within the fare limit.\n",
    "    \"\"\"\n",
    "    pass  # Implementation here\n",
    "\n",
    "# Pre-computation of Route Summary\n",
    "def compute_route_summary(pruned_df):\n",
    "    \"\"\"\n",
    "    Generate a summary of routes based on fare information.\n",
    "\n",
    "    Args:\n",
    "        pruned_df (DataFrame): The filtered DataFrame containing fare information.\n",
    "\n",
    "    Returns:\n",
    "        dict: A summary of routes with the following structure:\n",
    "              {\n",
    "                  route_id (int): {\n",
    "                      'min_price': float,          # The minimum fare for the route\n",
    "                      'stops': set                # A set of stop IDs for that route\n",
    "                  }\n",
    "              }\n",
    "    \"\"\"\n",
    "    pass  # Implementation here\n",
    "\n",
    "# BFS for optimized route planning\n",
    "def bfs_route_planner_optimized(start_stop_id, end_stop_id, initial_fare, route_summary, max_transfers=3):\n",
    "    \"\"\"\n",
    "    Use Breadth-First Search (BFS) to find the optimal route while considering fare constraints.\n",
    "\n",
    "    Args:\n",
    "        start_stop_id (int): The starting stop ID.\n",
    "        end_stop_id (int): The ending stop ID.\n",
    "        initial_fare (float): The available fare for the trip.\n",
    "        route_summary (dict): A summary of routes with fare and stop information.\n",
    "        max_transfers (int): The maximum number of transfers allowed (default is 3).\n",
    "\n",
    "    Returns:\n",
    "        list: A list representing the optimal route with stops and routes taken, structured as:\n",
    "              [\n",
    "                  (route_id (int), stop_id (int)),  # Tuple for each stop taken in the route\n",
    "                  ...\n",
    "              ]\n",
    "    \"\"\"\n",
    "    pass  # Implementation here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Just do this correctly it will work\n",
    "this is working properly fiine just need to convert this according to that function rest everything is corect\n",
    "\n",
    "from pyDatalog import pyDatalog\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def pddl_planning(start_stop_id, end_stop_id, stop_id_to_include, max_transfers):\n",
    "    \"\"\"\n",
    "    Optimized PDDL-based route planning implementation\n",
    "    Returns list of tuples (route1, transfer_stop, route2) representing valid paths\n",
    "    \"\"\"\n",
    "    # Start timing and memory tracking\n",
    "    start_time = time.time()\n",
    "    process = psutil.Process(os.getpid())\n",
    "    initial_memory = process.memory_info().rss / 1024 / 1024\n",
    "    \n",
    "    # Pre-process route data for faster lookups\n",
    "    stop_to_routes = defaultdict(set)\n",
    "    route_stops = defaultdict(set)\n",
    "    transfer_routes = set()\n",
    "    \n",
    "    # Build lookup dictionaries\n",
    "    for route_id, stops in route_to_stops.items():\n",
    "        route_stops[route_id] = set(stops)\n",
    "        if stop_id_to_include in stops:\n",
    "            transfer_routes.add(route_id)\n",
    "        for stop in stops:\n",
    "            stop_to_routes[stop].add(route_id)\n",
    "            \n",
    "    # Early termination checks\n",
    "    if not stop_to_routes[start_stop_id] or not stop_to_routes[end_stop_id]:\n",
    "        return []\n",
    "    \n",
    "    result_paths = set()  # Using set to avoid duplicates\n",
    "    \n",
    "    # Handle routes containing start, transfer, and end stops\n",
    "    routes_with_transfer = transfer_routes\n",
    "    start_routes = stop_to_routes[start_stop_id]\n",
    "    end_routes = stop_to_routes[end_stop_id]\n",
    "    \n",
    "    # Find all possible combinations within transfer limit\n",
    "    if max_transfers >= 0:\n",
    "        # Direct routes (no transfers)\n",
    "        direct_routes = start_routes & end_routes & routes_with_transfer\n",
    "        for route in direct_routes:\n",
    "            stops = list(route_to_stops[route])\n",
    "            start_idx = stops.index(start_stop_id)\n",
    "            via_idx = stops.index(stop_id_to_include)\n",
    "            end_idx = stops.index(end_stop_id)\n",
    "            \n",
    "            # Check if stops are in correct order\n",
    "            if is_valid_sequence(start_idx, via_idx, end_idx, len(stops)):\n",
    "                result_paths.add((route, stop_id_to_include, route))\n",
    "    \n",
    "    if max_transfers >= 1:\n",
    "        # Single transfer routes\n",
    "        for first_route in (start_routes & routes_with_transfer):\n",
    "            stops1 = list(route_to_stops[first_route])\n",
    "            start_idx = stops1.index(start_stop_id)\n",
    "            transfer_idx1 = stops1.index(stop_id_to_include)\n",
    "            \n",
    "            # Check if transfer is reachable from start\n",
    "            if not is_valid_sequence(start_idx, transfer_idx1, None, len(stops1)):\n",
    "                continue\n",
    "                \n",
    "            for second_route in (end_routes & routes_with_transfer):\n",
    "                if first_route == second_route:\n",
    "                    continue\n",
    "                    \n",
    "                stops2 = list(route_to_stops[second_route])\n",
    "                transfer_idx2 = stops2.index(stop_id_to_include)\n",
    "                end_idx = stops2.index(end_stop_id)\n",
    "                \n",
    "                # Check if end is reachable from transfer\n",
    "                if is_valid_sequence(transfer_idx2, end_idx, None, len(stops2), reverse_allowed=True):\n",
    "                    result_paths.add((first_route, stop_id_to_include, second_route))\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    execution_time = time.time() - start_time\n",
    "    final_memory = process.memory_info().rss / 1024 / 1024\n",
    "    memory_used = final_memory - initial_memory\n",
    "    \n",
    "    print(f\"\\nPerformance Metrics:\")\n",
    "    print(f\"Execution Time: {execution_time:.4f} seconds\")\n",
    "    print(f\"Memory Usage: {memory_used:.2f} MB\")\n",
    "    print(f\"Number of Steps: {len(result_paths)}\")\n",
    "    \n",
    "    return sorted(list(result_paths))\n",
    "\n",
    "def is_valid_sequence(idx1, idx2, idx3=None, route_length=None, reverse_allowed=False):\n",
    "    \"\"\"\n",
    "    Check if the sequence of indices represents a valid path through the route\n",
    "    \"\"\"\n",
    "    if reverse_allowed:\n",
    "        # Allow both forward and backward travel\n",
    "        if idx3 is None:\n",
    "            return True\n",
    "        return (idx1 <= idx2 <= idx3) or (idx3 <= idx2 <= idx1)\n",
    "    else:\n",
    "        # Forward travel only\n",
    "        if idx3 is None:\n",
    "            return idx1 <= idx2\n",
    "        return idx1 <= idx2 <= idx3\n",
    "\n",
    "Implement the previous planning problem using Planning Domain Definition Language (PDDL) using forward chaining. Use the PyDatalog library for the same.\n",
    "Key aspects:\n",
    "â€¢ Initial State: Define the initial state as the stop where the journey begins (e.g., start stop id).\n",
    "â€¢ Goal State: The goal state is to reach the destination stop (e.g., end stop id). â€¢ Action: You have two primary actions in this route planning:\n",
    "â€“ Board a route: This action allows you to board a specific route at a stop. Example: Action(â€˜board routeâ€™, R, X) means boarding route R at stop X.\n",
    "â€“ Transfer between routes: This action allows you to switch from one route to another at a stop. Example: Action(â€˜transfer routeâ€™, R1, R2, Z) means\n",
    "transferring from route R1 to route R2 at stop Z (the transfer stop).\n",
    "Print the current state information at each step. In your analysis, (a) evaluate time complexity in terms of execution time (measured in seconds) and memory usage (measured in megabytes, MB), (b) examine the intermediate steps in your reasoning process, and (c) compare the overall number of steps involved in both implementations. Do all algorithms (forward chaining, backward chaining, and PDDL) produce the same optimal route, or do some produce suboptimal routes due to the way constraints are applied?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate for AI Assignment â€” Knowledge Representation, Reasoning and Planning\n",
    "# CSE 643\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import networkx as nx\n",
    "from pyDatalog import pyDatalog\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "## ****IMPORTANT****\n",
    "## Don't import or use any other libraries other than defined above\n",
    "## Otherwise your code file will be rejected in the automated testing\n",
    "\n",
    "# ------------------ Global Variables ------------------\n",
    "route_to_stops = defaultdict(list)  # Mapping of route IDs to lists of stops\n",
    "trip_to_route = {}                   # Mapping of trip IDs to route IDs\n",
    "stop_trip_count = defaultdict(int)    # Count of trips for each stop\n",
    "fare_rules = {}                      # Mapping of route IDs to fare information\n",
    "merged_fare_df = None                # To be initialized in create_kb()\n",
    "\n",
    "# Load static data from GTFS (General Transit Feed Specification) files\n",
    "df_stops = pd.read_csv('GTFS/stops.txt')\n",
    "df_routes = pd.read_csv('GTFS/routes.txt')\n",
    "df_stop_times = pd.read_csv('GTFS/stop_times.txt')\n",
    "df_fare_attributes = pd.read_csv('GTFS/fare_attributes.txt')\n",
    "df_trips = pd.read_csv('GTFS/trips.txt')\n",
    "df_fare_rules = pd.read_csv('GTFS/fare_rules.txt')\n",
    "\n",
    "# ------------------ Function Definitions ------------------\n",
    "\n",
    "# Function to create knowledge base from the loaded data\n",
    "def create_kb():\n",
    "    \"\"\"\n",
    "    Create knowledge base by populating global variables with information from loaded datasets.\n",
    "    It establishes the relationships between routes, trips, stops, and fare rules.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    global route_to_stops, trip_to_route, stop_trip_count, fare_rules, merged_fare_df\n",
    "\n",
    "    # Create trip_id to route_id mapping\"\"\"\n",
    "    trip_to_route = defaultdict(list)\n",
    "    for _, row in df_trips.iterrows():\n",
    "        trip_to_route[row['trip_id']].append(row['route_id'])\n",
    "        \n",
    "    # Map route_id to a list of stops in order of their sequence\"\"\"\n",
    "    route_to_stops = defaultdict(list)\n",
    "    sorted_stop_times = df_stop_times.sort_values(['trip_id', 'stop_sequence'])\n",
    "    sorted_stop_times.head\n",
    "    for trip_id, stop_grp in sorted_stop_times.groupby('trip_id'):\n",
    "        if trip_id in trip_to_route:\n",
    "            route_id = trip_to_route[trip_id][0]\n",
    "            stops = stop_grp['stop_id'].to_list()\n",
    "            route_to_stops[route_id].extend(stops)\n",
    "            \n",
    "    # Ensure each route only has unique stops\"\"\"\n",
    "    for route_id in route_to_stops:\n",
    "        # Use dict.fromkeys() to preserve order while removing duplicates\n",
    "        route_to_stops[route_id] = list(dict.fromkeys(route_to_stops[route_id]))\n",
    "    \n",
    "    # Count trips per stop\"\"\"\n",
    "    stop_trip_count = dict(df_stop_times['stop_id'].value_counts())\n",
    "\n",
    "    # Create fare rules for routes\n",
    "    fare_rules = {}\n",
    "    for i in range(len(df_fare_rules['route_id'])):\n",
    "        route_id = df_fare_rules['route_id'][i]\n",
    "        fare_id = df_fare_rules['fare_id'][i]\n",
    "\n",
    "        if route_id not in fare_rules:\n",
    "            fare_rules[route_id] = []\n",
    "\n",
    "        fare_rules[route_id].append(fare_id)\n",
    "\n",
    "    # Merge fare rules and attributes into a single DataFrame\n",
    "    merged_fare_df = pd.merge(\n",
    "        df_fare_rules,\n",
    "        df_fare_attributes,\n",
    "        on='fare_id',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "# Function to find the top 5 busiest routes based on the number of trips\n",
    "def get_busiest_routes():\n",
    "    \"\"\"\n",
    "    Identify the top 5 busiest routes based on trip counts.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains:\n",
    "              - route_id (int): The ID of the route.\n",
    "              - trip_count (int): The number of trips for that route.\n",
    "    \"\"\"\n",
    "    route_trip_counts = defaultdict(int)\n",
    "    for trip_id, routes in trip_to_route.items():\n",
    "        # Since we stored routes as a list in trip_to_route, take the first route\n",
    "        route_id = routes[0]\n",
    "        route_trip_counts[route_id] += 1\n",
    "    \n",
    "    res = sorted(route_trip_counts.items(), key = lambda ele: ele[1], reverse = True)\n",
    "    \n",
    "    # Return top 5 routes\n",
    "    return res[:5]\n",
    "    pass  # Implementation here\n",
    "\n",
    "# Function to find the top 5 stops with the most frequent trips\n",
    "def get_most_frequent_stops():\n",
    "    \"\"\"\n",
    "    Identify the top 5 stops with the highest number of trips.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains:\n",
    "              - stop_id (int): The ID of the stop.\n",
    "              - trip_count (int): The number of trips for that stop.\n",
    "    \"\"\"\n",
    "    res = sorted(stop_trip_count.items(), key = lambda ele: ele[1], reverse = True)\n",
    "    \n",
    "    # Return top 5 routes\n",
    "    return res[:5]\n",
    "    pass  # Implementation here\n",
    "\n",
    "# Function to find the top 5 busiest stops based on the number of routes passing through them\n",
    "def get_top_5_busiest_stops():\n",
    "    \"\"\"\n",
    "    Identify the top 5 stops with the highest number of different routes.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains:\n",
    "              - stop_id (int): The ID of the stop.\n",
    "              - route_count (int): The number of routes passing through that stop.\n",
    "    \"\"\"\n",
    "    stop_routes = defaultdict(set)\n",
    "    for route_id, stops in route_to_stops.items():\n",
    "        for stop_id in stops:\n",
    "            stop_routes[stop_id].add(route_id)\n",
    "            \n",
    "    stop_counts = []\n",
    "    for stop_id, routes in stop_routes.items():\n",
    "        route_count = len(routes)\n",
    "        stop_counts.append((stop_id, route_count))\n",
    "\n",
    "    res = sorted(stop_counts, key = lambda ele: ele[1], reverse = True)\n",
    "    \n",
    "    return res[:5]\n",
    "    pass  # Implementation here\n",
    "\n",
    "# Function to identify the top 5 pairs of stops with only one direct route between them\n",
    "def get_stops_with_one_direct_route():\n",
    "    \"\"\"\n",
    "    Identify the top 5 pairs of consecutive stops (start and end) connected by exactly one direct route. \n",
    "    The pairs are sorted by the combined frequency of trips passing through both stops.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains:\n",
    "              - pair (tuple): A tuple with two stop IDs (stop_1, stop_2).\n",
    "              - route_id (int): The ID of the route connecting the two stops.\n",
    "    \"\"\"\n",
    "    connections = {}\n",
    "    \n",
    "    for route_id, stops in route_to_stops.items():\n",
    "        for i in range(len(stops) - 1):\n",
    "            current_stop = stops[i]\n",
    "            next_stop = stops[i + 1]\n",
    "            \n",
    "            # same order for consistency\n",
    "            stop_pair = (current_stop, next_stop) if current_stop < next_stop else (next_stop, current_stop)\n",
    "\n",
    "            \n",
    "            # Add the route to this pair's list of routes\n",
    "            if stop_pair not in connections:\n",
    "                connections[stop_pair] = []\n",
    "            connections[stop_pair].append(route_id)\n",
    "    \n",
    "    result = []\n",
    "    for stop_pair, routes in connections.items():\n",
    "        if len(routes) == 1:\n",
    "            result.append((stop_pair, routes[0]))\n",
    "    \n",
    "    return result\n",
    "    pass  # Implementation here\n",
    "\n",
    "# Function to get merged fare DataFrame\n",
    "# No need to change this function\n",
    "def get_merged_fare_df():\n",
    "    \"\"\"\n",
    "    Retrieve the merged fare DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The merged fare DataFrame containing fare rules and attributes.\n",
    "    \"\"\"\n",
    "    global merged_fare_df\n",
    "    return merged_fare_df\n",
    "\n",
    "# Visualize the stop-route graph interactively\n",
    "def visualize_stop_route_graph_interactive(route_to_stops):\n",
    "    \"\"\"\n",
    "    Visualize the stop-route graph using Plotly for interactive exploration.\n",
    "\n",
    "    Args:\n",
    "        route_to_stops (dict): A dictionary mapping route IDs to lists of stops.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Step 1: Create a network graph\n",
    "    grph = nx.Graph()\n",
    "    \n",
    "    # Step 2: Add edges (connections between stops) from each route\n",
    "    edge_colors = []\n",
    "    edge_labels = []\n",
    "    \n",
    "    unique_routes = list(route_to_stops.keys())\n",
    "    color_palette = plt.cm.get_cmap('hsv')(np.linspace(0, 1, len(unique_routes)))\n",
    "    \n",
    "    rt_color_map = {}\n",
    "    for i in range (len(unique_routes)):\n",
    "        route_id = unique_routes[i]\n",
    "        r, g, b, _ = color_palette[i]\n",
    "        \n",
    "        color_string = f'rgb({int(r*255)},{int(g*255)},{int(b*255)})'\n",
    "        rt_color_map[route_id] = color_string\n",
    "    \n",
    "    for route_id, stops_on_route in route_to_stops.items():\n",
    "        route_name = df_routes[df_routes['route_id'] == route_id]['route_long_name'].iloc[0]\n",
    "        for i in range(len(stops_on_route) - 1):\n",
    "            current_stop = stops_on_route[i]\n",
    "            next_stop = stops_on_route[i + 1]\n",
    "            \n",
    "            grph.add_edge(current_stop, next_stop)\n",
    "            \n",
    "            edge_colors.append(rt_color_map[route_id])\n",
    "            edge_labels.append(f\"Route: {route_name}\")\n",
    "        \n",
    "    # Step 3: Calculate state_positions for the graph\n",
    "    stop_positions = nx.shell_layout(grph)\n",
    "    \n",
    "    # Step 4: Create edge trace\n",
    "    edge_trace = []\n",
    "    for i in range (len(grph.edges())):\n",
    "        edge = list(grph.edges())[i]\n",
    "        color = edge_colors[i]\n",
    "        label = edge_labels[i]\n",
    "        \n",
    "        x0, y0 = stop_positions[edge[0]]\n",
    "        x1, y1 = stop_positions[edge[1]]\n",
    "        \n",
    "        \n",
    "        edge_trace.append(\n",
    "            go.Scatter(\n",
    "                x=[x0, x1, None],\n",
    "                y=[y0, y1, None],\n",
    "                line=dict(width=2, color=color),\n",
    "                hoverinfo='text',\n",
    "                text=label,\n",
    "                mode='lines'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    # Step 5: Create node trace\n",
    "    node_x = []\n",
    "    node_y = []\n",
    "    node_text = []\n",
    "    \n",
    "    for node in grph.nodes():\n",
    "        x, y = stop_positions[node]\n",
    "        node_x.append(x)\n",
    "        node_y.append(y)\n",
    "        # Get stop name for hover text\n",
    "        stop_name = df_stops[df_stops['stop_id'] == node]['stop_name'].iloc[0]\n",
    "        node_text.append(f\"Stop: {stop_name}<br>ID: {node}\")\n",
    "    \n",
    "    node_trace = go.Scatter(\n",
    "        x=node_x,\n",
    "        y=node_y,\n",
    "        mode='markers+text',\n",
    "        hoverinfo='text',\n",
    "        text=node_text,\n",
    "        marker=dict(\n",
    "            size=10,\n",
    "            color='lightblue',\n",
    "            line=dict(width=2, color='darkblue')\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Step 6: Create the figure\n",
    "    fig = go.Figure(data=edge_trace + [node_trace],\n",
    "                   layout=go.Layout(\n",
    "                       title='Transit Network Map',\n",
    "                       showlegend=False,\n",
    "                       hovermode='closest',\n",
    "                       margin=dict(b=0, l=0, r=0, t=40),\n",
    "                       xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                       yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                       plot_bgcolor='white'\n",
    "                   ))\n",
    "    \n",
    "    # Add a legend showing route colors\n",
    "    for route_id in unique_routes:\n",
    "        route_name = df_routes[df_routes['route_id'] == route_id]['route_long_name'].iloc[0]\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[None],\n",
    "            y=[None],\n",
    "            mode='lines',\n",
    "            name=route_name,\n",
    "            line=dict(color=rt_color_map[route_id], width=2),\n",
    "            showlegend=True\n",
    "        ))\n",
    "    \n",
    "    # Step 7: Show the plot\n",
    "    fig.show()\n",
    "    pass  # Implementation here\n",
    "\n",
    "# Brute-Force Approach for finding direct routes\n",
    "def direct_route_brute_force(start_stop, end_stop):\n",
    "    \"\"\"\n",
    "    Find all valid routes between two stops using a brute-force method.\n",
    "\n",
    "    Args:\n",
    "        start_stop (int): The ID of the starting stop.\n",
    "        end_stop (int): The ID of the ending stop.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of route IDs (int) that connect the two stops directly.\n",
    "    \"\"\"\n",
    "    \n",
    "    dir_routes = []\n",
    "    for route_id, stops in route_to_stops.items():\n",
    "        if start_stop in stops and end_stop in stops:\n",
    "            # Check if start_stop comes before end_stop in the sequence\n",
    "            if stops.index(start_stop) < stops.index(end_stop):\n",
    "                dir_routes.append(route_id)\n",
    "    return dir_routes\n",
    "    \n",
    "    pass  # Implementation here\n",
    "\n",
    "# Initialize Datalog predicates for reasoning\n",
    "pyDatalog.create_terms('RouteHasStop, DirectRoute, OptimalRoute, X, Y, Z, R, R1, R2')  \n",
    "def initialize_datalog():\n",
    "    \"\"\"\n",
    "    Initialize Datalog terms and predicates for reasoning about routes and stops.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    pyDatalog.clear()  # Clear previous terms\n",
    "    print(\"Terms initialized: DirectRoute, RouteHasStop, OptimalRoute\")  # Confirmation print\n",
    "\n",
    "    # Define Datalog predicates\n",
    "\n",
    "    create_kb()  # Populate the knowledge base\n",
    "    add_route_data(route_to_stops)  # Add route data to Datalog\n",
    "    \n",
    "    \n",
    "# Adding route data to Datalog\n",
    "def add_route_data(route_to_stops):\n",
    "    \"\"\"\n",
    "    Add the route data to Datalog for reasoning.\n",
    "\n",
    "    Args:\n",
    "        route_to_stops (dict): A dictionary mapping route IDs to lists of stops.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    for route_id, stops in route_to_stops.items():\n",
    "        for stop_id in stops:\n",
    "            +RouteHasStop(route_id, stop_id)\n",
    "\n",
    "# Function to query direct routes between two stops\n",
    "def query_direct_routes(start, end):\n",
    "    \"\"\"\n",
    "    Query for direct routes between two stops.\n",
    "\n",
    "    Args:\n",
    "        start (int): The ID of the starting stop.\n",
    "        end (int): The ID of the ending stop.\n",
    "\n",
    "    Returns:\n",
    "        list: A sorted list of route IDs (str) connecting the two stops.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Query for routes that contain both start and end stops\n",
    "    query_result = pyDatalog.ask(f'RouteHasStop(R, {start}) & RouteHasStop(R, {end})')\n",
    "    \n",
    "    # Process the results, assuming each answer contains a single route_id\n",
    "    if query_result:\n",
    "        return sorted(set(route_id[0] for route_id in query_result.answers))\n",
    "    return []\n",
    "    \n",
    "    pass  # Implementation here\n",
    "\n",
    "# Forward chaining for optimal route planning\n",
    "def forward_chaining(start_stop_id, end_stop_id, stop_id_to_include, max_transfers):\n",
    "    \"\"\"\n",
    "    Perform forward chaining to find optimal routes considering transfers.\n",
    "\n",
    "    Args:\n",
    "        start_stop_id (int): The starting stop ID.\n",
    "        end_stop_id (int): The ending stop ID.\n",
    "        stop_id_to_include (int): The stop ID where a transfer occurs.\n",
    "        max_transfers (int): The maximum number of transfers allowed.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of unique paths (list of tuples) that satisfy the criteria, where each tuple contains:\n",
    "              - route_id (int): The ID of the route.\n",
    "              - stop_id (int): The ID of the stop.\n",
    "    \"\"\"\n",
    "    result_paths = set()\n",
    "    \n",
    "    # Find routes containing the required stops\n",
    "    for route_id, stops in route_to_stops.items():\n",
    "        try:\n",
    "            # Check if all required stops are in this route\n",
    "            if stop_id_to_include in stops and (start_stop_id in stops or end_stop_id in stops):\n",
    "                via_idx = stops.index(stop_id_to_include)\n",
    "                # print(route_id)\n",
    "                # Case 1: Direct route containing all stops\n",
    "                if start_stop_id in stops and end_stop_id in stops:\n",
    "                    start_idx = stops.index(start_stop_id)\n",
    "                    end_idx = stops.index(end_stop_id)\n",
    "                    \n",
    "                    # Check if the route is valid (stops are in correct order)\n",
    "                    if min(start_idx, end_idx) <= via_idx <= max(start_idx, end_idx):\n",
    "                        result_paths.add((route_id, stop_id_to_include, end_stop_id))\n",
    "                        # print(\"yes\")\n",
    "                        \n",
    "                \n",
    "                # Case 2: Route contains via stop and either start or end\n",
    "                elif max_transfers >= 1:\n",
    "                    # Find connecting routes\n",
    "                    for other_route, other_stops in route_to_stops.items():\n",
    "                        # print(other_route)\n",
    "                        if other_route != route_id:\n",
    "                            # print(other_route)\n",
    "                            if start_stop_id in stops and end_stop_id in other_stops:\n",
    "                                # print(other_route)\n",
    "                                if stop_id_to_include in other_stops:\n",
    "                                    \n",
    "                                    result_paths.add((route_id, stop_id_to_include, other_route))\n",
    "                                    # print((route_id, stop_id_to_include, other_route))\n",
    "                                    # print(\"yes2\")\n",
    "                                    # print(other_route)\n",
    "                                    # print(end_stop_id)\n",
    "                            elif start_stop_id in other_stops and end_stop_id in stops:\n",
    "                                # print((other_route, stop_id_to_include, route_id,start_stop_id, end_stop_id))\n",
    "                                # print(other_stops)\n",
    "                                if stop_id_to_include in other_stops:\n",
    "                                    # print(other_route)\n",
    "                                    # print((other_route, stop_id_to_include, route_id,start_stop_id, end_stop_id))\n",
    "                                    result_paths.add((other_route, stop_id_to_include, route_id))\n",
    "                                    # print((other_route, stop_id_to_include, route_id))\n",
    "                                    # print(\"yes3\")\n",
    "                                    # print(other_route)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    # Convert set to list for return\n",
    "    return sorted(list(result_paths))\n",
    "    \n",
    "    \n",
    "    pass  # Implementation here\n",
    "\n",
    "# Backward chaining for optimal route planning\n",
    "def backward_chaining(start_stop_id, end_stop_id, stop_id_to_include, max_transfers):\n",
    "    \"\"\"\n",
    "    Perform backward chaining to find optimal routes considering transfers.\n",
    "\n",
    "    Args:\n",
    "        start_stop_id (int): The starting stop ID.\n",
    "        end_stop_id (int): The ending stop ID.\n",
    "        stop_id_to_include (int): The stop ID where a transfer occurs.\n",
    "        max_transfers (int): The maximum number of transfers allowed.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of unique paths (list of tuples) that satisfy the criteria, where each tuple contains:\n",
    "              - route_id (int): The ID of the route.\n",
    "              - stop_id (int): The ID of the stop.\n",
    "    \"\"\"\n",
    "    \n",
    "    result_paths = []\n",
    "    seen_paths = set()  # To avoid duplicates while maintaining order\n",
    "    \n",
    "    # Start from the end stop and work backwards\n",
    "    for route_id, stops in route_to_stops.items():\n",
    "        try:\n",
    "            # Check if the route contains the end stop and via stop\n",
    "            if end_stop_id in stops and stop_id_to_include in stops:\n",
    "                end_idx = stops.index(end_stop_id)\n",
    "                via_idx = stops.index(stop_id_to_include)\n",
    "                \n",
    "                # Case 1: Direct route containing all stops\n",
    "                if start_stop_id in stops:\n",
    "                    start_idx = stops.index(start_stop_id)\n",
    "                    # Check if the route is valid (stops are in correct order)\n",
    "                    if min(via_idx, end_idx) <= start_idx <= max(via_idx, end_idx):\n",
    "                        path_tuple = (end_stop_id, stop_id_to_include, route_id)\n",
    "                        path_key = str(path_tuple)  # Convert to string for hashing\n",
    "                        # print(\"yes1\")\n",
    "                        # print(path_tuple)\n",
    "                        if path_key not in seen_paths:\n",
    "                            seen_paths.add(path_key)\n",
    "                            result_paths.append(path_tuple)\n",
    "                \n",
    "                # Case 2: Route contains end stop and via stop, need to find connecting route\n",
    "                elif max_transfers >= 1:\n",
    "                    # Look for routes that can connect to our current route at the via stop\n",
    "                    for connecting_route, connecting_stops in route_to_stops.items():\n",
    "                        if connecting_route != route_id:\n",
    "                            # Check if connecting route has start stop and via stop\n",
    "                            if start_stop_id in connecting_stops and stop_id_to_include in connecting_stops:\n",
    "                                conn_start_idx = connecting_stops.index(start_stop_id)\n",
    "                                conn_via_idx = connecting_stops.index(stop_id_to_include)\n",
    "                                \n",
    "                                # Verify the order in connecting route\n",
    "                                if min(conn_start_idx, conn_via_idx) <= max(conn_start_idx, conn_via_idx):\n",
    "                                    path_tuple = (route_id, stop_id_to_include, connecting_route)\n",
    "                                    # print(\"yes2\")\n",
    "                                    # print(path_tuple)\n",
    "                                    path_key = str(path_tuple)\n",
    "                                    if path_key not in seen_paths:\n",
    "                                        seen_paths.add(path_key)\n",
    "                                        result_paths.append(path_tuple)\n",
    "                                        \n",
    "            \n",
    "            # Additional case: Route contains start stop and via stop\n",
    "            elif start_stop_id in stops and stop_id_to_include in stops and max_transfers >= 1:\n",
    "                start_idx = stops.index(start_stop_id)\n",
    "                via_idx = stops.index(stop_id_to_include)\n",
    "                \n",
    "                # Look for routes that can connect from via stop to end stop\n",
    "                for next_route, next_stops in route_to_stops.items():\n",
    "                    if next_route != route_id:\n",
    "                        if end_stop_id in next_stops and stop_id_to_include in next_stops:\n",
    "                            next_end_idx = next_stops.index(end_stop_id)\n",
    "                            next_via_idx = next_stops.index(stop_id_to_include)\n",
    "                            \n",
    "                            # Verify the order in next route\n",
    "                            if min(next_via_idx, next_end_idx) <= max(next_via_idx, next_end_idx):\n",
    "                                path_tuple = (next_route, stop_id_to_include, route_id)\n",
    "                                # print(\"yes3\")\n",
    "                                # print(path_tuple)\n",
    "                                path_key = str(path_tuple)\n",
    "                                if path_key not in seen_paths:\n",
    "                                    seen_paths.add(path_key)\n",
    "                                    result_paths.append(path_tuple)\n",
    "                                \n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    # Sort the results for consistent output\n",
    "    return sorted(result_paths)\n",
    "    \n",
    "    \n",
    "    pass  # Implementation here\n",
    "\n",
    "# PDDL-style planning for route finding\n",
    "def pddl_planning(start_stop_id, end_stop_id, stop_id_to_include, max_transfers):\n",
    "    from pyDatalog import pyDatalog\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# Initialize PyDatalog globally\n",
    "pyDatalog.create_terms('route_stop, R, X, Start, Via, End, Stop, R1, R2')\n",
    "pyDatalog.create_terms('can_board, can_transfer, reachable, path')\n",
    "\n",
    "def pddl_planning(start_stop_id, end_stop_id, stop_id_to_include, max_transfers):\n",
    "    \"\"\"\n",
    "    Optimized PDDL-based route planning implementation using PyDatalog\n",
    "    Returns list of tuples (route1, transfer_stop, route2) representing valid paths\n",
    "    \"\"\"\n",
    "    # Start timing and memory tracking\n",
    "    start_time = time.time()\n",
    "    process = psutil.Process(os.getpid())\n",
    "    initial_memory = process.memory_info().rss / 1024 / 1024\n",
    "\n",
    "    # Initialize PyDatalog\n",
    "    pyDatalog.clear()\n",
    "\n",
    "    # Pre-process route data for faster lookups\n",
    "    stop_to_routes = defaultdict(set)\n",
    "    route_stops = defaultdict(set)\n",
    "    transfer_routes = set()\n",
    "\n",
    "    # Build lookup dictionaries and assert facts\n",
    "    try:\n",
    "        for route_id, stops in route_to_stops.items():\n",
    "            route_stops[route_id] = set(stops)\n",
    "            if stop_id_to_include in stops:\n",
    "                transfer_routes.add(route_id)\n",
    "            for stop in stops:\n",
    "                stop_to_routes[stop].add(route_id)\n",
    "                # Assert facts using proper PyDatalog syntax\n",
    "                + route_stop(route_id, stop)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during fact assertion: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "    # Early termination checks\n",
    "    if not stop_to_routes[start_stop_id] or not stop_to_routes[end_stop_id]:\n",
    "        return []\n",
    "\n",
    "    # Define rules (without + operator)\n",
    "    can_board(R, X) <= route_stop(R, X)\n",
    "\n",
    "    reachable(R, Start, Via, End) <= (\n",
    "        can_board(R, Start) &\n",
    "        route_stop(R, Via) &\n",
    "        route_stop(R, End)\n",
    "    )\n",
    "\n",
    "    can_transfer(R1, R2, Stop) <= (\n",
    "        route_stop(R1, Stop) &\n",
    "        route_stop(R2, Stop)\n",
    "    )\n",
    "\n",
    "    path(R1, Via, R2) <= (\n",
    "        reachable(R1, start_stop_id, Via, stop_id_to_include) &\n",
    "        reachable(R2, stop_id_to_include, Via, end_stop_id)\n",
    "    )\n",
    "\n",
    "    result_paths = set()\n",
    "\n",
    "    # Query for direct routes (no transfers)\n",
    "    if max_transfers >= 0:\n",
    "        for route in stop_to_routes[start_stop_id] & stop_to_routes[end_stop_id] & transfer_routes:\n",
    "            try:\n",
    "                stops = list(route_to_stops[route])\n",
    "                start_idx = stops.index(start_stop_id)\n",
    "                via_idx = stops.index(stop_id_to_include)\n",
    "                end_idx = stops.index(end_stop_id)\n",
    "                \n",
    "                # Inline validity check for direct routes\n",
    "                if start_idx < via_idx < end_idx:\n",
    "                    result_paths.add((route, stop_id_to_include, route))\n",
    "                    # print(f\"State: Direct route found - {route}\")\n",
    "            except (ValueError, KeyError):\n",
    "                continue\n",
    "\n",
    "    # Query for routes with one transfer\n",
    "    if max_transfers >= 1:\n",
    "        # Query using PyDatalog syntax\n",
    "        solutions = path(R1, Via, R2)\n",
    "        if solutions:\n",
    "            for r1, via, r2 in solutions:\n",
    "                try:\n",
    "                    stops1 = list(route_to_stops[r1])\n",
    "                    stops2 = list(route_to_stops[r2])\n",
    "                    if r1 != r2:\n",
    "                        # Inline validity checks for transfer routes\n",
    "                        start_to_via_valid = stops1.index(start_stop_id) < stops1.index(stop_id_to_include)\n",
    "                        via_to_end_valid = True  # Allow reverse direction after transfer\n",
    "                        \n",
    "                        if start_to_via_valid and via_to_end_valid:\n",
    "                            result_paths.add((r1, stop_id_to_include, r2))\n",
    "                            # print(f\"State: Transfer route found - {r1} to {r2} at {stop_id_to_include}\")\n",
    "                except (ValueError, KeyError):\n",
    "                    continue\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    execution_time = time.time() - start_time\n",
    "    final_memory = process.memory_info().rss / 1024 / 1024\n",
    "    memory_used = final_memory - initial_memory\n",
    "    print(f\"\\nPerformance Metrics:\")\n",
    "    print(f\"Execution Time: {execution_time:.4f} seconds\")\n",
    "    print(f\"Memory Usage: {memory_used:.2f} MB\")\n",
    "    print(f\"Number of Steps: {len(result_paths)}\")\n",
    "\n",
    "    return sorted(list(result_paths))\n",
    "    \n",
    "    pass  # Implementation here\n",
    "\n",
    "# Function to filter fare data based on an initial fare limit\n",
    "def prune_data(merged_fare_df, initial_fare):\n",
    "    \"\"\"\n",
    "    Filter fare data based on an initial fare limit.\n",
    "\n",
    "    Args:\n",
    "        merged_fare_df (DataFrame): The merged fare DataFrame.\n",
    "        initial_fare (float): The maximum fare allowed.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A filtered DataFrame containing only routes within the fare limit.\n",
    "    \"\"\"\n",
    "    \n",
    "     # First, let's find the fare column - it might be 'price', 'fare_amount', etc.\n",
    "    fare_column = None\n",
    "    possible_fare_columns = ['price', 'fare', 'cost', 'fare_amount', 'amount']\n",
    "    \n",
    "    for col in possible_fare_columns:\n",
    "        if col in merged_fare_df.columns:\n",
    "            fare_column = col\n",
    "            break\n",
    "    \n",
    "    if fare_column is None:\n",
    "        # If we can't find a fare column, return the original DataFrame\n",
    "        return merged_fare_df\n",
    "        \n",
    "    return merged_fare_df[merged_fare_df[fare_column] <= initial_fare]\n",
    "    \n",
    "    pass  # Implementation here\n",
    "\n",
    "# Pre-computation of Route Summary\n",
    "def compute_route_summary(pruned_df):\n",
    "    \"\"\"\n",
    "    Generate a summary of routes based on fare information.\n",
    "\n",
    "    Args:\n",
    "        pruned_df (DataFrame): The filtered DataFrame containing fare information.\n",
    "\n",
    "    Returns:\n",
    "        dict: A summary of routes with the following structure:\n",
    "              {\n",
    "                  route_id (int): {\n",
    "                      'min_price': float,          # The minimum fare for the route\n",
    "                      'stops': set                # A set of stop IDs for that route\n",
    "                  }\n",
    "              }\n",
    "    \"\"\"\n",
    "    \n",
    "    summary = {}\n",
    "    # First, find the fare column\n",
    "    fare_column = None\n",
    "    possible_fare_columns = ['price', 'fare', 'cost', 'fare_amount', 'amount']\n",
    "    \n",
    "    for col in possible_fare_columns:\n",
    "        if col in pruned_df.columns:\n",
    "            fare_column = col\n",
    "            break\n",
    "    \n",
    "    if fare_column is None:\n",
    "        # If we can't find a fare column, use a default value\n",
    "        default_fare = 1.0\n",
    "        \n",
    "    for _, row in pruned_df.iterrows():\n",
    "        route_id = row['route_id']\n",
    "        fare = row[fare_column] if fare_column else default_fare\n",
    "        \n",
    "        if route_id not in summary:\n",
    "            summary[route_id] = {\n",
    "                'min_price': fare,\n",
    "                'stops': set(route_to_stops[route_id])\n",
    "            }\n",
    "        else:\n",
    "            summary[route_id]['min_price'] = min(summary[route_id]['min_price'], fare)\n",
    "\n",
    "    return summary\n",
    "    \n",
    "    pass  # Implementation here\n",
    "\n",
    "# BFS for optimized route planning\n",
    "def bfs_route_planner_optimized(start_stop_id, end_stop_id, initial_fare, route_summary, max_transfers=3):\n",
    "    \"\"\"\n",
    "    Use Breadth-First Search (BFS) to find the optimal route while considering fare constraints.\n",
    "\n",
    "    Args:\n",
    "        start_stop_id (int): The starting stop ID.\n",
    "        end_stop_id (int): The ending stop ID.\n",
    "        initial_fare (float): The available fare for the trip.\n",
    "        route_summary (dict): A summary of routes with fare and stop information.\n",
    "        max_transfers (int): The maximum number of transfers allowed (default is 3).\n",
    "\n",
    "    Returns:\n",
    "        list: A list representing the optimal route with stops and routes taken, structured as:\n",
    "              [\n",
    "                  (route_id (int), stop_id (int)),  # Tuple for each stop taken in the route\n",
    "                  ...\n",
    "              ]\n",
    "    \"\"\"\n",
    "    \n",
    "    queue = deque([(start_stop_id, [], 0, 0)])  # (current_stop, path, transfers_used, total_fare)\n",
    "    visited = set()\n",
    "    optimal_route = None\n",
    "\n",
    "    while queue:\n",
    "        current_stop, path, transfers_used, total_fare = queue.popleft()\n",
    "\n",
    "        if current_stop == end_stop_id:\n",
    "            if optimal_route is None or len(path) < len(optimal_route):\n",
    "                optimal_route = path\n",
    "            continue\n",
    "        \n",
    "        if transfers_used > max_transfers:\n",
    "            continue\n",
    "            \n",
    "        if (current_stop, transfers_used) in visited:\n",
    "            continue\n",
    "        visited.add((current_stop, transfers_used))\n",
    "\n",
    "        for route_id, info in route_summary.items():\n",
    "            if current_stop in info['stops']:\n",
    "                new_fare = total_fare + info['min_price']\n",
    "                if new_fare <= initial_fare:\n",
    "                    for next_stop in info['stops']:\n",
    "                        if next_stop != current_stop:\n",
    "                            new_transfers = transfers_used + 1 if path and path[-1][0] != route_id else transfers_used\n",
    "                            if new_transfers <= max_transfers:\n",
    "                                queue.append((\n",
    "                                    next_stop, \n",
    "                                    path + [(route_id, next_stop)], \n",
    "                                    new_transfers,\n",
    "                                    new_fare\n",
    "                                ))\n",
    "\n",
    "    return optimal_route or []\n",
    "    \n",
    "    pass  # Implementation here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terms initialized: DirectRoute, RouteHasStop, OptimalRoute\n",
      "Test direct_route_brute_force (2573, 1177):  Pass\n",
      "Test direct_route_brute_force (2001, 2005):  Pass\n",
      "Test query_direct_routes (2573, 1177):  Pass\n",
      "Test query_direct_routes (2001, 2005):  Pass\n",
      "Test forward_chaining (22540, 2573, 4686, 1):  Pass\n",
      "Test forward_chaining (951, 340, 300, 1):  Fail (Expected: [(294, 300, 712), (10453, 300, 712), (1211, 300, 712), (1158, 300, 712), (37, 300, 712), (1571, 300, 712), (49, 300, 712), (387, 300, 712), (1206, 300, 712), (1038, 300, 712), (10433, 300, 712), (121, 300, 712)], Got: [(37, 300, 712), (49, 300, 712), (121, 300, 712), (387, 300, 712), (1038, 300, 712), (1211, 300, 712), (1571, 300, 712), (10433, 300, 712), (10453, 300, 712)])\n",
      "Test backward_chaining (22540, 2573, 4686, 1):  Pass\n",
      "Test backward_chaining (951, 340, 300, 1):  Pass\n",
      "State: Transfer route found - 10153 to 1407 at 4686\n",
      "State: Transfer route found - 10153 to 1407 at 4686\n",
      "\n",
      "Performance Metrics:\n",
      "Execution Time: 2.1545 seconds\n",
      "Memory Usage: 2.75 MB\n",
      "Number of Steps: 1\n",
      "Test pddl_planning (22540, 2573, 4686, 1):  Pass\n",
      "State: Transfer route found - 121 to 712 at 300\n",
      "State: Transfer route found - 1038 to 712 at 300\n",
      "State: Transfer route found - 37 to 712 at 300\n",
      "State: Transfer route found - 1571 to 712 at 300\n",
      "State: Transfer route found - 1571 to 712 at 300\n",
      "State: Transfer route found - 1211 to 712 at 300\n",
      "State: Transfer route found - 387 to 712 at 300\n",
      "State: Transfer route found - 10453 to 712 at 300\n",
      "State: Transfer route found - 49 to 712 at 300\n",
      "State: Transfer route found - 10433 to 712 at 300\n",
      "\n",
      "Performance Metrics:\n",
      "Execution Time: 2.2565 seconds\n",
      "Memory Usage: 62.86 MB\n",
      "Number of Steps: 9\n",
      "Test pddl_planning (951, 340, 300, 1):  Fail (Expected: [(294, 300, 712), (10453, 300, 712), (1211, 300, 712), (1158, 300, 712), (37, 300, 712), (1571, 300, 712), (49, 300, 712), (387, 300, 712), (1206, 300, 712), (1038, 300, 712), (10433, 300, 712), (121, 300, 712)], Got: [(37, 300, 712), (49, 300, 712), (121, 300, 712), (387, 300, 712), (1038, 300, 712), (1211, 300, 712), (1571, 300, 712), (10433, 300, 712), (10453, 300, 712)])\n",
      "Test bfs_route_planner_optimized (22540, 2573, 10, 3):  Pass\n",
      "Test bfs_route_planner_optimized (4012, 4013, 10, 3):  Pass\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Sample public test inputs with expected outputs explicitly defined\n",
    "test_inputs = {\n",
    "    \"direct_route\": [\n",
    "        ((2573, 1177), [10001, 1117, 1407]),  # Input -> Expected output\n",
    "        ((2001, 2005), [10001, 1151])\n",
    "    ],\n",
    "\n",
    "    \"forward_chaining\": [\n",
    "        ((22540, 2573, 4686, 1), [(10153, 4686, 1407)]),\n",
    "        ((951, 340, 300, 1), [(294, 300, 712), (10453, 300, 712), (1211, 300, 712), (1158, 300, 712), \n",
    "                              (37, 300, 712), (1571, 300, 712), (49, 300, 712), (387, 300, 712), \n",
    "                              (1206, 300, 712), (1038, 300, 712), (10433, 300, 712), (121, 300, 712)])\n",
    "    ],\n",
    "    \"backward_chaining\": [\n",
    "        ((2573, 22540, 4686, 1), [(1407, 4686, 10153)]),\n",
    "        ((340, 951, 300, 1), [(712, 300, 121), (712, 300, 1211), (712, 300, 37), (712, 300, 387),\n",
    "                              (712, 300, 49), (712, 300, 10453), (712, 300, 1038), (712, 300, 10433),\n",
    "                              (712, 300, 1571)])\n",
    "    ],\n",
    "    \"pddl_planning\": [\n",
    "        ((22540, 2573, 4686, 1), [(10153, 4686, 1407)]),\n",
    "        ((951, 340, 300, 1), [(294, 300, 712), (10453, 300, 712), (1211, 300, 712), (1158, 300, 712), \n",
    "                              (37, 300, 712), (1571, 300, 712), (49, 300, 712), (387, 300, 712), \n",
    "                              (1206, 300, 712), (1038, 300, 712), (10433, 300, 712), (121, 300, 712)])\n",
    "    ],\n",
    "    \"bfs_route\": [\n",
    "        ((22540, 2573, 10, 3), [(10153, 4686), (1407, 2573)]),\n",
    "        ((4012, 4013, 10, 3), [(10004, 4013)])\n",
    "    ],\n",
    "\n",
    "    ### NOTE: The below values are just dummy values, the actual values are might differ! \n",
    "    \"busiest_routes\": [\n",
    "        [(123, 456), (789, 234), (567, 235), (3456, 897), (345, 345)]\n",
    "    ],\n",
    "    \"most_frequent_stops\": [\n",
    "        [(456, 456), (234, 765), (234, 765), (234, 657765), (3252, 35634)]\n",
    "    ],\n",
    "    \"busiest_stops\": [\n",
    "        [(432243, 14543), (454235, 2452), (2452, 2454), (78568, 24352), (42352, 24532)]\n",
    "    ],\n",
    "    \"stops_with_one_direct_route\": [\n",
    "        [((24527, 676), 542), ((243535, 8768), 2456), ((43262, 564), 65437),\n",
    "         ((256, 56), 245), ((266, 256), 78)]\n",
    "    ]\n",
    "}\n",
    "\n",
    "def check_output(expected, actual):\n",
    "    \"\"\"Function to compare expected and actual outputs.\"\"\"\n",
    "    return set(expected) == set(actual)\n",
    "\n",
    "def test_direct_route_brute_force():\n",
    "    for (start_stop, end_stop), expected_output in test_inputs[\"direct_route\"]:\n",
    "        actual_output = direct_route_brute_force(start_stop, end_stop)\n",
    "        print(f\"Test direct_route_brute_force ({start_stop}, {end_stop}): \", \n",
    "              \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "def test_query_direct_routes():\n",
    "    for (start_stop, end_stop), expected_output in test_inputs[\"direct_route\"]:\n",
    "        actual_output = query_direct_routes(start_stop, end_stop)\n",
    "        print(f\"Test query_direct_routes ({start_stop}, {end_stop}): \", \n",
    "              \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "def test_forward_chaining():\n",
    "    for (start_stop, end_stop, via_stop, max_transfers), expected_output in test_inputs[\"forward_chaining\"]:\n",
    "        actual_output = forward_chaining(start_stop, end_stop, via_stop, max_transfers)\n",
    "        print(f\"Test forward_chaining ({start_stop}, {end_stop}, {via_stop}, {max_transfers}): \", \n",
    "              \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "def test_backward_chaining():\n",
    "    for (end_stop, start_stop, via_stop, max_transfers), expected_output in test_inputs[\"backward_chaining\"]:\n",
    "        actual_output = backward_chaining(start_stop, end_stop, via_stop, max_transfers)\n",
    "        print(f\"Test backward_chaining ({start_stop}, {end_stop}, {via_stop}, {max_transfers}): \", \n",
    "              \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "def test_pddl_planning():\n",
    "    for (start_stop, end_stop, via_stop, max_transfers), expected_output in test_inputs[\"pddl_planning\"]:\n",
    "        actual_output = pddl_planning(start_stop, end_stop, via_stop, max_transfers)\n",
    "        print(f\"Test pddl_planning ({start_stop}, {end_stop}, {via_stop}, {max_transfers}): \", \n",
    "              \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "def test_bfs_route_planner():\n",
    "    for (start_stop, end_stop, initial_fare, max_transfers), expected_output in test_inputs[\"bfs_route\"]:\n",
    "        pruned_df = prune_data(merged_fare_df, initial_fare)\n",
    "        route_summary = compute_route_summary(pruned_df)\n",
    "        actual_output = bfs_route_planner_optimized(start_stop, end_stop, initial_fare, route_summary, max_transfers)\n",
    "        print(f\"Test bfs_route_planner_optimized ({start_stop}, {end_stop}, {initial_fare}, {max_transfers}): \", \n",
    "              \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "# New test functions for the additional queries\n",
    "\n",
    "def test_get_busiest_routes():\n",
    "    expected_output = test_inputs[\"busiest_routes\"][0]\n",
    "    actual_output = get_busiest_routes()\n",
    "    print(f\"Test get_busiest_routes: \", \n",
    "          \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "def test_get_most_frequent_stops():\n",
    "    expected_output = test_inputs[\"most_frequent_stops\"][0]\n",
    "    actual_output = get_most_frequent_stops()\n",
    "    print(f\"Test get_most_frequent_stops: \", \n",
    "          \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "def test_get_top_5_busiest_stops():\n",
    "    expected_output = test_inputs[\"busiest_stops\"][0]\n",
    "    actual_output = get_top_5_busiest_stops()\n",
    "    print(f\"Test get_top_5_busiest_stops: \", \n",
    "          \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "def test_get_stops_with_one_direct_route():\n",
    "    expected_output = test_inputs[\"stops_with_one_direct_route\"][0]\n",
    "    actual_output = get_stops_with_one_direct_route()\n",
    "    print(f\"Test get_stops_with_one_direct_route: \", \n",
    "          \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_kb()  # Ensure the data is loaded before testing\n",
    "    merged_fare_df = get_merged_fare_df()  # Use the function to retrieve the DataFrame\n",
    "    initialize_datalog()\n",
    "    \n",
    "    # Run all tests\n",
    "    test_direct_route_brute_force()\n",
    "    test_query_direct_routes()\n",
    "    test_forward_chaining()\n",
    "    test_backward_chaining()\n",
    "    test_pddl_planning()\n",
    "    test_bfs_route_planner()\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import psutil\n",
    "import os   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during fact assertion: name 'route_stop' is not defined\n",
      "Test pddl_planning (22540, 2573, 4686, 1):  Fail (Expected: [(10153, 4686, 1407)], Got: [])\n",
      "Error during fact assertion: name 'route_stop' is not defined\n",
      "Test pddl_planning (951, 340, 300, 1):  Fail (Expected: [(294, 300, 712), (10453, 300, 712), (1211, 300, 712), (1158, 300, 712), (37, 300, 712), (1571, 300, 712), (49, 300, 712), (387, 300, 712), (1206, 300, 712), (1038, 300, 712), (10433, 300, 712), (121, 300, 712)], Got: [])\n",
      "Test bfs_route_planner_optimized (22540, 2573, 10, 3):  Pass\n",
      "Test bfs_route_planner_optimized (4012, 4013, 10, 3):  Pass\n"
     ]
    }
   ],
   "source": [
    "test_pddl_planning()\n",
    "test_bfs_route_planner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: Transfer route found - 10153 to 1407 at 4686\n",
      "State: Transfer route found - 10153 to 1407 at 4686\n",
      "\n",
      "Performance Metrics:\n",
      "Execution Time: 2.4773 seconds\n",
      "Memory Usage: -2.84 MB\n",
      "Number of Steps: 1\n",
      "Test pddl_planning (22540, 2573, 4686, 1):  Pass\n",
      "State: Transfer route found - 121 to 712 at 300\n",
      "State: Transfer route found - 1211 to 712 at 300\n",
      "State: Transfer route found - 49 to 712 at 300\n",
      "State: Transfer route found - 1571 to 712 at 300\n",
      "State: Transfer route found - 1571 to 712 at 300\n",
      "State: Transfer route found - 10453 to 712 at 300\n",
      "State: Transfer route found - 387 to 712 at 300\n",
      "State: Transfer route found - 10433 to 712 at 300\n",
      "State: Transfer route found - 1038 to 712 at 300\n",
      "State: Transfer route found - 37 to 712 at 300\n",
      "\n",
      "Performance Metrics:\n",
      "Execution Time: 2.4973 seconds\n",
      "Memory Usage: 55.45 MB\n",
      "Number of Steps: 9\n",
      "Test pddl_planning (951, 340, 300, 1):  Fail (Expected: [(294, 300, 712), (10453, 300, 712), (1211, 300, 712), (1158, 300, 712), (37, 300, 712), (1571, 300, 712), (49, 300, 712), (387, 300, 712), (1206, 300, 712), (1038, 300, 712), (10433, 300, 712), (121, 300, 712)], Got: [(37, 300, 712), (49, 300, 712), (121, 300, 712), (387, 300, 712), (1038, 300, 712), (1211, 300, 712), (1571, 300, 712), (10433, 300, 712), (10453, 300, 712)])\n"
     ]
    }
   ],
   "source": [
    "test_pddl_planning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
