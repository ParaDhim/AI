{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate for AI Assignment â€” Knowledge Representation, Reasoning and Planning\n",
    "# CSE 643\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import networkx as nx\n",
    "from pyDatalog import pyDatalog\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "## ****IMPORTANT****\n",
    "## Don't import or use any other libraries other than defined above\n",
    "## Otherwise your code file will be rejected in the automated testing\n",
    "\n",
    "# ------------------ Global Variables ------------------\n",
    "route_to_stops = defaultdict(list)  # Mapping of route IDs to lists of stops\n",
    "trip_to_route = {}                   # Mapping of trip IDs to route IDs\n",
    "stop_trip_count = defaultdict(int)    # Count of trips for each stop\n",
    "fare_rules = {}                      # Mapping of route IDs to fare information\n",
    "merged_fare_df = None                # To be initialized in create_kb()\n",
    "\n",
    "# Load static data from GTFS (General Transit Feed Specification) files\n",
    "df_stops = pd.read_csv('GTFS/stops.txt')\n",
    "df_routes = pd.read_csv('GTFS/routes.txt')\n",
    "df_stop_times = pd.read_csv('GTFS/stop_times.txt')\n",
    "df_fare_attributes = pd.read_csv('GTFS/fare_attributes.txt')\n",
    "df_trips = pd.read_csv('GTFS/trips.txt')\n",
    "df_fare_rules = pd.read_csv('GTFS/fare_rules.txt')\n",
    "\n",
    "# ------------------ Function Definitions ------------------\n",
    "\n",
    "# Function to create knowledge base from the loaded data\n",
    "def create_kb():\n",
    "    \"\"\"\n",
    "    Create knowledge base by populating global variables with information from loaded datasets.\n",
    "    It establishes the relationships between routes, trips, stops, and fare rules.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    global route_to_stops, trip_to_route, stop_trip_count, fare_rules, merged_fare_df\n",
    "\n",
    "    # Create trip_id to route_id mapping\"\"\"\n",
    "    trip_to_route = defaultdict(list)\n",
    "    for _, row in df_trips.iterrows():\n",
    "        trip_to_route[row['trip_id']].append(row['route_id'])\n",
    "        \n",
    "    # Map route_id to a list of stops in order of their sequence\"\"\"\n",
    "    route_to_stops = defaultdict(list)\n",
    "    sorted_stop_times = df_stop_times.sort_values(['trip_id', 'stop_sequence'])\n",
    "    sorted_stop_times.head\n",
    "    for trip_id, stop_grp in sorted_stop_times.groupby('trip_id'):\n",
    "        if trip_id in trip_to_route:\n",
    "            route_id = trip_to_route[trip_id][0]\n",
    "            stops = stop_grp['stop_id'].to_list()\n",
    "            route_to_stops[route_id].extend(stops)\n",
    "            \n",
    "    # Ensure each route only has unique stops\"\"\"\n",
    "    for route_id in route_to_stops:\n",
    "        # Use dict.fromkeys() to preserve order while removing duplicates\n",
    "        route_to_stops[route_id] = list(dict.fromkeys(route_to_stops[route_id]))\n",
    "    \n",
    "    # Count trips per stop\"\"\"\n",
    "    stop_trip_count = dict(df_stop_times['stop_id'].value_counts())\n",
    "\n",
    "    # Create fare rules for routes\n",
    "    fare_rules = {}\n",
    "    for i in range(len(df_fare_rules['route_id'])):\n",
    "        route_id = df_fare_rules['route_id'][i]\n",
    "        fare_id = df_fare_rules['fare_id'][i]\n",
    "\n",
    "        if route_id not in fare_rules:\n",
    "            fare_rules[route_id] = []\n",
    "\n",
    "        fare_rules[route_id].append(fare_id)\n",
    "\n",
    "    # Merge fare rules and attributes into a single DataFrame\n",
    "    merged_fare_df = pd.merge(\n",
    "        df_fare_rules,\n",
    "        df_fare_attributes,\n",
    "        on='fare_id',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "# Function to find the top 5 busiest routes based on the number of trips\n",
    "def get_busiest_routes():\n",
    "    \"\"\"\n",
    "    Identify the top 5 busiest routes based on trip counts.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains:\n",
    "              - route_id (int): The ID of the route.\n",
    "              - trip_count (int): The number of trips for that route.\n",
    "    \"\"\"\n",
    "    route_trip_counts = defaultdict(int)\n",
    "    for trip_id, routes in trip_to_route.items():\n",
    "        # Since we stored routes as a list in trip_to_route, take the first route\n",
    "        route_id = routes[0]\n",
    "        route_trip_counts[route_id] += 1\n",
    "    \n",
    "    res = sorted(route_trip_counts.items(), key = lambda ele: ele[1], reverse = True)\n",
    "    \n",
    "    # Return top 5 routes\n",
    "    return res[:5]\n",
    "    pass  # Implementation here\n",
    "\n",
    "# Function to find the top 5 stops with the most frequent trips\n",
    "def get_most_frequent_stops():\n",
    "    \"\"\"\n",
    "    Identify the top 5 stops with the highest number of trips.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains:\n",
    "              - stop_id (int): The ID of the stop.\n",
    "              - trip_count (int): The number of trips for that stop.\n",
    "    \"\"\"\n",
    "    res = sorted(stop_trip_count.items(), key = lambda ele: ele[1], reverse = True)\n",
    "    \n",
    "    # Return top 5 routes\n",
    "    return res[:5]\n",
    "    pass  # Implementation here\n",
    "\n",
    "# Function to find the top 5 busiest stops based on the number of routes passing through them\n",
    "def get_top_5_busiest_stops():\n",
    "    \"\"\"\n",
    "    Identify the top 5 stops with the highest number of different routes.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains:\n",
    "              - stop_id (int): The ID of the stop.\n",
    "              - route_count (int): The number of routes passing through that stop.\n",
    "    \"\"\"\n",
    "    stop_routes = defaultdict(set)\n",
    "    for route_id, stops in route_to_stops.items():\n",
    "        for stop_id in stops:\n",
    "            stop_routes[stop_id].add(route_id)\n",
    "            \n",
    "    stop_counts = []\n",
    "    for stop_id, routes in stop_routes.items():\n",
    "        route_count = len(routes)\n",
    "        stop_counts.append((stop_id, route_count))\n",
    "\n",
    "    res = sorted(stop_counts, key = lambda ele: ele[1], reverse = True)\n",
    "    \n",
    "    return res[:5]\n",
    "    pass  # Implementation here\n",
    "\n",
    "# Function to identify the top 5 pairs of stops with only one direct route between them\n",
    "def get_stops_with_one_direct_route():\n",
    "    \"\"\"\n",
    "    Identify the top 5 pairs of consecutive stops (start and end) connected by exactly one direct route. \n",
    "    The pairs are sorted by the combined frequency of trips passing through both stops.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains:\n",
    "              - pair (tuple): A tuple with two stop IDs (stop_1, stop_2).\n",
    "              - route_id (int): The ID of the route connecting the two stops.\n",
    "    \"\"\"\n",
    "    connections = {}\n",
    "    \n",
    "    for route_id, stops in route_to_stops.items():\n",
    "        for i in range(len(stops) - 1):\n",
    "            current_stop = stops[i]\n",
    "            next_stop = stops[i + 1]\n",
    "            \n",
    "            # same order for consistency\n",
    "            stop_pair = (current_stop, next_stop) if current_stop < next_stop else (next_stop, current_stop)\n",
    "\n",
    "            \n",
    "            # Add the route to this pair's list of routes\n",
    "            if stop_pair not in connections:\n",
    "                connections[stop_pair] = []\n",
    "            connections[stop_pair].append(route_id)\n",
    "    \n",
    "    result = []\n",
    "    for stop_pair, routes in connections.items():\n",
    "        if len(routes) == 1:\n",
    "            result.append((stop_pair, routes[0]))\n",
    "    \n",
    "    return result\n",
    "    pass  # Implementation here\n",
    "\n",
    "# Function to get merged fare DataFrame\n",
    "# No need to change this function\n",
    "def get_merged_fare_df():\n",
    "    \"\"\"\n",
    "    Retrieve the merged fare DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The merged fare DataFrame containing fare rules and attributes.\n",
    "    \"\"\"\n",
    "    global merged_fare_df\n",
    "    return merged_fare_df\n",
    "\n",
    "# Visualize the stop-route graph interactively\n",
    "def visualize_stop_route_graph_interactive(route_to_stops):\n",
    "    \"\"\"\n",
    "    Visualize the stop-route graph using Plotly for interactive exploration.\n",
    "\n",
    "    Args:\n",
    "        route_to_stops (dict): A dictionary mapping route IDs to lists of stops.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Step 1: Create a network graph\n",
    "    grph = nx.Graph()\n",
    "    \n",
    "    # Step 2: Add edges (connections between stops) from each route\n",
    "    edge_colors = []\n",
    "    edge_labels = []\n",
    "    \n",
    "    unique_routes = list(route_to_stops.keys())\n",
    "    color_palette = plt.cm.get_cmap('hsv')(np.linspace(0, 1, len(unique_routes)))\n",
    "    \n",
    "    rt_color_map = {}\n",
    "    for i in range (len(unique_routes)):\n",
    "        route_id = unique_routes[i]\n",
    "        r, g, b, _ = color_palette[i]\n",
    "        \n",
    "        color_string = f'rgb({int(r*255)},{int(g*255)},{int(b*255)})'\n",
    "        rt_color_map[route_id] = color_string\n",
    "    \n",
    "    for route_id, stops_on_route in route_to_stops.items():\n",
    "        route_name = df_routes[df_routes['route_id'] == route_id]['route_long_name'].iloc[0]\n",
    "        for i in range(len(stops_on_route) - 1):\n",
    "            current_stop = stops_on_route[i]\n",
    "            next_stop = stops_on_route[i + 1]\n",
    "            \n",
    "            grph.add_edge(current_stop, next_stop)\n",
    "            \n",
    "            edge_colors.append(rt_color_map[route_id])\n",
    "            edge_labels.append(f\"Route: {route_name}\")\n",
    "        \n",
    "    # Step 3: Calculate state_positions for the graph\n",
    "    stop_positions = nx.shell_layout(grph)\n",
    "    \n",
    "    # Step 4: Create edge trace\n",
    "    edge_trace = []\n",
    "    for i in range (len(grph.edges())):\n",
    "        edge = list(grph.edges())[i]\n",
    "        color = edge_colors[i]\n",
    "        label = edge_labels[i]\n",
    "        \n",
    "        x0, y0 = stop_positions[edge[0]]\n",
    "        x1, y1 = stop_positions[edge[1]]\n",
    "        \n",
    "        \n",
    "        edge_trace.append(\n",
    "            go.Scatter(\n",
    "                x=[x0, x1, None],\n",
    "                y=[y0, y1, None],\n",
    "                line=dict(width=2, color=color),\n",
    "                hoverinfo='text',\n",
    "                text=label,\n",
    "                mode='lines'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    # Step 5: Create node trace\n",
    "    node_x = []\n",
    "    node_y = []\n",
    "    node_text = []\n",
    "    \n",
    "    for node in grph.nodes():\n",
    "        x, y = stop_positions[node]\n",
    "        node_x.append(x)\n",
    "        node_y.append(y)\n",
    "        # Get stop name for hover text\n",
    "        stop_name = df_stops[df_stops['stop_id'] == node]['stop_name'].iloc[0]\n",
    "        node_text.append(f\"Stop: {stop_name}<br>ID: {node}\")\n",
    "    \n",
    "    node_trace = go.Scatter(\n",
    "        x=node_x,\n",
    "        y=node_y,\n",
    "        mode='markers+text',\n",
    "        hoverinfo='text',\n",
    "        text=node_text,\n",
    "        marker=dict(\n",
    "            size=10,\n",
    "            color='lightblue',\n",
    "            line=dict(width=2, color='darkblue')\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Step 6: Create the figure\n",
    "    fig = go.Figure(data=edge_trace + [node_trace],\n",
    "                   layout=go.Layout(\n",
    "                       title='Transit Network Map',\n",
    "                       showlegend=False,\n",
    "                       hovermode='closest',\n",
    "                       margin=dict(b=0, l=0, r=0, t=40),\n",
    "                       xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                       yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                       plot_bgcolor='white'\n",
    "                   ))\n",
    "    \n",
    "    # Add a legend showing route colors\n",
    "    for route_id in unique_routes:\n",
    "        route_name = df_routes[df_routes['route_id'] == route_id]['route_long_name'].iloc[0]\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[None],\n",
    "            y=[None],\n",
    "            mode='lines',\n",
    "            name=route_name,\n",
    "            line=dict(color=rt_color_map[route_id], width=2),\n",
    "            showlegend=True\n",
    "        ))\n",
    "    \n",
    "    # Step 7: Show the plot\n",
    "    fig.show()\n",
    "    pass  # Implementation here\n",
    "\n",
    "# Brute-Force Approach for finding direct routes\n",
    "def direct_route_brute_force(start_stop, end_stop):\n",
    "    \"\"\"\n",
    "    Find all valid routes between two stops using a brute-force method.\n",
    "\n",
    "    Args:\n",
    "        start_stop (int): The ID of the starting stop.\n",
    "        end_stop (int): The ID of the ending stop.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of route IDs (int) that connect the two stops directly.\n",
    "    \"\"\"\n",
    "    \n",
    "    dir_routes = []\n",
    "    for route_id, stops in route_to_stops.items():\n",
    "        if start_stop in stops and end_stop in stops:\n",
    "            # Check if start_stop comes before end_stop in the sequence\n",
    "            if stops.index(start_stop) < stops.index(end_stop):\n",
    "                dir_routes.append(route_id)\n",
    "    return dir_routes\n",
    "    \n",
    "    \n",
    "    \n",
    "    # dir_routes = []\n",
    "    # for route_id, stops in route_to_stops.items():\n",
    "    #     start_indexes = [i for i, stop in enumerate(stops) if stop == start_stop]\n",
    "    #     end_indexes = [i for i, stop in enumerate(stops) if stop == end_stop]\n",
    "    #     for start_idx in start_indexes:\n",
    "    #         for end_idx in end_indexes:\n",
    "    #             if end_idx > start_idx:\n",
    "    #                 dir_routes.append(route_id)\n",
    "    #                 break\n",
    "    #         if route_id in dir_routes:\n",
    "    #             break\n",
    "            \n",
    "    # return sorted(dir_routes)\n",
    "    \n",
    "    pass  # Implementation here\n",
    "\n",
    "# Initialize Datalog predicates for reasoning\n",
    "pyDatalog.create_terms('RouteHasStop, DirectRoute, OptimalRoute, X, Y, Z, R, R1, R2')  \n",
    "def initialize_datalog():\n",
    "    \"\"\"\n",
    "    Initialize Datalog terms and predicates for reasoning about routes and stops.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    pyDatalog.clear()  # Clear previous terms\n",
    "    print(\"Terms initialized: DirectRoute, RouteHasStop, OptimalRoute\")  # Confirmation print\n",
    "\n",
    "    # Define Datalog predicates\n",
    "\n",
    "    create_kb()  # Populate the knowledge base\n",
    "    add_route_data(route_to_stops)  # Add route data to Datalog\n",
    "    \n",
    "    \n",
    "# Adding route data to Datalog\n",
    "def add_route_data(route_to_stops):\n",
    "    \"\"\"\n",
    "    Add the route data to Datalog for reasoning.\n",
    "\n",
    "    Args:\n",
    "        route_to_stops (dict): A dictionary mapping route IDs to lists of stops.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    for route_id, stops in route_to_stops.items():\n",
    "        for stop_id in stops:\n",
    "            +RouteHasStop(route_id, stop_id)\n",
    "\n",
    "# Function to query direct routes between two stops\n",
    "def query_direct_routes(start, end):\n",
    "    \"\"\"\n",
    "    Query for direct routes between two stops.\n",
    "\n",
    "    Args:\n",
    "        start (int): The ID of the starting stop.\n",
    "        end (int): The ID of the ending stop.\n",
    "\n",
    "    Returns:\n",
    "        list: A sorted list of route IDs (str) connecting the two stops.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Query for routes that contain both start and end stops\n",
    "    query_result = pyDatalog.ask(f'RouteHasStop(R, {start}) & RouteHasStop(R, {end})')\n",
    "    \n",
    "    # Process the results, assuming each answer contains a single route_id\n",
    "    if query_result:\n",
    "        return sorted(set(route_id[0] for route_id in query_result.answers))\n",
    "    return []\n",
    "    \n",
    "    pass  # Implementation here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "route_to_stops = defaultdict(list)  # Maps route_id to an ordered list of stop_ids\n",
    "trip_to_route = {}  # Maps trip_id to route_id\n",
    "stop_trip_count = defaultdict(int)  # Maps stop_id to count of trips stopping there\n",
    "fare_rules = {}  # Maps route_id to fare information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terms initialized: DirectRoute, RouteHasStop, OptimalRoute\n"
     ]
    }
   ],
   "source": [
    "create_kb()  # Ensure the data is loaded before testing\n",
    "merged_fare_df = get_merged_fare_df()  # Use the function to retrieve the DataFrame\n",
    "initialize_datalog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1323,\n",
       " 2713,\n",
       " 1324,\n",
       " 1325,\n",
       " 1326,\n",
       " 1327,\n",
       " 1328,\n",
       " 2714,\n",
       " 1329,\n",
       " 1330,\n",
       " 22511,\n",
       " 2600,\n",
       " 2601,\n",
       " 2602,\n",
       " 2603,\n",
       " 2604,\n",
       " 1159,\n",
       " 1160,\n",
       " 1161,\n",
       " 1162,\n",
       " 22530,\n",
       " 973,\n",
       " 974,\n",
       " 975,\n",
       " 22532,\n",
       " 22533,\n",
       " 22534,\n",
       " 22535,\n",
       " 4051,\n",
       " 981,\n",
       " 982,\n",
       " 983,\n",
       " 984,\n",
       " 985,\n",
       " 986,\n",
       " 987,\n",
       " 988,\n",
       " 989,\n",
       " 990,\n",
       " 991,\n",
       " 992,\n",
       " 993,\n",
       " 994,\n",
       " 995,\n",
       " 996,\n",
       " 997,\n",
       " 2605,\n",
       " 2606,\n",
       " 2607,\n",
       " 2608,\n",
       " 2609,\n",
       " 2009,\n",
       " 4511,\n",
       " 1438,\n",
       " 1440,\n",
       " 1441,\n",
       " 951,\n",
       " 952,\n",
       " 953,\n",
       " 954,\n",
       " 955,\n",
       " 293,\n",
       " 3436,\n",
       " 3437,\n",
       " 3438,\n",
       " 3439,\n",
       " 3440,\n",
       " 3441,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 936,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "route_to_stops[294]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample public test inputs with expected outputs explicitly defined\n",
    "test_inputs = {\n",
    "    \"direct_route\": [\n",
    "        ((2573, 1177), [10001, 1117, 1407]),  # Input -> Expected output\n",
    "        ((2001, 2005), [10001, 1151])\n",
    "    ],\n",
    "\n",
    "    \"forward_chaining\": [\n",
    "        ((22540, 2573, 4686, 1), [(10153, 4686, 1407)]),\n",
    "        ((951, 340, 300, 1), [(294, 300, 712), (10453, 300, 712), (1211, 300, 712), (1158, 300, 712), \n",
    "                              (37, 300, 712), (1571, 300, 712), (49, 300, 712), (387, 300, 712), \n",
    "                              (1206, 300, 712), (1038, 300, 712), (10433, 300, 712), (121, 300, 712)])\n",
    "    ],\n",
    "    \"backward_chaining\": [\n",
    "        ((2573, 22540, 4686, 1), [(1407, 4686, 10153)]),\n",
    "        ((340, 951, 300, 1), [(712, 300, 121), (712, 300, 1211), (712, 300, 37), (712, 300, 387),\n",
    "                              (712, 300, 49), (712, 300, 10453), (712, 300, 1038), (712, 300, 10433),\n",
    "                              (712, 300, 1571)])\n",
    "    ],\n",
    "    \"pddl_planning\": [\n",
    "        ((22540, 2573, 4686, 1), [(10153, 4686, 1407)]),\n",
    "        ((951, 340, 300, 1), [(294, 300, 712), (10453, 300, 712), (1211, 300, 712), (1158, 300, 712), \n",
    "                              (37, 300, 712), (1571, 300, 712), (49, 300, 712), (387, 300, 712), \n",
    "                              (1206, 300, 712), (1038, 300, 712), (10433, 300, 712), (121, 300, 712)])\n",
    "    ],\n",
    "    \"bfs_route\": [\n",
    "        ((22540, 2573, 10, 3), [(10153, 4686), (1407, 2573)]),\n",
    "        ((4012, 4013, 10, 3), [(10004, 4013)])\n",
    "    ],\n",
    "\n",
    "    ### NOTE: The below values are just dummy values, the actual values are might differ! \n",
    "    \"busiest_routes\": [\n",
    "        [(123, 456), (789, 234), (567, 235), (3456, 897), (345, 345)]\n",
    "    ],\n",
    "    \"most_frequent_stops\": [\n",
    "        [(456, 456), (234, 765), (234, 765), (234, 657765), (3252, 35634)]\n",
    "    ],\n",
    "    \"busiest_stops\": [\n",
    "        [(432243, 14543), (454235, 2452), (2452, 2454), (78568, 24352), (42352, 24532)]\n",
    "    ],\n",
    "    \"stops_with_one_direct_route\": [\n",
    "        [((24527, 676), 542), ((243535, 8768), 2456), ((43262, 564), 65437),\n",
    "         ((256, 56), 245), ((266, 256), 78)]\n",
    "    ]\n",
    "}\n",
    "\n",
    "def check_output(expected, actual):\n",
    "    \"\"\"Function to compare expected and actual outputs.\"\"\"\n",
    "    return set(expected) == set(actual)\n",
    "\n",
    "def test_direct_route_brute_force():\n",
    "    for (start_stop, end_stop), expected_output in test_inputs[\"direct_route\"]:\n",
    "        actual_output = direct_route_brute_force(start_stop, end_stop)\n",
    "        print(f\"Test direct_route_brute_force ({start_stop}, {end_stop}): \", \n",
    "              \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "def test_query_direct_routes():\n",
    "    for (start_stop, end_stop), expected_output in test_inputs[\"direct_route\"]:\n",
    "        actual_output = query_direct_routes(start_stop, end_stop)\n",
    "        print(f\"Test query_direct_routes ({start_stop}, {end_stop}): \", \n",
    "              \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "def test_forward_chaining():\n",
    "    for (start_stop, end_stop, via_stop, max_transfers), expected_output in test_inputs[\"forward_chaining\"]:\n",
    "        actual_output = forward_chaining(start_stop, end_stop, via_stop, max_transfers)\n",
    "        print(f\"Test forward_chaining ({start_stop}, {end_stop}, {via_stop}, {max_transfers}): \", \n",
    "              \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "def test_backward_chaining():\n",
    "    for (end_stop, start_stop, via_stop, max_transfers), expected_output in test_inputs[\"backward_chaining\"]:\n",
    "        actual_output = backward_chaining(start_stop, end_stop, via_stop, max_transfers)\n",
    "        print(f\"Test backward_chaining ({start_stop}, {end_stop}, {via_stop}, {max_transfers}): \", \n",
    "              \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "def test_pddl_planning():\n",
    "    for (start_stop, end_stop, via_stop, max_transfers), expected_output in test_inputs[\"pddl_planning\"]:\n",
    "        actual_output = pddl_planning(start_stop, end_stop, via_stop, max_transfers)\n",
    "        print(f\"Test pddl_planning ({start_stop}, {end_stop}, {via_stop}, {max_transfers}): \", \n",
    "              \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "def test_bfs_route_planner():\n",
    "    for (start_stop, end_stop, initial_fare, max_transfers), expected_output in test_inputs[\"bfs_route\"]:\n",
    "        pruned_df = prune_data(merged_fare_df, initial_fare)\n",
    "        route_summary = compute_route_summary(pruned_df)\n",
    "        actual_output = bfs_route_planner_optimized(start_stop, end_stop, initial_fare, route_summary, max_transfers)\n",
    "        print(f\"Test bfs_route_planner_optimized ({start_stop}, {end_stop}, {initial_fare}, {max_transfers}): \", \n",
    "              \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "# New test functions for the additional queries\n",
    "\n",
    "def test_get_busiest_routes():\n",
    "    expected_output = test_inputs[\"busiest_routes\"][0]\n",
    "    actual_output = get_busiest_routes()\n",
    "    print(f\"Test get_busiest_routes: \", \n",
    "          \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "def test_get_most_frequent_stops():\n",
    "    expected_output = test_inputs[\"most_frequent_stops\"][0]\n",
    "    actual_output = get_most_frequent_stops()\n",
    "    print(f\"Test get_most_frequent_stops: \", \n",
    "          \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "def test_get_top_5_busiest_stops():\n",
    "    expected_output = test_inputs[\"busiest_stops\"][0]\n",
    "    actual_output = get_top_5_busiest_stops()\n",
    "    print(f\"Test get_top_5_busiest_stops: \", \n",
    "          \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "def test_get_stops_with_one_direct_route():\n",
    "    expected_output = test_inputs[\"stops_with_one_direct_route\"][0]\n",
    "    actual_output = get_stops_with_one_direct_route()\n",
    "    print(f\"Test get_stops_with_one_direct_route: \", \n",
    "          \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     create_kb()  # Ensure the data is loaded before testing\n",
    "#     merged_fare_df = get_merged_fare_df()  # Use the function to retrieve the DataFrame\n",
    "#     initialize_datalog()\n",
    "    \n",
    "#     # Run all tests\n",
    "#     test_direct_route_brute_force()\n",
    "#     test_query_direct_routes()\n",
    "#     test_forward_chaining()\n",
    "#     test_backward_chaining()\n",
    "#     test_pddl_planning()\n",
    "#     test_bfs_route_planner()\n",
    "    \n",
    "#     # Run additional tests for the new queries\n",
    "#     test_get_busiest_routes()\n",
    "#     test_get_most_frequent_stops()\n",
    "#     test_get_top_5_busiest_stops()\n",
    "#     test_get_stops_with_one_direct_route()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test direct_route_brute_force (2573, 1177):  Pass\n",
      "Test direct_route_brute_force (2001, 2005):  Pass\n",
      "Test query_direct_routes (2573, 1177):  Pass\n",
      "Test query_direct_routes (2001, 2005):  Pass\n"
     ]
    }
   ],
   "source": [
    "test_direct_route_brute_force()\n",
    "test_query_direct_routes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_chaining(start_stop_id, end_stop_id, stop_id_to_include, max_transfers):\n",
    "    \"\"\"\n",
    "    Perform forward chaining to find optimal routes considering transfers.\n",
    "    \n",
    "    Args:\n",
    "        start_stop_id (int): The starting stop ID.\n",
    "        end_stop_id (int): The ending stop ID.\n",
    "        stop_id_to_include (int): The stop ID that must be included in the path.\n",
    "        max_transfers (int): Maximum number of transfers allowed.\n",
    "    \n",
    "    Returns:\n",
    "        list: List of paths that satisfy the constraints.\n",
    "    \"\"\"\n",
    "    import time\n",
    "    import psutil\n",
    "    start_time = time.time()\n",
    "    \n",
    "    paths = []\n",
    "    visited_routes = set()\n",
    "    \n",
    "    # Step 1: Find all routes that contain the start stop\n",
    "    start_routes = set()\n",
    "    for route_id, stops in route_to_stops.items():\n",
    "        if start_stop_id in stops:\n",
    "            start_routes.add(route_id)\n",
    "    \n",
    "    # Step 2: For each starting route, try to find paths\n",
    "    for start_route in start_routes:\n",
    "        if start_route in visited_routes:\n",
    "            continue\n",
    "            \n",
    "        visited_routes.add(start_route)\n",
    "        stops = route_to_stops[start_route]\n",
    "        \n",
    "        try:\n",
    "            start_idx = stops.index(start_stop_id)\n",
    "            \n",
    "            # Check if the via stop is in this route\n",
    "            if stop_id_to_include in stops:\n",
    "                via_idx = stops.index(stop_id_to_include)\n",
    "                \n",
    "                # Check if end stop is also in this route\n",
    "                if end_stop_id in stops:\n",
    "                    end_idx = stops.index(end_stop_id)\n",
    "                    \n",
    "                    # Verify the sequence is valid (start -> via -> end or start -> end -> via)\n",
    "                    if ((start_idx < via_idx < end_idx) or \n",
    "                        (start_idx > via_idx > end_idx)):\n",
    "                        path = [(start_route, stop) for stop in stops[min(start_idx, end_idx):max(start_idx, end_idx) + 1]]\n",
    "                        paths.append(path)\n",
    "                else:\n",
    "                    # Need to find connecting routes\n",
    "                    for route2, stops2 in route_to_stops.items():\n",
    "                        if route2 != start_route and stop_id_to_include in stops2 and end_stop_id in stops2:\n",
    "                            # Valid transfer found\n",
    "                            if len(paths) == 0 or len(paths[-1]) <= max_transfers + 1:\n",
    "                                path1 = [(start_route, stop) for stop in stops[start_idx:via_idx + 1]]\n",
    "                                end_idx2 = stops2.index(end_stop_id)\n",
    "                                via_idx2 = stops2.index(stop_id_to_include)\n",
    "                                path2 = [(route2, stop) for stop in stops2[via_idx2:end_idx2 + 1]]\n",
    "                                paths.append(path1 + path2[1:])  # Avoid duplicating via stop\n",
    "        \n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    # Calculate execution metrics\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    memory_usage = psutil.Process().memory_info().rss / 1024 / 1024  # Convert to MB\n",
    "    \n",
    "    print(f\"Forward Chaining Metrics:\")\n",
    "    print(f\"Execution Time: {execution_time:.4f} seconds\")\n",
    "    print(f\"Memory Usage: {memory_usage:.2f} MB\")\n",
    "    print(f\"Number of paths found: {len(paths)}\")\n",
    "    \n",
    "    return paths\n",
    "\n",
    "def backward_chaining(start_stop_id, end_stop_id, stop_id_to_include, max_transfers):\n",
    "    \"\"\"\n",
    "    Perform backward chaining to find optimal routes considering transfers.\n",
    "    \n",
    "    Args:\n",
    "        start_stop_id (int): The starting stop ID.\n",
    "        end_stop_id (int): The ending stop ID.\n",
    "        stop_id_to_include (int): The stop ID that must be included in the path.\n",
    "        max_transfers (int): Maximum number of transfers allowed.\n",
    "    \n",
    "    Returns:\n",
    "        list: List of paths that satisfy the constraints.\n",
    "    \"\"\"\n",
    "    import time\n",
    "    import psutil\n",
    "    start_time = time.time()\n",
    "    \n",
    "    paths = []\n",
    "    visited_routes = set()\n",
    "    \n",
    "    # Step 1: Find all routes that contain the end stop\n",
    "    end_routes = set()\n",
    "    for route_id, stops in route_to_stops.items():\n",
    "        if end_stop_id in stops:\n",
    "            end_routes.add(route_id)\n",
    "    \n",
    "    # Step 2: Work backwards from end stop\n",
    "    for end_route in end_routes:\n",
    "        if end_route in visited_routes:\n",
    "            continue\n",
    "            \n",
    "        visited_routes.add(end_route)\n",
    "        stops = route_to_stops[end_route]\n",
    "        \n",
    "        try:\n",
    "            end_idx = stops.index(end_stop_id)\n",
    "            \n",
    "            # Check if via stop is in this route\n",
    "            if stop_id_to_include in stops:\n",
    "                via_idx = stops.index(stop_id_to_include)\n",
    "                \n",
    "                # Check if start stop is also in this route\n",
    "                if start_stop_id in stops:\n",
    "                    start_idx = stops.index(start_stop_id)\n",
    "                    \n",
    "                    # Verify sequence is valid\n",
    "                    if ((start_idx < via_idx < end_idx) or \n",
    "                        (start_idx > via_idx > end_idx)):\n",
    "                        path = [(end_route, stop) for stop in stops[min(start_idx, end_idx):max(start_idx, end_idx) + 1]]\n",
    "                        paths.append(path)\n",
    "                else:\n",
    "                    # Need to find connecting routes from start to via\n",
    "                    for route1, stops1 in route_to_stops.items():\n",
    "                        if route1 != end_route and start_stop_id in stops1 and stop_id_to_include in stops1:\n",
    "                            # Valid transfer found\n",
    "                            if len(paths) == 0 or len(paths[-1]) <= max_transfers + 1:\n",
    "                                start_idx1 = stops1.index(start_stop_id)\n",
    "                                via_idx1 = stops1.index(stop_id_to_include)\n",
    "                                path1 = [(route1, stop) for stop in stops1[start_idx1:via_idx1 + 1]]\n",
    "                                path2 = [(end_route, stop) for stop in stops[via_idx:end_idx + 1]]\n",
    "                                paths.append(path1 + path2)\n",
    "        \n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    # Calculate execution metrics\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    memory_usage = psutil.Process().memory_info().rss / 1024 / 1024  # Convert to MB\n",
    "    \n",
    "    print(f\"Backward Chaining Metrics:\")\n",
    "    print(f\"Execution Time: {execution_time:.4f} seconds\")\n",
    "    print(f\"Memory Usage: {memory_usage:.2f} MB\")\n",
    "    print(f\"Number of paths found: {len(paths)}\")\n",
    "    \n",
    "    return paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def forward_chaining(start_stop_id, end_stop_id, stop_id_to_include, max_transfers):\n",
    "#     import time\n",
    "#     import psutil\n",
    "#     start_time = time.time()\n",
    "#     paths = []\n",
    "\n",
    "#     # Step 1: Find all routes that contain the start stop and via stop\n",
    "#     start_via_routes = []\n",
    "#     for route_id, stops in route_to_stops.items():\n",
    "#         if start_stop_id in stops and stop_id_to_include in stops:\n",
    "#             start_via_routes.append((route_id, stops.index(start_stop_id), stops.index(stop_id_to_include)))\n",
    "\n",
    "#     # Step 2: Find all routes that contain the via stop and end stop\n",
    "#     via_end_routes = []\n",
    "#     for route_id, stops in route_to_stops.items():\n",
    "#         if stop_id_to_include in stops and end_stop_id in stops:\n",
    "#             via_end_routes.append((route_id, stops.index(stop_id_to_include), stops.index(end_stop_id)))\n",
    "\n",
    "#     # Step 3: Combine the routes\n",
    "#     for start_route, start_idx, via_idx in start_via_routes:\n",
    "#         for end_route, via_idx2, end_idx in via_end_routes:\n",
    "#             if start_route != end_route:  # Ensure one transfer\n",
    "#                 path1 = [(start_route, stop) for stop in route_to_stops[start_route][start_idx:via_idx + 1]]\n",
    "#                 path2 = [(end_route, stop) for stop in route_to_stops[end_route][via_idx2:end_idx + 1]]\n",
    "#                 paths.append(path1 + path2[1:])  # Avoid duplicating via stop\n",
    "\n",
    "#     # Calculate execution metrics\n",
    "#     end_time = time.time()\n",
    "#     execution_time = end_time - start_time\n",
    "#     memory_usage = psutil.Process().memory_info().rss / 1024 / 1024  # Convert to MB\n",
    "#     print(f\"Forward Chaining Metrics:\")\n",
    "#     print(f\"Execution Time: {execution_time:.4f} seconds\")\n",
    "#     print(f\"Memory Usage: {memory_usage:.2f} MB\")\n",
    "#     print(f\"Number of paths found: {len(paths)}\")\n",
    "\n",
    "#     for i, path in enumerate(paths):\n",
    "#         print(f\"Path {i+1}:\")\n",
    "#         for route_id, stop_id in path:\n",
    "#             print(f\"Route ID: {route_id}, Stop ID: {stop_id}\")\n",
    "#         print()  # Empty line for readability\n",
    "\n",
    "#     return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def forward_chaining(start_stop_id, end_stop_id, stop_id_to_include, max_transfers):\n",
    "#     \"\"\"Perform forward chaining to find optimal routes considering transfers.\n",
    "    \n",
    "#     Args:\n",
    "#         start_stop_id (int): The starting stop ID.\n",
    "#         end_stop_id (int): The ending stop ID.\n",
    "#         stop_id_to_include (int): The stop ID where a transfer occurs.\n",
    "#         max_transfers (int): The maximum number of transfers allowed.\n",
    "        \n",
    "#     Returns:\n",
    "#         list: A list of tuples (route_id, via_stop, end_stop) representing valid paths\n",
    "#     \"\"\"\n",
    "#     result_paths = set()\n",
    "    \n",
    "#     # Find routes containing the required stops\n",
    "#     for route_id, stops in route_to_stops.items():\n",
    "#         try:\n",
    "#             # Check if all required stops are in this route\n",
    "#             if stop_id_to_include in stops and (start_stop_id in stops or end_stop_id in stops):\n",
    "#                 via_idx = stops.index(stop_id_to_include)\n",
    "                \n",
    "#                 # Case 1: Direct route containing all stops\n",
    "#                 if start_stop_id in stops and end_stop_id in stops:\n",
    "#                     start_idx = stops.index(start_stop_id)\n",
    "#                     end_idx = stops.index(end_stop_id)\n",
    "                    \n",
    "#                     # Check if the route is valid (stops are in correct order)\n",
    "#                     if min(start_idx, end_idx) <= via_idx <= max(start_idx, end_idx):\n",
    "#                         result_paths.add((route_id, stop_id_to_include, end_stop_id))\n",
    "                \n",
    "#                 # Case 2: Route contains via stop and either start or end\n",
    "#                 elif max_transfers >= 1:\n",
    "#                     # Find connecting routes\n",
    "#                     for other_route, other_stops in route_to_stops.items():\n",
    "#                         if other_route != route_id:\n",
    "#                             if start_stop_id in stops and end_stop_id in other_stops:\n",
    "#                                 if stop_id_to_include in other_stops:\n",
    "#                                     result_paths.add((other_route, stop_id_to_include, end_stop_id))\n",
    "#                             elif start_stop_id in other_stops and end_stop_id in stops:\n",
    "#                                 if stop_id_to_include in other_stops:\n",
    "#                                     result_paths.add((route_id, stop_id_to_include, end_stop_id))\n",
    "                                    \n",
    "#         except ValueError:\n",
    "#             continue\n",
    "    \n",
    "#     # Convert set to list for return\n",
    "#     return list(result_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_chaining(start_stop_id, end_stop_id, stop_id_to_include, max_transfers):\n",
    "    \"\"\"Perform forward chaining to find optimal routes considering transfers.\n",
    "    \n",
    "    Args:\n",
    "        start_stop_id (int): The starting stop ID.\n",
    "        end_stop_id (int): The ending stop ID.\n",
    "        stop_id_to_include (int): The stop ID where a transfer occurs.\n",
    "        max_transfers (int): The maximum number of transfers allowed.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of tuples (route_id, via_stop, end_stop) representing valid paths\n",
    "    \"\"\"\n",
    "    result_paths = set()\n",
    "    \n",
    "    # Find routes containing the required stops\n",
    "    for route_id, stops in route_to_stops.items():\n",
    "        try:\n",
    "            # Check if all required stops are in this route\n",
    "            if stop_id_to_include in stops and (start_stop_id in stops or end_stop_id in stops):\n",
    "                via_idx = stops.index(stop_id_to_include)\n",
    "                \n",
    "                # Case 1: Direct route containing all stops\n",
    "                if start_stop_id in stops and end_stop_id in stops:\n",
    "                    start_idx = stops.index(start_stop_id)\n",
    "                    end_idx = stops.index(end_stop_id)\n",
    "                    \n",
    "                    # Check if the route is valid (stops are in correct order)\n",
    "                    if min(start_idx, end_idx) <= via_idx <= max(start_idx, end_idx):\n",
    "                        result_paths.add((route_id, stop_id_to_include, end_stop_id))\n",
    "                        print(\"yes\")\n",
    "                \n",
    "                # Case 2: Route contains via stop and either start or end\n",
    "                elif max_transfers >= 1:\n",
    "                    # Find connecting routes\n",
    "                    for other_route, other_stops in route_to_stops.items():\n",
    "                        if other_route != route_id:\n",
    "                            if start_stop_id in stops and end_stop_id in other_stops:\n",
    "                                if stop_id_to_include in other_stops:\n",
    "                                    print((route_id, stop_id_to_include, other_route))\n",
    "                                    result_paths.add((route_id, stop_id_to_include, other_route))\n",
    "                                    print(\"yes2\")\n",
    "                            elif start_stop_id in other_stops and end_stop_id in stops:\n",
    "                                if stop_id_to_include in other_stops:\n",
    "                                    result_paths.add((route_id, stop_id_to_include, end_stop_id))\n",
    "                                    print((route_id, stop_id_to_include, route_id))\n",
    "                                    print(\"yes3\")\n",
    "                                    \n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    # Convert set to list for return\n",
    "    return sorted(list(result_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_chaining(start_stop_id, end_stop_id, stop_id_to_include, max_transfers):\n",
    "    \"\"\"Perform forward chaining to find optimal routes considering transfers.\n",
    "    \n",
    "    Args:\n",
    "        start_stop_id (int): The starting stop ID.\n",
    "        end_stop_id (int): The ending stop ID.\n",
    "        stop_id_to_include (int): The stop ID where a transfer occurs.\n",
    "        max_transfers (int): The maximum number of transfers allowed.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of tuples (route_id, via_stop, end_stop) representing valid paths\n",
    "    \"\"\"\n",
    "    result_paths = set()\n",
    "    \n",
    "    # Find routes containing the required stops\n",
    "    for route_id, stops in route_to_stops.items():\n",
    "        try:\n",
    "            # Check if all required stops are in this route\n",
    "            if stop_id_to_include in stops and (start_stop_id in stops or end_stop_id in stops):\n",
    "                via_idx = stops.index(stop_id_to_include)\n",
    "                # print(route_id)\n",
    "                # Case 1: Direct route containing all stops\n",
    "                if start_stop_id in stops and end_stop_id in stops:\n",
    "                    start_idx = stops.index(start_stop_id)\n",
    "                    end_idx = stops.index(end_stop_id)\n",
    "                    \n",
    "                    # Check if the route is valid (stops are in correct order)\n",
    "                    if min(start_idx, end_idx) <= via_idx <= max(start_idx, end_idx):\n",
    "                        result_paths.add((route_id, stop_id_to_include, end_stop_id))\n",
    "                        # print(\"yes\")\n",
    "                        \n",
    "                \n",
    "                # Case 2: Route contains via stop and either start or end\n",
    "                elif max_transfers >= 1:\n",
    "                    # Find connecting routes\n",
    "                    for other_route, other_stops in route_to_stops.items():\n",
    "                        # print(other_route)\n",
    "                        if other_route != route_id:\n",
    "                            # print(other_route)\n",
    "                            if start_stop_id in stops and end_stop_id in other_stops:\n",
    "                                # print(other_route)\n",
    "                                if stop_id_to_include in other_stops:\n",
    "                                    \n",
    "                                    result_paths.add((route_id, stop_id_to_include, other_route))\n",
    "                                    # print((route_id, stop_id_to_include, other_route))\n",
    "                                    # print(\"yes2\")\n",
    "                                    # print(other_route)\n",
    "                                    # print(end_stop_id)\n",
    "                            elif start_stop_id in other_stops and end_stop_id in stops:\n",
    "                                # print((other_route, stop_id_to_include, route_id,start_stop_id, end_stop_id))\n",
    "                                # print(other_stops)\n",
    "                                if stop_id_to_include in other_stops:\n",
    "                                    # print(other_route)\n",
    "                                    # print((other_route, stop_id_to_include, route_id,start_stop_id, end_stop_id))\n",
    "                                    result_paths.add((other_route, stop_id_to_include, route_id))\n",
    "                                    # print((other_route, stop_id_to_include, route_id))\n",
    "                                    # print(\"yes3\")\n",
    "                                    # print(other_route)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    # Convert set to list for return\n",
    "    return sorted(list(result_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test forward_chaining (22540, 2573, 4686, 1):  Pass\n",
      "Test forward_chaining (951, 340, 300, 1):  Fail (Expected: [(294, 300, 712), (10453, 300, 712), (1211, 300, 712), (1158, 300, 712), (37, 300, 712), (1571, 300, 712), (49, 300, 712), (387, 300, 712), (1206, 300, 712), (1038, 300, 712), (10433, 300, 712), (121, 300, 712)], Got: [(37, 300, 712), (49, 300, 712), (121, 300, 712), (387, 300, 712), (1038, 300, 712), (1211, 300, 712), (1571, 300, 712), (10433, 300, 712), (10453, 300, 712)])\n"
     ]
    }
   ],
   "source": [
    "test_forward_chaining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def backward_chaining(start_stop_id, end_stop_id, stop_id_to_include, max_transfers):\n",
    "#     \"\"\"Perform backward chaining to find optimal routes considering transfers.\n",
    "    \n",
    "#     Args:\n",
    "#         start_stop_id (int): The starting stop ID.\n",
    "#         end_stop_id (int): The ending stop ID.\n",
    "#         stop_id_to_include (int): The stop ID where a transfer occurs.\n",
    "#         max_transfers (int): The maximum number of transfers allowed.\n",
    "    \n",
    "#     Returns:\n",
    "#         list: A list of tuples (route_id, via_stop, end_stop) representing valid paths\n",
    "#     \"\"\"\n",
    "#     result_paths = []\n",
    "#     seen_paths = set()  # To avoid duplicates while maintaining order\n",
    "    \n",
    "#     # Start from the end stop and work backwards\n",
    "#     for route_id, stops in route_to_stops.items():\n",
    "#         try:\n",
    "#             # Check if the route contains the end stop and via stop\n",
    "#             if end_stop_id in stops and stop_id_to_include in stops:\n",
    "#                 end_idx = stops.index(end_stop_id)\n",
    "#                 via_idx = stops.index(stop_id_to_include)\n",
    "                \n",
    "#                 # Case 1: Direct route containing all stops\n",
    "#                 if start_stop_id in stops:\n",
    "#                     start_idx = stops.index(start_stop_id)\n",
    "#                     # Check if the route is valid (stops are in correct order)\n",
    "#                     if min(via_idx, end_idx) <= start_idx <= max(via_idx, end_idx):\n",
    "#                         path_tuple = (route_id, stop_id_to_include, end_stop_id)\n",
    "#                         path_key = str(path_tuple)  # Convert to string for hashing\n",
    "#                         print(\"yes1\")\n",
    "#                         print(path_tuple)\n",
    "#                         if path_key not in seen_paths:\n",
    "#                             seen_paths.add(path_key)\n",
    "#                             result_paths.append(path_tuple)\n",
    "                \n",
    "#                 # Case 2: Route contains end stop and via stop, need to find connecting route\n",
    "#                 elif max_transfers >= 1:\n",
    "#                     # Look for routes that can connect to our current route at the via stop\n",
    "#                     for connecting_route, connecting_stops in route_to_stops.items():\n",
    "#                         if connecting_route != route_id:\n",
    "#                             # Check if connecting route has start stop and via stop\n",
    "#                             if start_stop_id in connecting_stops and stop_id_to_include in connecting_stops:\n",
    "#                                 conn_start_idx = connecting_stops.index(start_stop_id)\n",
    "#                                 conn_via_idx = connecting_stops.index(stop_id_to_include)\n",
    "                                \n",
    "#                                 # Verify the order in connecting route\n",
    "#                                 if min(conn_start_idx, conn_via_idx) <= max(conn_start_idx, conn_via_idx):\n",
    "#                                     path_tuple = (connecting_route, stop_id_to_include, route_id)\n",
    "#                                     print(path_tuple)\n",
    "#                                     print(\"yes2\")\n",
    "#                                     path_key = str(path_tuple)\n",
    "#                                     if path_key not in seen_paths:\n",
    "#                                         seen_paths.add(path_key)\n",
    "#                                         result_paths.append(path_tuple)\n",
    "                                        \n",
    "            \n",
    "#             # Additional case: Route contains start stop and via stop\n",
    "#             elif start_stop_id in stops and stop_id_to_include in stops and max_transfers >= 1:\n",
    "#                 start_idx = stops.index(start_stop_id)\n",
    "#                 via_idx = stops.index(stop_id_to_include)\n",
    "                \n",
    "#                 # Look for routes that can connect from via stop to end stop\n",
    "#                 for next_route, next_stops in route_to_stops.items():\n",
    "#                     if next_route != route_id:\n",
    "#                         if end_stop_id in next_stops and stop_id_to_include in next_stops:\n",
    "#                             next_end_idx = next_stops.index(end_stop_id)\n",
    "#                             next_via_idx = next_stops.index(stop_id_to_include)\n",
    "                            \n",
    "#                             # Verify the order in next route\n",
    "#                             if min(next_via_idx, next_end_idx) <= max(next_via_idx, next_end_idx):\n",
    "#                                 path_tuple = (route_id, stop_id_to_include, next_route)\n",
    "#                                 print(\"yes3\")\n",
    "#                                 print(path_tuple)\n",
    "#                                 path_key = str(path_tuple)\n",
    "#                                 if path_key not in seen_paths:\n",
    "#                                     seen_paths.add(path_key)\n",
    "#                                     result_paths.append(path_tuple)\n",
    "                                \n",
    "#         except ValueError:\n",
    "#             continue\n",
    "    \n",
    "#     # Sort the results for consistent output\n",
    "#     return sorted(result_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_chaining(start_stop_id, end_stop_id, stop_id_to_include, max_transfers):\n",
    "    \"\"\"Perform backward chaining to find optimal routes considering transfers.\n",
    "    \n",
    "    Args:\n",
    "        start_stop_id (int): The starting stop ID.\n",
    "        end_stop_id (int): The ending stop ID.\n",
    "        stop_id_to_include (int): The stop ID where a transfer occurs.\n",
    "        max_transfers (int): The maximum number of transfers allowed.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of tuples (route_id, via_stop, end_stop) representing valid paths\n",
    "    \"\"\"\n",
    "    result_paths = []\n",
    "    seen_paths = set()  # To avoid duplicates while maintaining order\n",
    "    \n",
    "    # Start from the end stop and work backwards\n",
    "    for route_id, stops in route_to_stops.items():\n",
    "        try:\n",
    "            # Check if the route contains the end stop and via stop\n",
    "            if end_stop_id in stops and stop_id_to_include in stops:\n",
    "                end_idx = stops.index(end_stop_id)\n",
    "                via_idx = stops.index(stop_id_to_include)\n",
    "                \n",
    "                # Case 1: Direct route containing all stops\n",
    "                if start_stop_id in stops:\n",
    "                    start_idx = stops.index(start_stop_id)\n",
    "                    # Check if the route is valid (stops are in correct order)\n",
    "                    if min(via_idx, end_idx) <= start_idx <= max(via_idx, end_idx):\n",
    "                        path_tuple = (end_stop_id, stop_id_to_include, route_id)\n",
    "                        path_key = str(path_tuple)  # Convert to string for hashing\n",
    "                        print(\"yes1\")\n",
    "                        print(path_tuple)\n",
    "                        if path_key not in seen_paths:\n",
    "                            seen_paths.add(path_key)\n",
    "                            result_paths.append(path_tuple)\n",
    "                \n",
    "                # Case 2: Route contains end stop and via stop, need to find connecting route\n",
    "                elif max_transfers >= 1:\n",
    "                    # Look for routes that can connect to our current route at the via stop\n",
    "                    for connecting_route, connecting_stops in route_to_stops.items():\n",
    "                        if connecting_route != route_id:\n",
    "                            # Check if connecting route has start stop and via stop\n",
    "                            if start_stop_id in connecting_stops and stop_id_to_include in connecting_stops:\n",
    "                                conn_start_idx = connecting_stops.index(start_stop_id)\n",
    "                                conn_via_idx = connecting_stops.index(stop_id_to_include)\n",
    "                                \n",
    "                                # Verify the order in connecting route\n",
    "                                if min(conn_start_idx, conn_via_idx) <= max(conn_start_idx, conn_via_idx):\n",
    "                                    path_tuple = (route_id, stop_id_to_include, connecting_route)\n",
    "                                    print(\"yes2\")\n",
    "                                    print(path_tuple)\n",
    "                                    path_key = str(path_tuple)\n",
    "                                    if path_key not in seen_paths:\n",
    "                                        seen_paths.add(path_key)\n",
    "                                        result_paths.append(path_tuple)\n",
    "                                        \n",
    "            \n",
    "            # Additional case: Route contains start stop and via stop\n",
    "            elif start_stop_id in stops and stop_id_to_include in stops and max_transfers >= 1:\n",
    "                start_idx = stops.index(start_stop_id)\n",
    "                via_idx = stops.index(stop_id_to_include)\n",
    "                \n",
    "                # Look for routes that can connect from via stop to end stop\n",
    "                for next_route, next_stops in route_to_stops.items():\n",
    "                    if next_route != route_id:\n",
    "                        if end_stop_id in next_stops and stop_id_to_include in next_stops:\n",
    "                            next_end_idx = next_stops.index(end_stop_id)\n",
    "                            next_via_idx = next_stops.index(stop_id_to_include)\n",
    "                            \n",
    "                            # Verify the order in next route\n",
    "                            if min(next_via_idx, next_end_idx) <= max(next_via_idx, next_end_idx):\n",
    "                                path_tuple = (next_route, stop_id_to_include, route_id)\n",
    "                                print(\"yes3\")\n",
    "                                print(path_tuple)\n",
    "                                path_key = str(path_tuple)\n",
    "                                if path_key not in seen_paths:\n",
    "                                    seen_paths.add(path_key)\n",
    "                                    result_paths.append(path_tuple)\n",
    "                                \n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    # Sort the results for consistent output\n",
    "    return sorted(result_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes3\n",
      "(1407, 4686, 10153)\n",
      "yes2\n",
      "(1407, 4686, 10153)\n",
      "Test backward_chaining (22540, 2573, 4686, 1):  Pass\n",
      "yes3\n",
      "(712, 300, 1038)\n",
      "yes3\n",
      "(712, 300, 10433)\n",
      "yes3\n",
      "(712, 300, 10453)\n",
      "yes3\n",
      "(712, 300, 1211)\n",
      "yes3\n",
      "(712, 300, 121)\n",
      "yes3\n",
      "(712, 300, 1571)\n",
      "yes3\n",
      "(712, 300, 37)\n",
      "yes3\n",
      "(712, 300, 387)\n",
      "yes3\n",
      "(712, 300, 49)\n",
      "yes2\n",
      "(712, 300, 1038)\n",
      "yes2\n",
      "(712, 300, 10433)\n",
      "yes2\n",
      "(712, 300, 10453)\n",
      "yes2\n",
      "(712, 300, 1211)\n",
      "yes2\n",
      "(712, 300, 121)\n",
      "yes2\n",
      "(712, 300, 1571)\n",
      "yes2\n",
      "(712, 300, 37)\n",
      "yes2\n",
      "(712, 300, 387)\n",
      "yes2\n",
      "(712, 300, 49)\n",
      "Test backward_chaining (951, 340, 300, 1):  Pass\n"
     ]
    }
   ],
   "source": [
    "test_backward_chaining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import psutil\n",
    "# import sys\n",
    "# from datetime import datetime\n",
    "\n",
    "# # PDDL-style planning implementation\n",
    "# def pddl_planning(start_stop_id, end_stop_id, stop_id_to_include, max_transfers):\n",
    "#     \"\"\"\n",
    "#     Implement PDDL-style planning to find routes with optional transfers.\n",
    "    \n",
    "#     Uses forward chaining with PDDL-style actions and state tracking.\n",
    "#     Measures execution time and memory usage for analysis.\n",
    "#     \"\"\"\n",
    "#     start_time = time.time()\n",
    "#     process = psutil.Process()\n",
    "#     initial_memory = process.memory_info().rss / (1024 * 1024)  # Convert to MB\n",
    "    \n",
    "#     # print(\"\\nPDDL Planning Analysis:\")\n",
    "#     # print(f\"Initial State: Stop {start_stop_id}\")\n",
    "#     # print(f\"Goal State: Stop {end_stop_id}\")\n",
    "#     # print(f\"Required Transfer Stop: {stop_id_to_include}\")\n",
    "#     # print(f\"Max Transfers Allowed: {max_transfers}\\n\")\n",
    "    \n",
    "#     class State:\n",
    "#         def __init__(self, current_stop, visited_stops, current_route, transfers_used, path):\n",
    "#             self.current_stop = current_stop\n",
    "#             self.visited_stops = visited_stops\n",
    "#             self.current_route = current_route\n",
    "#             self.transfers_used = transfers_used\n",
    "#             self.path = path\n",
    "            \n",
    "#     # Initialize actions using PyDatalog\n",
    "#     pyDatalog.create_terms('Board, Transfer, ValidRoute, ValidTransfer, X, Y, Z, R, R1, R2')\n",
    "    \n",
    "#     # Define PDDL-style actions\n",
    "#     valid_routes = []\n",
    "#     visited_states = set()\n",
    "#     initial_state = State(start_stop_id, {start_stop_id}, None, 0, [])\n",
    "#     states_to_explore = [initial_state]\n",
    "    \n",
    "#     # print(\"Starting PDDL Planning Process...\")\n",
    "    \n",
    "#     while states_to_explore:\n",
    "#         current_state = states_to_explore.pop(0)\n",
    "#         state_key = (current_state.current_stop, current_state.current_route, \n",
    "#                     current_state.transfers_used)\n",
    "        \n",
    "#         if state_key in visited_states:\n",
    "#             continue\n",
    "            \n",
    "#         visited_states.add(state_key)\n",
    "        \n",
    "#         # print(f\"\\nExploring State:\")\n",
    "#         # print(f\"Current Stop: {current_state.current_stop}\")\n",
    "#         # print(f\"Current Route: {current_state.current_route}\")\n",
    "#         # print(f\"Transfers Used: {current_state.transfers_used}\")\n",
    "        \n",
    "#         # Check if goal reached\n",
    "#         if (current_state.current_stop == end_stop_id and \n",
    "#             stop_id_to_include in current_state.visited_stops):\n",
    "#             route_path = current_state.path\n",
    "#             if route_path and len(route_path) >= 2:  # Must have at least two stops\n",
    "#                 valid_routes.append(route_path)\n",
    "#                 # print(f\"Found Valid Route: {route_path}\")\n",
    "#             continue\n",
    "            \n",
    "#         # Action 1: Board a route\n",
    "#         for route_id, stops in route_to_stops.items():\n",
    "#             if current_state.current_stop in stops:\n",
    "#                 next_stop_idx = stops.index(current_state.current_stop)\n",
    "                \n",
    "#                 # Check forward direction\n",
    "#                 for next_idx in range(next_stop_idx + 1, len(stops)):\n",
    "#                     next_stop = stops[next_idx]\n",
    "#                     if next_stop not in current_state.visited_stops:\n",
    "#                         new_path = current_state.path + [(route_id, next_stop)]\n",
    "#                         new_state = State(\n",
    "#                             next_stop,\n",
    "#                             current_state.visited_stops | {next_stop},\n",
    "#                             route_id,\n",
    "#                             current_state.transfers_used,\n",
    "#                             new_path\n",
    "#                         )\n",
    "#                         states_to_explore.append(new_state)\n",
    "#                         # print(f\"Action: Board route {route_id} to stop {next_stop}\")\n",
    "                        \n",
    "#         # Action 2: Transfer between routes\n",
    "#         if current_state.transfers_used < max_transfers:\n",
    "#             for route_id, stops in route_to_stops.items():\n",
    "#                 if (route_id != current_state.current_route and \n",
    "#                     current_state.current_stop in stops):\n",
    "#                     new_state = State(\n",
    "#                         current_state.current_stop,\n",
    "#                         current_state.visited_stops,\n",
    "#                         route_id,\n",
    "#                         current_state.transfers_used + 1,\n",
    "#                         current_state.path\n",
    "#                     )\n",
    "#                     states_to_explore.append(new_state)\n",
    "#                     # print(f\"Action: Transfer to route {route_id}\")\n",
    "                    \n",
    "#     # Convert paths to required format\n",
    "#     formatted_routes = []\n",
    "#     for path in valid_routes:\n",
    "#         for i in range(len(path) - 1):\n",
    "#             if path[i][1] == stop_id_to_include:\n",
    "#                 formatted_routes.append((path[i][0], path[i][1], path[i+1][0]))\n",
    "                \n",
    "#     # Measure performance metrics\n",
    "#     end_time = time.time()\n",
    "#     final_memory = process.memory_info().rss / (1024 * 1024)\n",
    "#     execution_time = end_time - start_time\n",
    "#     memory_usage = final_memory - initial_memory\n",
    "    \n",
    "#     # print(\"\\nPerformance Metrics:\")\n",
    "#     # print(f\"Execution Time: {execution_time:.2f} seconds\")\n",
    "#     # print(f\"Memory Usage: {memory_usage:.2f} MB\")\n",
    "#     # print(f\"States Explored: {len(visited_states)}\")\n",
    "#     # print(f\"Valid Routes Found: {len(formatted_routes)}\")\n",
    "    \n",
    "#     return sorted(list(set(formatted_routes)))\n",
    "\n",
    "# def prune_data(merged_fare_df, initial_fare):\n",
    "#     \"\"\"\n",
    "#     Filter fare data based on an initial fare limit.\n",
    "#     \"\"\"\n",
    "#     # Filter routes where price is less than or equal to initial fare\n",
    "#     pruned_df = merged_fare_df[merged_fare_df['price'] <= initial_fare].copy()\n",
    "    \n",
    "#     print(f\"Pruned {len(merged_fare_df) - len(pruned_df)} routes exceeding fare limit\")\n",
    "#     return pruned_df\n",
    "\n",
    "# def compute_route_summary(pruned_df):\n",
    "#     \"\"\"\n",
    "#     Generate a summary of routes based on fare information.\n",
    "#     \"\"\"\n",
    "#     route_summary = {}\n",
    "    \n",
    "#     # Group by route_id and compute minimum price\n",
    "#     for route_id in pruned_df['route_id'].unique():\n",
    "#         route_fares = pruned_df[pruned_df['route_id'] == route_id]\n",
    "#         min_price = route_fares['price'].min()\n",
    "        \n",
    "#         # Get all stops for this route\n",
    "#         route_stops = set(route_to_stops.get(route_id, []))\n",
    "        \n",
    "#         route_summary[route_id] = {\n",
    "#             'min_price': min_price,\n",
    "#             'stops': route_stops\n",
    "#         }\n",
    "        \n",
    "#     return route_summary\n",
    "\n",
    "# def bfs_route_planner_optimized(start_stop_id, end_stop_id, initial_fare, route_summary, max_transfers=3):\n",
    "#     \"\"\"\n",
    "#     Optimized BFS route planner considering fare constraints.\n",
    "#     \"\"\"\n",
    "#     queue = deque([(start_stop_id, [], 0, 0)])  # (stop, path, total_fare, transfers)\n",
    "#     visited = set()  # Track visited (stop, route) combinations\n",
    "#     valid_paths = []\n",
    "    \n",
    "#     while queue:\n",
    "#         current_stop, path, total_fare, transfers = queue.popleft()\n",
    "        \n",
    "#         # Check if we've reached the destination\n",
    "#         if current_stop == end_stop_id:\n",
    "#             valid_paths.append((path, total_fare))\n",
    "#             continue\n",
    "            \n",
    "#         # Get all possible routes from current stop\n",
    "#         for route_id, info in route_summary.items():\n",
    "#             if current_stop in info['stops']:\n",
    "#                 # Skip if we've exceeded transfers\n",
    "#                 if path and path[-1][0] != route_id and transfers >= max_transfers:\n",
    "#                     continue\n",
    "                    \n",
    "#                 # Calculate new fare\n",
    "#                 new_fare = total_fare + info['min_price']\n",
    "#                 if new_fare > initial_fare:\n",
    "#                     continue\n",
    "                    \n",
    "#                 # Find next possible stops on this route\n",
    "#                 current_idx = list(info['stops']).index(current_stop)\n",
    "#                 next_stops = list(info['stops'])[current_idx + 1:]\n",
    "                \n",
    "#                 for next_stop in next_stops:\n",
    "#                     state = (next_stop, route_id)\n",
    "#                     if state not in visited:\n",
    "#                         visited.add(state)\n",
    "#                         new_transfers = transfers\n",
    "#                         if path and path[-1][0] != route_id:\n",
    "#                             new_transfers += 1\n",
    "                        \n",
    "#                         new_path = path + [(route_id, next_stop)]\n",
    "#                         queue.append((next_stop, new_path, new_fare, new_transfers))\n",
    "                        \n",
    "#     # Return the path with minimum fare that reaches the destination\n",
    "#     if valid_paths:\n",
    "#         valid_paths.sort(key=lambda x: x[1])  # Sort by fare\n",
    "#         return valid_paths[0][0]  # Return path with minimum fare\n",
    "#     return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prune fare data based on an initial fare limit\n",
    "def prune_data(merged_fare_df, initial_fare):\n",
    "    \"\"\"\n",
    "    Filter fare data based on an initial fare limit.\n",
    "    Args:\n",
    "        merged_fare_df (DataFrame): The merged fare DataFrame.\n",
    "        initial_fare (float): The maximum fare allowed.\n",
    "    Returns:\n",
    "        DataFrame: A filtered DataFrame containing only routes within the fare limit.\n",
    "    \"\"\"\n",
    "    return merged_fare_df[merged_fare_df['cost'] <= initial_fare]\n",
    "\n",
    "# Pre-computation of Route Summary\n",
    "def compute_route_summary(pruned_df):\n",
    "    \"\"\"\n",
    "    Generate a summary of routes based on fare information.\n",
    "    Args:\n",
    "        pruned_df (DataFrame): The filtered DataFrame containing fare information.\n",
    "    Returns:\n",
    "        dict: A summary of routes with the following structure:\n",
    "        {\n",
    "            route_id (int): {\n",
    "                'min_price': float, # The minimum fare for the route\n",
    "                'stops': set        # A set of stop IDs for that route\n",
    "            }\n",
    "        }\n",
    "    \"\"\"\n",
    "    summary = {}\n",
    "    for _, row in pruned_df.iterrows():\n",
    "        route_id = row['route_id']\n",
    "        fare = row['cost']\n",
    "        \n",
    "        if route_id not in summary:\n",
    "            summary[route_id] = {\n",
    "                'min_price': fare,\n",
    "                'stops': set(route_to_stops[route_id])\n",
    "            }\n",
    "        else:\n",
    "            summary[route_id]['min_price'] = min(summary[route_id]['min_price'], fare)\n",
    "\n",
    "    return summary\n",
    "\n",
    "# PDDL-style planning for route finding\n",
    "def pddl_planning(start_stop_id, end_stop_id, stop_id_to_include, max_transfers):\n",
    "    \"\"\"\n",
    "    Implement PDDL-style planning to find routes with optional transfers.\n",
    "    Args:\n",
    "        start_stop_id (int): The starting stop ID.\n",
    "        end_stop_id (int): The ending stop ID.\n",
    "        stop_id_to_include (int): The stop ID for a transfer.\n",
    "        max_transfers (int): The maximum number of transfers allowed.\n",
    "    Returns:\n",
    "        list: A list of unique paths (list of tuples) that satisfy the criteria, where each tuple contains:\n",
    "              - route_id (int): The ID of the route.\n",
    "              - stop_id (int): The ID of the stop.\n",
    "    \"\"\"\n",
    "    paths = []\n",
    "    \n",
    "    def explore_path(current_stop, transfers_used, current_path):\n",
    "        if current_stop == end_stop_id:\n",
    "            paths.append(current_path)\n",
    "            return\n",
    "        if transfers_used > max_transfers:\n",
    "            return\n",
    "        \n",
    "        for route_id, stops in route_to_stops.items():\n",
    "            if current_stop in stops:\n",
    "                for stop in stops:\n",
    "                    if stop != current_stop and (stop_id_to_include is None or stop_id_to_include in stops):\n",
    "                        explore_path(stop, transfers_used + 1, current_path + [(route_id, stop)])\n",
    "\n",
    "    explore_path(start_stop_id, 0, [])\n",
    "    return paths\n",
    "\n",
    "# BFS for optimized route planning\n",
    "def bfs_route_planner_optimized(start_stop_id, end_stop_id, initial_fare, route_summary, max_transfers=3):\n",
    "    \"\"\"\n",
    "    Use Breadth-First Search (BFS) to find the optimal route while considering fare constraints.\n",
    "    Args:\n",
    "        start_stop_id (int): The starting stop ID.\n",
    "        end_stop_id (int): The ending stop ID.\n",
    "        initial_fare (float): The available fare for the trip.\n",
    "        route_summary (dict): A summary of routes with fare and stop information.\n",
    "        max_transfers (int): The maximum number of transfers allowed (default is 3).\n",
    "    Returns:\n",
    "        list: A list representing the optimal route with stops and routes taken, structured as:\n",
    "        [\n",
    "            (route_id (int), stop_id (int)), # Tuple for each stop taken in the route\n",
    "            ...\n",
    "        ]\n",
    "    \"\"\"\n",
    "    queue = deque([(start_stop_id, [], 0)])  # (current_stop, path, transfers_used)\n",
    "    visited = set()\n",
    "    optimal_route = None\n",
    "\n",
    "    while queue:\n",
    "        current_stop, path, transfers_used = queue.popleft()\n",
    "\n",
    "        if current_stop == end_stop_id:\n",
    "            if optimal_route is None or len(path) < len(optimal_route):\n",
    "                optimal_route = path\n",
    "            continue\n",
    "        \n",
    "        if (current_stop, transfers_used) in visited:\n",
    "            continue\n",
    "        visited.add((current_stop, transfers_used))\n",
    "\n",
    "        for route_id, stops in route_to_stops.items():\n",
    "            if current_stop in stops:\n",
    "                for next_stop in stops:\n",
    "                    if next_stop != current_stop:\n",
    "                        fare = route_summary[route_id]['min_price']\n",
    "                        if fare <= initial_fare:\n",
    "                            queue.append((next_stop, path + [(route_id, next_stop)], transfers_used + 1 if next_stop == stop_id_to_include else transfers_used))\n",
    "\n",
    "    return optimal_route or []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "# Function to prune fare data based on an initial fare limit\n",
    "def prune_data(merged_fare_df, initial_fare):\n",
    "    \"\"\"\n",
    "    Filter fare data based on an initial fare limit.\n",
    "    Args:\n",
    "        merged_fare_df (DataFrame): The merged fare DataFrame.\n",
    "        initial_fare (float): The maximum fare allowed.\n",
    "    Returns:\n",
    "        DataFrame: A filtered DataFrame containing only routes within the fare limit.\n",
    "    \"\"\"\n",
    "    # Assuming the fare column is named 'fare' instead of 'cost'\n",
    "    return merged_fare_df[merged_fare_df['fare'] <= initial_fare]\n",
    "\n",
    "# Pre-computation of Route Summary\n",
    "def compute_route_summary(pruned_df, route_to_stops):\n",
    "    \"\"\"\n",
    "    Generate a summary of routes based on fare information.\n",
    "    Args:\n",
    "        pruned_df (DataFrame): The filtered DataFrame containing fare information.\n",
    "        route_to_stops (dict): Mapping of route_ids to their stops.\n",
    "    Returns:\n",
    "        dict: A summary of routes with the following structure:\n",
    "        {\n",
    "            route_id (int): {\n",
    "                'min_price': float, # The minimum fare for the route\n",
    "                'stops': set        # A set of stop IDs for that route\n",
    "            }\n",
    "        }\n",
    "    \"\"\"\n",
    "    summary = {}\n",
    "    for _, row in pruned_df.iterrows():\n",
    "        route_id = row['route_id']\n",
    "        fare = row['fare']  # Changed from 'cost' to 'fare'\n",
    "        \n",
    "        if route_id not in summary:\n",
    "            summary[route_id] = {\n",
    "                'min_price': fare,\n",
    "                'stops': set(route_to_stops[route_id])\n",
    "            }\n",
    "        else:\n",
    "            summary[route_id]['min_price'] = min(summary[route_id]['min_price'], fare)\n",
    "\n",
    "    return summary\n",
    "\n",
    "# PDDL-style planning for route finding\n",
    "def pddl_planning(start_stop_id, end_stop_id, stop_id_to_include, max_transfers):\n",
    "    \"\"\"\n",
    "    Implement PDDL-style planning to find routes with optional transfers.\n",
    "    Args:\n",
    "        start_stop_id (int): The starting stop ID.\n",
    "        end_stop_id (int): The ending stop ID.\n",
    "        stop_id_to_include (int): The stop ID for a transfer.\n",
    "        max_transfers (int): The maximum number of transfers allowed.\n",
    "        route_to_stops (dict): Mapping of route_ids to their stops.\n",
    "    Returns:\n",
    "        list: A list of unique paths (list of tuples) that satisfy the criteria.\n",
    "    \"\"\"\n",
    "    paths = []\n",
    "    \n",
    "    def explore_path(current_stop, transfers_used, current_path):\n",
    "        if current_stop == end_stop_id:\n",
    "            paths.append(current_path)\n",
    "            return\n",
    "        if transfers_used > max_transfers:\n",
    "            return\n",
    "        \n",
    "        for route_id, stops in route_to_stops.items():\n",
    "            if current_stop in stops:\n",
    "                for stop in stops:\n",
    "                    if stop != current_stop and (stop_id_to_include is None or stop_id_to_include in stops):\n",
    "                        explore_path(stop, transfers_used + 1, current_path + [(route_id, stop)])\n",
    "\n",
    "    explore_path(start_stop_id, 0, [])\n",
    "    return paths\n",
    "\n",
    "# BFS for optimized route planning\n",
    "def bfs_route_planner_optimized(start_stop_id, end_stop_id, initial_fare, route_summary, route_to_stops, stop_id_to_include=None, max_transfers=3):\n",
    "    \"\"\"\n",
    "    Use Breadth-First Search (BFS) to find the optimal route while considering fare constraints.\n",
    "    Args:\n",
    "        start_stop_id (int): The starting stop ID.\n",
    "        end_stop_id (int): The ending stop ID.\n",
    "        initial_fare (float): The available fare for the trip.\n",
    "        route_summary (dict): A summary of routes with fare and stop information.\n",
    "        route_to_stops (dict): Mapping of route_ids to their stops.\n",
    "        stop_id_to_include (int, optional): Required transfer stop.\n",
    "        max_transfers (int): The maximum number of transfers allowed (default is 3).\n",
    "    Returns:\n",
    "        list: A list representing the optimal route with stops and routes taken.\n",
    "    \"\"\"\n",
    "    queue = deque([(start_stop_id, [], 0)])  # (current_stop, path, transfers_used)\n",
    "    visited = set()\n",
    "    optimal_route = None\n",
    "\n",
    "    while queue:\n",
    "        current_stop, path, transfers_used = queue.popleft()\n",
    "\n",
    "        if current_stop == end_stop_id:\n",
    "            if optimal_route is None or len(path) < len(optimal_route):\n",
    "                optimal_route = path\n",
    "            continue\n",
    "        \n",
    "        if transfers_used > max_transfers:\n",
    "            continue\n",
    "            \n",
    "        if (current_stop, transfers_used) in visited:\n",
    "            continue\n",
    "        visited.add((current_stop, transfers_used))\n",
    "\n",
    "        for route_id, route_info in route_summary.items():\n",
    "            if current_stop in route_info['stops']:\n",
    "                for next_stop in route_info['stops']:\n",
    "                    if next_stop != current_stop:\n",
    "                        fare = route_info['min_price']\n",
    "                        if fare <= initial_fare:\n",
    "                            new_transfers = transfers_used + 1 if next_stop == stop_id_to_include else transfers_used\n",
    "                            queue.append((next_stop, path + [(route_id, next_stop)], new_transfers))\n",
    "\n",
    "    return optimal_route or []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prune fare data based on an initial fare limit\n",
    "def prune_data(merged_fare_df, initial_fare):\n",
    "    \"\"\"\n",
    "    Filter fare data based on an initial fare limit.\n",
    "    Args:\n",
    "        merged_fare_df (DataFrame): The merged fare DataFrame.\n",
    "        initial_fare (float): The maximum fare allowed.\n",
    "    Returns:\n",
    "        DataFrame: A filtered DataFrame containing only routes within the fare limit.\n",
    "    \"\"\"\n",
    "    return merged_fare_df[merged_fare_df['cost'] <= initial_fare]\n",
    "\n",
    "# Pre-computation of Route Summary\n",
    "def compute_route_summary(pruned_df):\n",
    "    \"\"\"\n",
    "    Generate a summary of routes based on fare information.\n",
    "    Args:\n",
    "        pruned_df (DataFrame): The filtered DataFrame containing fare information.\n",
    "    Returns:\n",
    "        dict: A summary of routes with the following structure:\n",
    "        {\n",
    "            route_id (int): {\n",
    "                'min_price': float, # The minimum fare for the route\n",
    "                'stops': set        # A set of stop IDs for that route\n",
    "            }\n",
    "        }\n",
    "    \"\"\"\n",
    "    summary = {}\n",
    "    for _, row in pruned_df.iterrows():\n",
    "        route_id = row['route_id']\n",
    "        fare = row['cost']\n",
    "        \n",
    "        if route_id not in summary:\n",
    "            summary[route_id] = {\n",
    "                'min_price': fare,\n",
    "                'stops': set(route_to_stops[route_id])\n",
    "            }\n",
    "        else:\n",
    "            summary[route_id]['min_price'] = min(summary[route_id]['min_price'], fare)\n",
    "\n",
    "    return summary\n",
    "\n",
    "# PDDL-style planning for route finding\n",
    "def pddl_planning(start_stop_id, end_stop_id, stop_id_to_include, max_transfers):\n",
    "    \"\"\"\n",
    "    Implement PDDL-style planning to find routes with optional transfers.\n",
    "    Args:\n",
    "        start_stop_id (int): The starting stop ID.\n",
    "        end_stop_id (int): The ending stop ID.\n",
    "        stop_id_to_include (int): The stop ID for a transfer.\n",
    "        max_transfers (int): The maximum number of transfers allowed.\n",
    "    Returns:\n",
    "        list: A list of tuples where each tuple contains:\n",
    "              (route_id, stop_id_to_include, final_stop)\n",
    "    \"\"\"\n",
    "    paths = []\n",
    "    \n",
    "    def explore_path(current_stop, transfers_used, current_path):\n",
    "        if current_stop == end_stop_id and stop_id_to_include in [stop for _, stop in current_path]:\n",
    "            # Convert the path format to match expected output\n",
    "            # We only need the route that includes the required stop and reaches the destination\n",
    "            for i in range(len(current_path)):\n",
    "                route_id, stop = current_path[i]\n",
    "                if stop == stop_id_to_include:\n",
    "                    paths.append((route_id, stop_id_to_include, end_stop_id))\n",
    "            return\n",
    "            \n",
    "        if transfers_used > max_transfers:\n",
    "            return\n",
    "        \n",
    "        for route_id, stops in route_to_stops.items():\n",
    "            if current_stop in stops:\n",
    "                for stop in stops:\n",
    "                    if stop != current_stop:\n",
    "                        new_path = current_path + [(route_id, stop)]\n",
    "                        explore_path(stop, transfers_used + 1, new_path)\n",
    "\n",
    "    explore_path(start_stop_id, 0, [])\n",
    "    \n",
    "    # Remove duplicates while preserving order\n",
    "    unique_paths = list(dict.fromkeys(paths))\n",
    "    return unique_paths\n",
    "\n",
    "# BFS for optimized route planning\n",
    "def bfs_route_planner_optimized(start_stop_id, end_stop_id, initial_fare, route_summary, max_transfers=3):\n",
    "    \"\"\"\n",
    "    Use Breadth-First Search (BFS) to find the optimal route while considering fare constraints.\n",
    "    Args:\n",
    "        start_stop_id (int): The starting stop ID.\n",
    "        end_stop_id (int): The ending stop ID.\n",
    "        initial_fare (float): The available fare for the trip.\n",
    "        route_summary (dict): A summary of routes with fare and stop information.\n",
    "        max_transfers (int): The maximum number of transfers allowed (default is 3).\n",
    "    Returns:\n",
    "        list: A list representing the optimal route with stops and routes taken, structured as:\n",
    "        [\n",
    "            (route_id (int), stop_id (int)), # Tuple for each stop taken in the route\n",
    "            ...\n",
    "        ]\n",
    "    \"\"\"\n",
    "    queue = deque([(start_stop_id, [], 0)])  # (current_stop, path, transfers_used)\n",
    "    visited = set()\n",
    "    optimal_route = None\n",
    "\n",
    "    while queue:\n",
    "        current_stop, path, transfers_used = queue.popleft()\n",
    "\n",
    "        if current_stop == end_stop_id:\n",
    "            if optimal_route is None or len(path) < len(optimal_route):\n",
    "                optimal_route = path\n",
    "            continue\n",
    "        \n",
    "        if (current_stop, transfers_used) in visited:\n",
    "            continue\n",
    "        visited.add((current_stop, transfers_used))\n",
    "\n",
    "        for route_id, stops in route_to_stops.items():\n",
    "            if current_stop in stops:\n",
    "                for next_stop in stops:\n",
    "                    if next_stop != current_stop:\n",
    "                        fare = route_summary[route_id]['min_price']\n",
    "                        if fare <= initial_fare:\n",
    "                            queue.append((next_stop, path + [(route_id, next_stop)], transfers_used + 1 if next_stop == stop_id_to_include else transfers_used))\n",
    "\n",
    "    return optimal_route or []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test pddl_planning (22540, 2573, 4686, 1):  Fail (Expected: [(10153, 4686, 1407)], Got: [(10153, 4686, 2573)])\n",
      "Test pddl_planning (951, 340, 300, 1):  Fail (Expected: [(294, 300, 712), (10453, 300, 712), (1211, 300, 712), (1158, 300, 712), (37, 300, 712), (1571, 300, 712), (49, 300, 712), (387, 300, 712), (1206, 300, 712), (1038, 300, 712), (10433, 300, 712), (121, 300, 712)], Got: [(1038, 300, 340), (10433, 300, 340), (10453, 300, 340), (1211, 300, 340), (121, 300, 340), (1571, 300, 340), (37, 300, 340), (387, 300, 340), (49, 300, 340)])\n"
     ]
    }
   ],
   "source": [
    "test_pddl_planning()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDDL-style planning for route finding\n",
    "def pddl_planning(start_stop_id, end_stop_id, stop_id_to_include, max_transfers):\n",
    "    \"\"\"\n",
    "    Implement PDDL-style planning to find routes with optional transfers.\n",
    "    Args:\n",
    "        start_stop_id (int): The starting stop ID.\n",
    "        end_stop_id (int): The ending stop ID.\n",
    "        stop_id_to_include (int): The stop ID for a transfer.\n",
    "        max_transfers (int): The maximum number of transfers allowed.\n",
    "    Returns:\n",
    "        list: A list of tuples where each tuple contains:\n",
    "              (route_id, stop_id_to_include, final_stop)\n",
    "    \"\"\"\n",
    "    paths = []\n",
    "    \n",
    "    def explore_path(current_stop, transfers_used, current_path):\n",
    "        if current_stop == end_stop_id and stop_id_to_include in [stop for _, stop in current_path]:\n",
    "            # Convert the path format to match expected output\n",
    "            # We only need the route that includes the required stop and reaches the destination\n",
    "            for i in range(len(current_path)):\n",
    "                route_id, stop = current_path[i]\n",
    "                if stop == stop_id_to_include:\n",
    "                    paths.append((route_id, stop_id_to_include, end_stop_id))\n",
    "            return\n",
    "            \n",
    "        if transfers_used > max_transfers:\n",
    "            return\n",
    "        \n",
    "        for route_id, stops in route_to_stops.items():\n",
    "            if current_stop in stops:\n",
    "                for stop in stops:\n",
    "                    if stop != current_stop:\n",
    "                        new_path = current_path + [(route_id, stop)]\n",
    "                        explore_path(stop, transfers_used + 1, new_path)\n",
    "\n",
    "    explore_path(start_stop_id, 0, [])\n",
    "    \n",
    "    # Remove duplicates while preserving order\n",
    "    unique_paths = list(dict.fromkeys(paths))\n",
    "    return unique_paths\n",
    "\n",
    "def prune_data(merged_fare_df, initial_fare):\n",
    "    \"\"\"\n",
    "    Filter fare data based on an initial fare limit.\n",
    "    Args:\n",
    "        merged_fare_df (DataFrame): The merged fare DataFrame.\n",
    "        initial_fare (float): The maximum fare allowed.\n",
    "    Returns:\n",
    "        DataFrame: A filtered DataFrame containing only routes within the fare limit.\n",
    "    \"\"\"\n",
    "    # First, let's find the fare column - it might be 'price', 'fare_amount', etc.\n",
    "    fare_column = None\n",
    "    possible_fare_columns = ['price', 'fare', 'cost', 'fare_amount', 'amount']\n",
    "    \n",
    "    for col in possible_fare_columns:\n",
    "        if col in merged_fare_df.columns:\n",
    "            fare_column = col\n",
    "            break\n",
    "    \n",
    "    if fare_column is None:\n",
    "        # If we can't find a fare column, return the original DataFrame\n",
    "        return merged_fare_df\n",
    "        \n",
    "    return merged_fare_df[merged_fare_df[fare_column] <= initial_fare]\n",
    "\n",
    "def compute_route_summary(pruned_df):\n",
    "    \"\"\"\n",
    "    Generate a summary of routes based on fare information.\n",
    "    Args:\n",
    "        pruned_df (DataFrame): The filtered DataFrame containing fare information.\n",
    "    Returns:\n",
    "        dict: A summary of routes with fare and stop information\n",
    "    \"\"\"\n",
    "    summary = {}\n",
    "    # First, find the fare column\n",
    "    fare_column = None\n",
    "    possible_fare_columns = ['price', 'fare', 'cost', 'fare_amount', 'amount']\n",
    "    \n",
    "    for col in possible_fare_columns:\n",
    "        if col in pruned_df.columns:\n",
    "            fare_column = col\n",
    "            break\n",
    "    \n",
    "    if fare_column is None:\n",
    "        # If we can't find a fare column, use a default value\n",
    "        default_fare = 1.0\n",
    "        \n",
    "    for _, row in pruned_df.iterrows():\n",
    "        route_id = row['route_id']\n",
    "        fare = row[fare_column] if fare_column else default_fare\n",
    "        \n",
    "        if route_id not in summary:\n",
    "            summary[route_id] = {\n",
    "                'min_price': fare,\n",
    "                'stops': set(route_to_stops[route_id])\n",
    "            }\n",
    "        else:\n",
    "            summary[route_id]['min_price'] = min(summary[route_id]['min_price'], fare)\n",
    "\n",
    "    return summary\n",
    "\n",
    "def bfs_route_planner_optimized(start_stop_id, end_stop_id, initial_fare, route_summary, max_transfers=3):\n",
    "    \"\"\"\n",
    "    Use Breadth-First Search (BFS) to find the optimal route while considering fare constraints.\n",
    "    Args:\n",
    "        start_stop_id (int): The starting stop ID.\n",
    "        end_stop_id (int): The ending stop ID.\n",
    "        initial_fare (float): The available fare for the trip.\n",
    "        route_summary (dict): A summary of routes with fare and stop information.\n",
    "        max_transfers (int): The maximum number of transfers allowed (default is 3).\n",
    "    Returns:\n",
    "        list: A list representing the optimal route with stops and routes taken.\n",
    "    \"\"\"\n",
    "    queue = deque([(start_stop_id, [], 0, 0)])  # (current_stop, path, transfers_used, total_fare)\n",
    "    visited = set()\n",
    "    optimal_route = None\n",
    "\n",
    "    while queue:\n",
    "        current_stop, path, transfers_used, total_fare = queue.popleft()\n",
    "\n",
    "        if current_stop == end_stop_id:\n",
    "            if optimal_route is None or len(path) < len(optimal_route):\n",
    "                optimal_route = path\n",
    "            continue\n",
    "        \n",
    "        if transfers_used > max_transfers:\n",
    "            continue\n",
    "            \n",
    "        if (current_stop, transfers_used) in visited:\n",
    "            continue\n",
    "        visited.add((current_stop, transfers_used))\n",
    "\n",
    "        for route_id, info in route_summary.items():\n",
    "            if current_stop in info['stops']:\n",
    "                new_fare = total_fare + info['min_price']\n",
    "                if new_fare <= initial_fare:\n",
    "                    for next_stop in info['stops']:\n",
    "                        if next_stop != current_stop:\n",
    "                            new_transfers = transfers_used + 1 if path and path[-1][0] != route_id else transfers_used\n",
    "                            if new_transfers <= max_transfers:\n",
    "                                queue.append((\n",
    "                                    next_stop, \n",
    "                                    path + [(route_id, next_stop)], \n",
    "                                    new_transfers,\n",
    "                                    new_fare\n",
    "                                ))\n",
    "\n",
    "    return optimal_route or []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test bfs_route_planner_optimized (22540, 2573, 10, 3):  Pass\n",
      "Test bfs_route_planner_optimized (4012, 4013, 10, 3):  Pass\n"
     ]
    }
   ],
   "source": [
    "test_bfs_route_planner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test pddl_planning (22540, 2573, 4686, 1):  Fail (Expected: [(10153, 4686, 1407)], Got: [(10153, 4686, 2573)])\n",
      "Test pddl_planning (951, 340, 300, 1):  Fail (Expected: [(294, 300, 712), (10453, 300, 712), (1211, 300, 712), (1158, 300, 712), (37, 300, 712), (1571, 300, 712), (49, 300, 712), (387, 300, 712), (1206, 300, 712), (1038, 300, 712), (10433, 300, 712), (121, 300, 712)], Got: [(1038, 300, 340), (10433, 300, 340), (10453, 300, 340), (1211, 300, 340), (121, 300, 340), (1571, 300, 340), (37, 300, 340), (387, 300, 340), (49, 300, 340)])\n"
     ]
    }
   ],
   "source": [
    "test_pddl_planning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_kb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 149\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest get_stops_with_one_direct_route: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m    146\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_output(expected_output, actual_output) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFail (Expected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_output\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactual_output\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 149\u001b[0m     \u001b[43mcreate_kb\u001b[49m()  \u001b[38;5;66;03m# Ensure the data is loaded before testing\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     merged_fare_df \u001b[38;5;241m=\u001b[39m get_merged_fare_df()  \u001b[38;5;66;03m# Use the function to retrieve the DataFrame\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     initialize_datalog()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_kb' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
