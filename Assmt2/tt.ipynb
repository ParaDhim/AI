{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate for AI Assignment â€” Knowledge Representation, Reasoning and Planning\n",
    "# CSE 643\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import networkx as nx\n",
    "from pyDatalog import pyDatalog\n",
    "from collections import defaultdict, deque\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "## ****IMPORTANT****\n",
    "## Don't import or use any other libraries other than defined above\n",
    "## Otherwise your code file will be rejected in the automated testing\n",
    "\n",
    "# ------------------ Global Variables ------------------\n",
    "route_to_stops = defaultdict(list)  # Mapping of route IDs to lists of stops\n",
    "trip_to_route = {}                   # Mapping of trip IDs to route IDs\n",
    "stop_trip_count = defaultdict(int)    # Count of trips for each stop\n",
    "fare_rules = {}                      # Mapping of route IDs to fare information\n",
    "merged_fare_df = None                # To be initialized in create_kb()\n",
    "\n",
    "# Load static data from GTFS (General Transit Feed Specification) files\n",
    "df_stops = pd.read_csv('GTFS/stops.txt')\n",
    "df_routes = pd.read_csv('GTFS/routes.txt')\n",
    "df_stop_times = pd.read_csv('GTFS/stop_times.txt')\n",
    "df_fare_attributes = pd.read_csv('GTFS/fare_attributes.txt')\n",
    "df_trips = pd.read_csv('GTFS/trips.txt')\n",
    "df_fare_rules = pd.read_csv('GTFS/fare_rules.txt')\n",
    "\n",
    "# ------------------ Function Definitions ------------------\n",
    "\n",
    "# Function to create knowledge base from the loaded data\n",
    "def create_kb():\n",
    "    \"\"\"\n",
    "    Create knowledge base by populating global variables with information from loaded datasets.\n",
    "    It establishes the relationships between routes, trips, stops, and fare rules.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    global route_to_stops, trip_to_route, stop_trip_count, fare_rules, merged_fare_df\n",
    "\n",
    "    # Create trip_id to route_id mapping\"\"\"\n",
    "    trip_to_route = defaultdict(list)\n",
    "    for _, row in df_trips.iterrows():\n",
    "        trip_to_route[row['trip_id']].append(row['route_id'])\n",
    "        \n",
    "    # Map route_id to a list of stops in order of their sequence\"\"\"\n",
    "    route_to_stops = defaultdict(list)\n",
    "    sorted_stop_times = df_stop_times.sort_values(['trip_id', 'stop_sequence'])\n",
    "    sorted_stop_times.head\n",
    "    for trip_id, stop_grp in sorted_stop_times.groupby('trip_id'):\n",
    "        if trip_id in trip_to_route:\n",
    "            route_id = trip_to_route[trip_id][0]\n",
    "            stops = stop_grp['stop_id'].to_list()\n",
    "            route_to_stops[route_id].extend(stops)\n",
    "            \n",
    "    # Ensure each route only has unique stops\"\"\"\n",
    "    for route_id in route_to_stops:\n",
    "        # Use dict.fromkeys() to preserve order while removing duplicates\n",
    "        route_to_stops[route_id] = list(dict.fromkeys(route_to_stops[route_id]))\n",
    "    \n",
    "    # Count trips per stop\"\"\"\n",
    "    stop_trip_count = dict(df_stop_times['stop_id'].value_counts())\n",
    "\n",
    "    # Create fare rules for routes\n",
    "    fare_rules = {}\n",
    "    for i in range(len(df_fare_rules['route_id'])):\n",
    "        route_id = df_fare_rules['route_id'][i]\n",
    "        fare_id = df_fare_rules['fare_id'][i]\n",
    "\n",
    "        if route_id not in fare_rules:\n",
    "            fare_rules[route_id] = []\n",
    "\n",
    "        fare_rules[route_id].append(fare_id)\n",
    "\n",
    "    # Merge fare rules and attributes into a single DataFrame\n",
    "    merged_fare_df = pd.merge(\n",
    "        df_fare_rules,\n",
    "        df_fare_attributes,\n",
    "        on='fare_id',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "# Function to find the top 5 busiest routes based on the number of trips\n",
    "def get_busiest_routes():\n",
    "    \"\"\"\n",
    "    Identify the top 5 busiest routes based on trip counts.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains:\n",
    "              - route_id (int): The ID of the route.\n",
    "              - trip_count (int): The number of trips for that route.\n",
    "    \"\"\"\n",
    "    route_trip_counts = defaultdict(int)\n",
    "    for trip_id, routes in trip_to_route.items():\n",
    "        # Since we stored routes as a list in trip_to_route, take the first route\n",
    "        route_id = routes[0]\n",
    "        route_trip_counts[route_id] += 1\n",
    "    \n",
    "    res = sorted(route_trip_counts.items(), key = lambda ele: ele[1], reverse = True)\n",
    "    \n",
    "    # Return top 5 routes\n",
    "    return res[:5]\n",
    "    pass  # Implementation here\n",
    "\n",
    "# Function to find the top 5 stops with the most frequent trips\n",
    "def get_most_frequent_stops():\n",
    "    \"\"\"\n",
    "    Identify the top 5 stops with the highest number of trips.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains:\n",
    "              - stop_id (int): The ID of the stop.\n",
    "              - trip_count (int): The number of trips for that stop.\n",
    "    \"\"\"\n",
    "    res = sorted(stop_trip_count.items(), key = lambda ele: ele[1], reverse = True)\n",
    "    \n",
    "    # Return top 5 routes\n",
    "    return res[:5]\n",
    "    pass  # Implementation here\n",
    "\n",
    "# Function to find the top 5 busiest stops based on the number of routes passing through them\n",
    "def get_top_5_busiest_stops():\n",
    "    \"\"\"\n",
    "    Identify the top 5 stops with the highest number of different routes.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains:\n",
    "              - stop_id (int): The ID of the stop.\n",
    "              - route_count (int): The number of routes passing through that stop.\n",
    "    \"\"\"\n",
    "    stop_routes = defaultdict(set)\n",
    "    for route_id, stops in route_to_stops.items():\n",
    "        for stop_id in stops:\n",
    "            stop_routes[stop_id].add(route_id)\n",
    "            \n",
    "    stop_counts = []\n",
    "    for stop_id, routes in stop_routes.items():\n",
    "        route_count = len(routes)\n",
    "        stop_counts.append((stop_id, route_count))\n",
    "\n",
    "    res = sorted(stop_counts, key = lambda ele: ele[1], reverse = True)\n",
    "    \n",
    "    return res[:5]\n",
    "    pass  # Implementation here\n",
    "\n",
    "# Function to identify the top 5 pairs of stops with only one direct route between them\n",
    "def get_stops_with_one_direct_route():\n",
    "    \"\"\"\n",
    "    Identify the top 5 pairs of consecutive stops (start and end) connected by exactly one direct route. \n",
    "    The pairs are sorted by the combined frequency of trips passing through both stops.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains:\n",
    "              - pair (tuple): A tuple with two stop IDs (stop_1, stop_2).\n",
    "              - route_id (int): The ID of the route connecting the two stops.\n",
    "    \"\"\"\n",
    "    connections = {}\n",
    "    \n",
    "    for route_id, stops in route_to_stops.items():\n",
    "        for i in range(len(stops) - 1):\n",
    "            current_stop = stops[i]\n",
    "            next_stop = stops[i + 1]\n",
    "            \n",
    "            # same order for consistency\n",
    "            stop_pair = (current_stop, next_stop) if current_stop < next_stop else (next_stop, current_stop)\n",
    "\n",
    "            \n",
    "            # Add the route to this pair's list of routes\n",
    "            if stop_pair not in connections:\n",
    "                connections[stop_pair] = []\n",
    "            connections[stop_pair].append(route_id)\n",
    "    \n",
    "    result = []\n",
    "    for stop_pair, routes in connections.items():\n",
    "        if len(routes) == 1:\n",
    "            result.append((stop_pair, routes[0]))\n",
    "    \n",
    "    return result\n",
    "    pass  # Implementation here\n",
    "\n",
    "# Function to get merged fare DataFrame\n",
    "# No need to change this function\n",
    "def get_merged_fare_df():\n",
    "    \"\"\"\n",
    "    Retrieve the merged fare DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The merged fare DataFrame containing fare rules and attributes.\n",
    "    \"\"\"\n",
    "    global merged_fare_df\n",
    "    return merged_fare_df\n",
    "\n",
    "# Visualize the stop-route graph interactively\n",
    "def visualize_stop_route_graph_interactive(route_to_stops):\n",
    "    \"\"\"\n",
    "    Visualize the stop-route graph using Plotly for interactive exploration.\n",
    "\n",
    "    Args:\n",
    "        route_to_stops (dict): A dictionary mapping route IDs to lists of stops.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Step 1: Create a network graph\n",
    "    grph = nx.Graph()\n",
    "    \n",
    "    # Step 2: Add edges (connections between stops) from each route\n",
    "    edge_colors = []\n",
    "    edge_labels = []\n",
    "    \n",
    "    unique_routes = list(route_to_stops.keys())\n",
    "    color_palette = plt.cm.get_cmap('hsv')(np.linspace(0, 1, len(unique_routes)))\n",
    "    \n",
    "    rt_color_map = {}\n",
    "    for i in range (len(unique_routes)):\n",
    "        route_id = unique_routes[i]\n",
    "        r, g, b, _ = color_palette[i]\n",
    "        \n",
    "        color_string = f'rgb({int(r*255)},{int(g*255)},{int(b*255)})'\n",
    "        rt_color_map[route_id] = color_string\n",
    "    \n",
    "    for route_id, stops_on_route in route_to_stops.items():\n",
    "        route_name = df_routes[df_routes['route_id'] == route_id]['route_long_name'].iloc[0]\n",
    "        for i in range(len(stops_on_route) - 1):\n",
    "            current_stop = stops_on_route[i]\n",
    "            next_stop = stops_on_route[i + 1]\n",
    "            \n",
    "            grph.add_edge(current_stop, next_stop)\n",
    "            \n",
    "            edge_colors.append(rt_color_map[route_id])\n",
    "            edge_labels.append(f\"Route: {route_name}\")\n",
    "        \n",
    "    # Step 3: Calculate state_positions for the graph\n",
    "    stop_positions = nx.shell_layout(grph)\n",
    "    \n",
    "    # Step 4: Create edge trace\n",
    "    edge_trace = []\n",
    "    for i in range (len(grph.edges())):\n",
    "        edge = list(grph.edges())[i]\n",
    "        color = edge_colors[i]\n",
    "        label = edge_labels[i]\n",
    "        \n",
    "        x0, y0 = stop_positions[edge[0]]\n",
    "        x1, y1 = stop_positions[edge[1]]\n",
    "        \n",
    "        \n",
    "        edge_trace.append(\n",
    "            go.Scatter(\n",
    "                x=[x0, x1, None],\n",
    "                y=[y0, y1, None],\n",
    "                line=dict(width=2, color=color),\n",
    "                hoverinfo='text',\n",
    "                text=label,\n",
    "                mode='lines'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    # Step 5: Create node trace\n",
    "    node_x = []\n",
    "    node_y = []\n",
    "    node_text = []\n",
    "    \n",
    "    for node in grph.nodes():\n",
    "        x, y = stop_positions[node]\n",
    "        node_x.append(x)\n",
    "        node_y.append(y)\n",
    "        # Get stop name for hover text\n",
    "        stop_name = df_stops[df_stops['stop_id'] == node]['stop_name'].iloc[0]\n",
    "        node_text.append(f\"Stop: {stop_name}<br>ID: {node}\")\n",
    "    \n",
    "    node_trace = go.Scatter(\n",
    "        x=node_x,\n",
    "        y=node_y,\n",
    "        mode='markers+text',\n",
    "        hoverinfo='text',\n",
    "        text=node_text,\n",
    "        marker=dict(\n",
    "            size=10,\n",
    "            color='lightblue',\n",
    "            line=dict(width=2, color='darkblue')\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Step 6: Create the figure\n",
    "    fig = go.Figure(data=edge_trace + [node_trace],\n",
    "                   layout=go.Layout(\n",
    "                       title='Transit Network Map',\n",
    "                       showlegend=False,\n",
    "                       hovermode='closest',\n",
    "                       margin=dict(b=0, l=0, r=0, t=40),\n",
    "                       xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                       yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                       plot_bgcolor='white'\n",
    "                   ))\n",
    "    \n",
    "    # Add a legend showing route colors\n",
    "    for route_id in unique_routes:\n",
    "        route_name = df_routes[df_routes['route_id'] == route_id]['route_long_name'].iloc[0]\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[None],\n",
    "            y=[None],\n",
    "            mode='lines',\n",
    "            name=route_name,\n",
    "            line=dict(color=rt_color_map[route_id], width=2),\n",
    "            showlegend=True\n",
    "        ))\n",
    "    \n",
    "    # Step 7: Show the plot\n",
    "    fig.show()\n",
    "    pass  # Implementation here\n",
    "\n",
    "# Brute-Force Approach for finding direct routes\n",
    "def direct_route_brute_force(start_stop, end_stop):\n",
    "    \"\"\"\n",
    "    Find all valid routes between two stops using a brute-force method.\n",
    "\n",
    "    Args:\n",
    "        start_stop (int): The ID of the starting stop.\n",
    "        end_stop (int): The ID of the ending stop.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of route IDs (int) that connect the two stops directly.\n",
    "    \"\"\"\n",
    "    \n",
    "    dir_routes = []\n",
    "    for route_id, stops in route_to_stops.items():\n",
    "        if start_stop in stops and end_stop in stops:\n",
    "            # Check if start_stop comes before end_stop in the sequence\n",
    "            if stops.index(start_stop) < stops.index(end_stop):\n",
    "                dir_routes.append(route_id)\n",
    "    return dir_routes\n",
    "    \n",
    "    pass  # Implementation here\n",
    "\n",
    "# Initialize Datalog predicates for reasoning\n",
    "pyDatalog.create_terms('RouteHasStop, DirectRoute, OptimalRoute, X, Y, Z, R, R1, R2')  \n",
    "def initialize_datalog():\n",
    "    \"\"\"\n",
    "    Initialize Datalog terms and predicates for reasoning about routes and stops.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    pyDatalog.clear()  # Clear previous terms\n",
    "    print(\"Terms initialized: DirectRoute, RouteHasStop, OptimalRoute\")  # Confirmation print\n",
    "\n",
    "    # Define Datalog predicates\n",
    "\n",
    "    create_kb()  # Populate the knowledge base\n",
    "    add_route_data(route_to_stops)  # Add route data to Datalog\n",
    "    \n",
    "    \n",
    "# Adding route data to Datalog\n",
    "def add_route_data(route_to_stops):\n",
    "    \"\"\"\n",
    "    Add the route data to Datalog for reasoning.\n",
    "\n",
    "    Args:\n",
    "        route_to_stops (dict): A dictionary mapping route IDs to lists of stops.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    for route_id, stops in route_to_stops.items():\n",
    "        for stop_id in stops:\n",
    "            +RouteHasStop(route_id, stop_id)\n",
    "\n",
    "# Function to query direct routes between two stops\n",
    "def query_direct_routes(start, end):\n",
    "    \"\"\"\n",
    "    Query for direct routes between two stops.\n",
    "\n",
    "    Args:\n",
    "        start (int): The ID of the starting stop.\n",
    "        end (int): The ID of the ending stop.\n",
    "\n",
    "    Returns:\n",
    "        list: A sorted list of route IDs (str) connecting the two stops.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Query for routes that contain both start and end stops\n",
    "    query_result = pyDatalog.ask(f'RouteHasStop(R, {start}) & RouteHasStop(R, {end})')\n",
    "    \n",
    "    # Process the results, assuming each answer contains a single route_id\n",
    "    if query_result:\n",
    "        return sorted(set(route_id[0] for route_id in query_result.answers))\n",
    "    return []\n",
    "    \n",
    "    pass  # Implementation here\n",
    "\n",
    "# Forward chaining for optimal route planning\n",
    "def forward_chaining(start_stop_id, end_stop_id, stop_id_to_include, max_transfers):\n",
    "    \"\"\"\n",
    "    Perform forward chaining to find optimal routes considering transfers.\n",
    "\n",
    "    Args:\n",
    "        start_stop_id (int): The starting stop ID.\n",
    "        end_stop_id (int): The ending stop ID.\n",
    "        stop_id_to_include (int): The stop ID where a transfer occurs.\n",
    "        max_transfers (int): The maximum number of transfers allowed.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of unique paths (list of tuples) that satisfy the criteria, where each tuple contains:\n",
    "              - route_id (int): The ID of the route.\n",
    "              - stop_id (int): The ID of the stop.\n",
    "    \"\"\"\n",
    "    # Clear any existing facts\n",
    "    pyDatalog.clear()\n",
    "    start_time = time.time()\n",
    "    process = psutil.Process(os.getpid())\n",
    "    initial_memory = process.memory_info().rss / 1024 / 1024  # Convert to MB\n",
    "\n",
    "    # Add facts about which routes contain which stops\n",
    "    for route_id, stops in route_to_stops.items():\n",
    "        for stop_id in stops:\n",
    "            +RouteHasStop(route_id, stop_id)\n",
    "\n",
    "    # Define valid path rules for direct routes\n",
    "    OptimalRoute(X, Y) <= (\n",
    "        RouteHasStop(X, start_stop_id) &\n",
    "        RouteHasStop(X, stop_id_to_include) &\n",
    "        RouteHasStop(X, end_stop_id)\n",
    "    )\n",
    "\n",
    "    # Rule for paths with one transfer\n",
    "    OptimalRoute(X, Y) <= (\n",
    "        RouteHasStop(X, start_stop_id) &\n",
    "        RouteHasStop(X, stop_id_to_include) &\n",
    "        RouteHasStop(Y, stop_id_to_include) &\n",
    "        RouteHasStop(Y, end_stop_id) &\n",
    "        (X != Y)\n",
    "    )\n",
    "\n",
    "    # Query for valid paths\n",
    "    results = OptimalRoute(X, Y)\n",
    "\n",
    "    # Convert results to list of tuples\n",
    "    paths = [(x, stop_id_to_include, y) for x, y in results \n",
    "             if x is not None and y is not None]\n",
    "\n",
    "    end_time = time.time()\n",
    "    final_memory = process.memory_info().rss / 1024 / 1024\n",
    "    execution_metrics = {\n",
    "        'execution_time': end_time - start_time,\n",
    "        'memory_usage': final_memory - initial_memory\n",
    "    }\n",
    "    return sorted(list(set(paths)))\n",
    "    \n",
    "\n",
    "\n",
    "# Backward chaining for optimal route planning\n",
    "def backward_chaining(start_stop_id, end_stop_id, stop_id_to_include, max_transfers):\n",
    "    \"\"\"\n",
    "    Perform backward chaining to find optimal routes considering transfers.\n",
    "\n",
    "    Args:\n",
    "        start_stop_id (int): The starting stop ID.\n",
    "        end_stop_id (int): The ending stop ID.\n",
    "        stop_id_to_include (int): The stop ID where a transfer occurs.\n",
    "        max_transfers (int): The maximum number of transfers allowed.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of unique paths (list of tuples) that satisfy the criteria, where each tuple contains:\n",
    "              - route_id (int): The ID of the route.\n",
    "              - stop_id (int): The ID of the stop.\n",
    "    \"\"\"\n",
    "    \n",
    "     # Clear any existing facts\n",
    "    pyDatalog.clear()\n",
    "    start_time = time.time()\n",
    "    process = psutil.Process(os.getpid())\n",
    "    initial_memory = process.memory_info().rss / 1024 / 1024\n",
    "\n",
    "    # Add facts about which routes contain which stops\n",
    "    for route_id, stops in route_to_stops.items():\n",
    "        for stop_id in stops:\n",
    "            +RouteHasStop(route_id, stop_id)\n",
    "\n",
    "    # Define rules starting from the end stop\n",
    "    OptimalRoute(X, Y) <= (\n",
    "        RouteHasStop(X, end_stop_id) &\n",
    "        RouteHasStop(X, stop_id_to_include) &\n",
    "        RouteHasStop(X, start_stop_id)\n",
    "    )\n",
    "\n",
    "    # Rule for paths with one transfer (backward direction)\n",
    "    OptimalRoute(X, Y) <= (\n",
    "        RouteHasStop(X, end_stop_id) &\n",
    "        RouteHasStop(X, stop_id_to_include) &\n",
    "        RouteHasStop(Y, stop_id_to_include) &\n",
    "        RouteHasStop(Y, start_stop_id) &\n",
    "        (X != Y)\n",
    "    )\n",
    "\n",
    "    # Query for valid paths\n",
    "    results = OptimalRoute(X, Y)\n",
    "\n",
    "    # Convert results to list of tuples\n",
    "    paths = [(x, stop_id_to_include, y) for x, y in results \n",
    "             if x is not None and y is not None]\n",
    "\n",
    "    end_time = time.time()\n",
    "    final_memory = process.memory_info().rss / 1024 / 1024\n",
    "    execution_metrics = {\n",
    "        'execution_time': end_time - start_time,\n",
    "        'memory_usage': final_memory - initial_memory\n",
    "    }\n",
    "    return sorted(list(set(paths)))\n",
    "    \n",
    "    \n",
    "    pass  # Implementation here\n",
    "\n",
    "\n",
    "pyDatalog.create_terms('route_stop, R, X, Start, Via, End, Stop, R1, R2')\n",
    "pyDatalog.create_terms('can_board, can_transfer, reachable, path')\n",
    "def pddl_planning(start_stop_id, end_stop_id, stop_id_to_include, max_transfers):\n",
    "    \"\"\"\n",
    "    Optimized PDDL-based route planning implementation using PyDatalog\n",
    "    Returns list of tuples (route1, transfer_stop, route2) representing valid paths\n",
    "    \"\"\"\n",
    "    # Initialize PyDatalog\n",
    "    pyDatalog.clear()\n",
    "    # Initialize PyDatalog globally\n",
    "    \n",
    "\n",
    "    # # Start timing and memory tracking\n",
    "    # start_time = time.time()\n",
    "    # process = psutil.Process(os.getpid())\n",
    "    # initial_memory = process.memory_info().rss / 1024 / 1024\n",
    "\n",
    "    \n",
    "\n",
    "    # Pre-process route data for faster lookups\n",
    "    stop_to_routes = defaultdict(set)\n",
    "    route_stops = defaultdict(set)\n",
    "    transfer_routes = set()\n",
    "\n",
    "    # Build lookup dictionaries and assert facts\n",
    "    try:\n",
    "        for route_id, stops in route_to_stops.items():\n",
    "            route_stops[route_id] = set(stops)\n",
    "            if stop_id_to_include in stops:\n",
    "                transfer_routes.add(route_id)\n",
    "            for stop in stops:\n",
    "                stop_to_routes[stop].add(route_id)\n",
    "                # Assert facts using proper PyDatalog syntax\n",
    "                + route_stop(route_id, stop)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during fact assertion: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "    # Early termination checks\n",
    "    if not stop_to_routes[start_stop_id] or not stop_to_routes[end_stop_id]:\n",
    "        return []\n",
    "\n",
    "    # Define rules (without + operator)\n",
    "    can_board(R, X) <= route_stop(R, X)\n",
    "\n",
    "    reachable(R, Start, Via, End) <= (\n",
    "        can_board(R, Start) &\n",
    "        route_stop(R, Via) &\n",
    "        route_stop(R, End)\n",
    "    )\n",
    "\n",
    "    can_transfer(R1, R2, Stop) <= (\n",
    "        route_stop(R1, Stop) &\n",
    "        route_stop(R2, Stop)\n",
    "    )\n",
    "\n",
    "    path(R1, Via, R2) <= (\n",
    "        reachable(R1, start_stop_id, Via, stop_id_to_include) &\n",
    "        reachable(R2, stop_id_to_include, Via, end_stop_id)\n",
    "    )\n",
    "\n",
    "    result_paths = set()\n",
    "\n",
    "    # Query for direct routes (no transfers)\n",
    "    if max_transfers >= 0:\n",
    "        for route in stop_to_routes[start_stop_id] & stop_to_routes[end_stop_id] & transfer_routes:\n",
    "            try:\n",
    "                stops = list(route_to_stops[route])\n",
    "                start_idx = stops.index(start_stop_id)\n",
    "                via_idx = stops.index(stop_id_to_include)\n",
    "                end_idx = stops.index(end_stop_id)\n",
    "                \n",
    "                # Inline validity check for direct routes\n",
    "                if start_idx < via_idx < end_idx:\n",
    "                    result_paths.add((route, stop_id_to_include, route))\n",
    "                    # print(f\"State: Direct route found - {route}\")\n",
    "            except (ValueError, KeyError):\n",
    "                continue\n",
    "\n",
    "    # Query for routes with one transfer\n",
    "    if max_transfers >= 1:\n",
    "        # Query using PyDatalog syntax\n",
    "        solutions = path(R1, Via, R2)\n",
    "        if solutions:\n",
    "            for r1, via, r2 in solutions:\n",
    "                try:\n",
    "                    stops1 = list(route_to_stops[r1])\n",
    "                    stops2 = list(route_to_stops[r2])\n",
    "                    if r1 != r2:\n",
    "                        # Inline validity checks for transfer routes\n",
    "                        start_to_via_valid = stops1.index(start_stop_id) < stops1.index(stop_id_to_include)\n",
    "                        via_to_end_valid = True  # Allow reverse direction after transfer\n",
    "                        \n",
    "                        if start_to_via_valid and via_to_end_valid:\n",
    "                            result_paths.add((r1, stop_id_to_include, r2))\n",
    "                            # print(f\"State: Transfer route found - {r1} to {r2} at {stop_id_to_include}\")\n",
    "                except (ValueError, KeyError):\n",
    "                    continue\n",
    "\n",
    "    # # Calculate performance metrics\n",
    "    # execution_time = time.time() - start_time\n",
    "    # final_memory = process.memory_info().rss / 1024 / 1024\n",
    "    # memory_used = final_memory - initial_memory\n",
    "    # print(f\"\\nPerformance Metrics:\")\n",
    "    # print(f\"Execution Time: {execution_time:.4f} seconds\")\n",
    "    # print(f\"Memory Usage: {memory_used:.2f} MB\")\n",
    "    # print(f\"Number of Steps: {len(result_paths)}\")\n",
    "\n",
    "    return sorted(list(result_paths))\n",
    "    \n",
    "    pass  # Implementation here\n",
    "\n",
    "# Function to filter fare data based on an initial fare limit\n",
    "def prune_data(merged_fare_df, initial_fare):\n",
    "    \"\"\"\n",
    "    Filter fare data based on an initial fare limit.\n",
    "\n",
    "    Args:\n",
    "        merged_fare_df (DataFrame): The merged fare DataFrame.\n",
    "        initial_fare (float): The maximum fare allowed.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A filtered DataFrame containing only routes within the fare limit.\n",
    "    \"\"\"\n",
    "    \n",
    "     # First, let's find the fare column - it might be 'price', 'fare_amount', etc.\n",
    "    fare_column = None\n",
    "    possible_fare_columns = ['price', 'fare', 'cost', 'fare_amount', 'amount']\n",
    "    \n",
    "    for col in possible_fare_columns:\n",
    "        if col in merged_fare_df.columns:\n",
    "            fare_column = col\n",
    "            break\n",
    "    \n",
    "    if fare_column is None:\n",
    "        # If we can't find a fare column, return the original DataFrame\n",
    "        return merged_fare_df\n",
    "        \n",
    "    return merged_fare_df[merged_fare_df[fare_column] <= initial_fare]\n",
    "    \n",
    "    pass  # Implementation here\n",
    "\n",
    "# Pre-computation of Route Summary\n",
    "def compute_route_summary(pruned_df):\n",
    "    \"\"\"\n",
    "    Generate a summary of routes based on fare information.\n",
    "\n",
    "    Args:\n",
    "        pruned_df (DataFrame): The filtered DataFrame containing fare information.\n",
    "\n",
    "    Returns:\n",
    "        dict: A summary of routes with the following structure:\n",
    "              {\n",
    "                  route_id (int): {\n",
    "                      'min_price': float,          # The minimum fare for the route\n",
    "                      'stops': set                # A set of stop IDs for that route\n",
    "                  }\n",
    "              }\n",
    "    \"\"\"\n",
    "    \n",
    "    summary = {}\n",
    "    # First, find the fare column\n",
    "    fare_column = None\n",
    "    possible_fare_columns = ['price', 'fare', 'cost', 'fare_amount', 'amount']\n",
    "    \n",
    "    for col in possible_fare_columns:\n",
    "        if col in pruned_df.columns:\n",
    "            fare_column = col\n",
    "            break\n",
    "    \n",
    "    if fare_column is None:\n",
    "        # If we can't find a fare column, use a default value\n",
    "        default_fare = 1.0\n",
    "        \n",
    "    for _, row in pruned_df.iterrows():\n",
    "        route_id = row['route_id']\n",
    "        fare = row[fare_column] if fare_column else default_fare\n",
    "        \n",
    "        if route_id not in summary:\n",
    "            summary[route_id] = {\n",
    "                'min_price': fare,\n",
    "                'stops': set(route_to_stops[route_id])\n",
    "            }\n",
    "        else:\n",
    "            summary[route_id]['min_price'] = min(summary[route_id]['min_price'], fare)\n",
    "\n",
    "    return summary\n",
    "    \n",
    "    pass  # Implementation here\n",
    "\n",
    "# BFS for optimized route planning\n",
    "def bfs_route_planner_optimized(start_stop_id, end_stop_id, initial_fare, route_summary, max_transfers=3):\n",
    "    \"\"\"\n",
    "    Use Breadth-First Search (BFS) to find the optimal route while considering fare constraints.\n",
    "\n",
    "    Args:\n",
    "        start_stop_id (int): The starting stop ID.\n",
    "        end_stop_id (int): The ending stop ID.\n",
    "        initial_fare (float): The available fare for the trip.\n",
    "        route_summary (dict): A summary of routes with fare and stop information.\n",
    "        max_transfers (int): The maximum number of transfers allowed (default is 3).\n",
    "\n",
    "    Returns:\n",
    "        list: A list representing the optimal route with stops and routes taken, structured as:\n",
    "              [\n",
    "                  (route_id (int), stop_id (int)),  # Tuple for each stop taken in the route\n",
    "                  ...\n",
    "              ]\n",
    "    \"\"\"\n",
    "    \n",
    "    queue = deque([(start_stop_id, [], 0, 0)])  # (current_stop, path, transfers_used, total_fare)\n",
    "    visited = set()\n",
    "    optimal_route = None\n",
    "\n",
    "    while queue:\n",
    "        current_stop, path, transfers_used, total_fare = queue.popleft()\n",
    "\n",
    "        if current_stop == end_stop_id:\n",
    "            if optimal_route is None or len(path) < len(optimal_route):\n",
    "                optimal_route = path\n",
    "            continue\n",
    "        \n",
    "        if transfers_used > max_transfers:\n",
    "            continue\n",
    "            \n",
    "        if (current_stop, transfers_used) in visited:\n",
    "            continue\n",
    "        visited.add((current_stop, transfers_used))\n",
    "\n",
    "        for route_id, info in route_summary.items():\n",
    "            if current_stop in info['stops']:\n",
    "                new_fare = total_fare + info['min_price']\n",
    "                if new_fare <= initial_fare:\n",
    "                    for next_stop in info['stops']:\n",
    "                        if next_stop != current_stop:\n",
    "                            new_transfers = transfers_used + 1 if path and path[-1][0] != route_id else transfers_used\n",
    "                            if new_transfers <= max_transfers:\n",
    "                                queue.append((\n",
    "                                    next_stop, \n",
    "                                    path + [(route_id, next_stop)], \n",
    "                                    new_transfers,\n",
    "                                    new_fare\n",
    "                                ))\n",
    "\n",
    "    return optimal_route or []\n",
    "    \n",
    "    pass  # Implementation here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terms initialized: DirectRoute, RouteHasStop, OptimalRoute\n",
      "Test direct_route_brute_force (2573, 1177):  Pass\n",
      "Test direct_route_brute_force (2001, 2005):  Pass\n",
      "Test query_direct_routes (2573, 1177):  Pass\n",
      "Test query_direct_routes (2001, 2005):  Pass\n",
      "Test forward_chaining (22540, 2573, 4686, 1):  Pass\n",
      "Test forward_chaining (951, 340, 300, 1):  Pass\n",
      "Test backward_chaining (22540, 2573, 4686, 1):  Pass\n",
      "Test backward_chaining (951, 340, 300, 1):  Pass\n",
      "Test pddl_planning (22540, 2573, 4686, 1):  Pass\n",
      "Test pddl_planning (951, 340, 300, 1):  Pass\n",
      "Test bfs_route_planner_optimized (22540, 2573, 10, 3):  Pass\n",
      "Test bfs_route_planner_optimized (4012, 4013, 10, 3):  Pass\n"
     ]
    }
   ],
   "source": [
    "\n",
    "route_to_stops = defaultdict(list)  # Maps route_id to an ordered list of stop_ids\n",
    "trip_to_route = {}  # Maps trip_id to route_id\n",
    "stop_trip_count = defaultdict(int)  # Maps stop_id to count of trips stopping there\n",
    "fare_rules = {}  # Maps route_id to fare information\n",
    "\n",
    "# Sample public test inputs with expected outputs explicitly defined\n",
    "test_inputs = {\n",
    "    \"direct_route\": [\n",
    "        ((2573, 1177), [10001, 1117, 1407]),  # Input -> Expected output\n",
    "        ((2001, 2005), [10001, 1151])\n",
    "    ],\n",
    "\n",
    "    \"forward_chaining\": [\n",
    "        ((22540, 2573, 4686, 1), [(10153, 4686, 1407)]),\n",
    "        ((951, 340, 300, 1), [(1211, 300, 712), (10453, 300, 712), (387, 300, 712), (49, 300, 712), \n",
    "                              (1571, 300, 712), (37, 300, 712), (1038, 300, 712), (10433, 300, 712), \n",
    "                              (121, 300, 712)])\n",
    "    ],\n",
    "    \"backward_chaining\": [\n",
    "        ((2573, 22540, 4686, 1), [(1407, 4686, 10153)]),\n",
    "        ((340, 951, 300, 1), [(712, 300, 121), (712, 300, 1211), (712, 300, 37), (712, 300, 387),\n",
    "                              (712, 300, 49), (712, 300, 10453), (712, 300, 1038), (712, 300, 10433),\n",
    "                              (712, 300, 1571)])\n",
    "    ],\n",
    "    \"pddl_planning\": [\n",
    "        ((22540, 2573, 4686, 1), [(10153, 4686, 1407)]),\n",
    "        ((951, 340, 300, 1), [(1211, 300, 712), (10453, 300, 712), (387, 300, 712), (49, 300, 712), \n",
    "                        (1571, 300, 712), (37, 300, 712), (1038, 300, 712), (10433, 300, 712), \n",
    "                        (121, 300, 712)])\n",
    "    ],\n",
    "    \"bfs_route\": [\n",
    "        ((22540, 2573, 10, 3), [(10153, 4686), (1407, 2573)]),\n",
    "        ((4012, 4013, 10, 3), [(10004, 4013)])\n",
    "    ],\n",
    "\n",
    "    ### NOTE: The below values are just dummy values, the actual values are might differ! \n",
    "    \"busiest_routes\": [\n",
    "        [(123, 456), (789, 234), (567, 235), (3456, 897), (345, 345)]\n",
    "    ],\n",
    "    \"most_frequent_stops\": [\n",
    "        [(456, 456), (234, 765), (234, 765), (234, 657765), (3252, 35634)]\n",
    "    ],\n",
    "    \"busiest_stops\": [\n",
    "        [(432243, 14543), (454235, 2452), (2452, 2454), (78568, 24352), (42352, 24532)]\n",
    "    ],\n",
    "    \"stops_with_one_direct_route\": [\n",
    "        [((24527, 676), 542), ((243535, 8768), 2456), ((43262, 564), 65437),\n",
    "         ((256, 56), 245), ((266, 256), 78)]\n",
    "    ]\n",
    "}\n",
    "\n",
    "# def check_output(expected, actual):\n",
    "#     \"\"\"Function to compare expected and actual outputs.\"\"\"\n",
    "#     return set(expected) == set(actual)\n",
    "\n",
    "def check_output(expected, actual):\n",
    "    \"\"\"Function to compare expected and actual outputs.\"\"\"\n",
    "    if isinstance(expected, list) and isinstance(actual, list):\n",
    "        return sorted(expected) == sorted(actual)  # Ensures order-independent comparison\n",
    "    return expected == actual  # For non-list types\n",
    "\n",
    "def test_direct_route_brute_force():\n",
    "    for (start_stop, end_stop), expected_output in test_inputs[\"direct_route\"]:\n",
    "        actual_output = direct_route_brute_force(start_stop, end_stop)\n",
    "        print(f\"Test direct_route_brute_force ({start_stop}, {end_stop}): \", \n",
    "              \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "def test_query_direct_routes():\n",
    "    for (start_stop, end_stop), expected_output in test_inputs[\"direct_route\"]:\n",
    "        actual_output = query_direct_routes(start_stop, end_stop)\n",
    "        print(f\"Test query_direct_routes ({start_stop}, {end_stop}): \", \n",
    "              \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "def test_forward_chaining():\n",
    "    for (start_stop, end_stop, via_stop, max_transfers), expected_output in test_inputs[\"forward_chaining\"]:\n",
    "        actual_output = forward_chaining(start_stop, end_stop, via_stop, max_transfers)\n",
    "        print(f\"Test forward_chaining ({start_stop}, {end_stop}, {via_stop}, {max_transfers}): \", \n",
    "              \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "def test_backward_chaining():\n",
    "    for (end_stop, start_stop, via_stop, max_transfers), expected_output in test_inputs[\"backward_chaining\"]:\n",
    "        actual_output = backward_chaining(start_stop, end_stop, via_stop, max_transfers)\n",
    "        print(f\"Test backward_chaining ({start_stop}, {end_stop}, {via_stop}, {max_transfers}): \", \n",
    "              \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "def test_pddl_planning():\n",
    "    for (start_stop, end_stop, via_stop, max_transfers), expected_output in test_inputs[\"pddl_planning\"]:\n",
    "        actual_output = pddl_planning(start_stop, end_stop, via_stop, max_transfers)\n",
    "        print(f\"Test pddl_planning ({start_stop}, {end_stop}, {via_stop}, {max_transfers}): \", \n",
    "              \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "def test_bfs_route_planner():\n",
    "    for (start_stop, end_stop, initial_fare, max_transfers), expected_output in test_inputs[\"bfs_route\"]:\n",
    "        pruned_df = prune_data(merged_fare_df, initial_fare)\n",
    "        route_summary = compute_route_summary(pruned_df)\n",
    "        actual_output = bfs_route_planner_optimized(start_stop, end_stop, initial_fare, route_summary, max_transfers)\n",
    "        print(f\"Test bfs_route_planner_optimized ({start_stop}, {end_stop}, {initial_fare}, {max_transfers}): \", \n",
    "              \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "# New test functions for the additional queries\n",
    "\n",
    "def test_get_busiest_routes():\n",
    "    expected_output = test_inputs[\"busiest_routes\"][0]\n",
    "    actual_output = get_busiest_routes()\n",
    "    print(f\"Test get_busiest_routes: \", \n",
    "          \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "def test_get_most_frequent_stops():\n",
    "    expected_output = test_inputs[\"most_frequent_stops\"][0]\n",
    "    actual_output = get_most_frequent_stops()\n",
    "    print(f\"Test get_most_frequent_stops: \", \n",
    "          \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "def test_get_top_5_busiest_stops():\n",
    "    expected_output = test_inputs[\"busiest_stops\"][0]\n",
    "    actual_output = get_top_5_busiest_stops()\n",
    "    print(f\"Test get_top_5_busiest_stops: \", \n",
    "          \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "def test_get_stops_with_one_direct_route():\n",
    "    expected_output = test_inputs[\"stops_with_one_direct_route\"][0]\n",
    "    actual_output = get_stops_with_one_direct_route()\n",
    "    print(f\"Test get_stops_with_one_direct_route: \", \n",
    "          \"Pass\" if check_output(expected_output, actual_output) else f\"Fail (Expected: {expected_output}, Got: {actual_output})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_kb()  # Ensure the data is loaded before testing\n",
    "    merged_fare_df = get_merged_fare_df()  # Use the function to retrieve the DataFrame\n",
    "    initialize_datalog()\n",
    "    \n",
    "    # Run all tests\n",
    "    test_direct_route_brute_force()\n",
    "    test_query_direct_routes()\n",
    "    test_forward_chaining()\n",
    "    test_backward_chaining()\n",
    "    test_pddl_planning()\n",
    "    test_bfs_route_planner()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
